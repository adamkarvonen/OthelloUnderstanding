{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import torch as t\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from typing import Callable, Optional\n",
    "\n",
    "import circuits.analysis as analysis\n",
    "import circuits.eval_sae_as_classifier as eval_sae\n",
    "import circuits.utils as utils\n",
    "import circuits.f1_analysis as f1_analysis\n",
    "import circuits.dictionary_learning.dictionary as dictionary\n",
    "from circuits.dictionary_learning.dictionary import AutoEncoder\n",
    "import circuits.chess_utils as chess_utils\n",
    "import circuits.othello_utils as othello_utils\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key for mapping from the last entry of the board state tensor to pieces:\n",
    "* 0 => black king\n",
    "* 1 => black queen\n",
    "* 2 => black rook\n",
    "* 3 => black bishop\n",
    "* 4 => black knight\n",
    "* 5 => black pawn\n",
    "* 6 => empty\n",
    "* 7 => white pawn\n",
    "* 8 => white knight\n",
    "* 9 => white bishop\n",
    "* 10 => white rook\n",
    "* 11 => white queen\n",
    "* 12 => white king"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load SAE\n",
    "# ae_path = '../autoencoders/chess_layer5_large_sweep/ef=16_lr=1e-03_l1=3e-02_layer_5'\n",
    "# ae_path = '../autoencoders/chess_layer5_large_sweep/ef=4_lr=1e-03_l1=1e-01_layer_5'\n",
    "\n",
    "def get_ae(ae_path):\n",
    "\n",
    "    if \"gated\" in ae_path:\n",
    "        ae = dictionary.GatedAutoEncoder.from_pretrained(os.path.join(ae_path, 'ae.pt'), device='cuda:0')\n",
    "    else:\n",
    "        ae = AutoEncoder.from_pretrained(os.path.join(ae_path, 'ae.pt'), device='cuda:0')\n",
    "    return ae\n",
    "\n",
    "def get_feature_labels(autoencoder_path: str, high_threshold: float, filename_filter: str, device):\n",
    "\n",
    "    results_filenames = analysis.get_all_results_file_names(autoencoder_path, filename_filter)\n",
    "    if len(results_filenames) > 1 or len(results_filenames) == 0:\n",
    "        raise ValueError(\"There are multiple results files\")\n",
    "    results_filename = results_filenames[0]\n",
    "\n",
    "    with open(os.path.join(autoencoder_path, results_filename), 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "    results = utils.to_device(results, device)\n",
    "    feature_labels, misc_stats = analysis.analyze_results_dict(results, \"\", device, high_threshold=high_threshold, save_results=False, print_results=False, verbose=False)\n",
    "    return feature_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_idx(feat_idx: int) -> int:\n",
    "#     return (feature_labels['alive_features'] == feat_idx).nonzero().item()\n",
    "# find_idx(1600)\n",
    "\n",
    "\n",
    "def get_linear_probe_MDRRC(linear_probe_path: str) -> t.Tensor:\n",
    "\n",
    "    with open(linear_probe_path, \"rb\") as f:\n",
    "        state_dict = t.load(f, map_location=device)\n",
    "        print(state_dict.keys())\n",
    "        linear_probe_MDRRC = state_dict[\"linear_probe\"]\n",
    "    return linear_probe_MDRRC\n",
    "\n",
    "\n",
    "def get_average_from_list_of_tuples(l: list[tuple[float, int]]) -> float:\n",
    "    return sum([x[0] for x in l]) / len(l)\n",
    "\n",
    "\n",
    "def get_cos_sims(\n",
    "    ae, feature_labels: dict, func_name: str, threshold: int, linear_probe_MDRRC: t.Tensor\n",
    ") -> list[float]:\n",
    "\n",
    "    decoder_weights = ae.decoder.weight.data.to(device)\n",
    "    M, D, R1, R2, C = linear_probe_MDRRC.shape\n",
    "\n",
    "    cos_sims_true = []\n",
    "    cos_sims_random1 = []\n",
    "    cos_sims_random2 = []\n",
    "\n",
    "    for idx in range(feature_labels[\"alive_features\"].shape[0]):\n",
    "        feat_idx = feature_labels[\"alive_features\"][idx]\n",
    "        num_classified_squares = (feature_labels[func_name][threshold][idx]).sum()\n",
    "\n",
    "        if num_classified_squares == 0:\n",
    "            continue\n",
    "\n",
    "        # if num_classified_squares > 10:\n",
    "        #     continue\n",
    "\n",
    "        classified_squares = (feature_labels[func_name][threshold][idx] == 1).nonzero()\n",
    "        linear_probe_vector = t.zeros(linear_probe_MDRRC.shape[1]).to(device)\n",
    "        random_linear_probe_vector = t.zeros(linear_probe_MDRRC.shape[1]).to(device)\n",
    "        random_vector = t.randn(linear_probe_MDRRC.shape[1]).to(device)\n",
    "\n",
    "        for square in classified_squares:\n",
    "            # print(square)\n",
    "            linear_probe_vector += (\n",
    "                linear_probe_MDRRC[0, :, square[0], square[1], square[2]]\n",
    "                / linear_probe_MDRRC[0, :, square[0], square[1], square[2]].norm()\n",
    "            )\n",
    "\n",
    "            random_square = t.randint(0, R1, (2,))\n",
    "            random_class = t.randint(0, C, (1,))\n",
    "            random_linear_probe_vector += (\n",
    "                linear_probe_MDRRC[0, :, random_square[0], random_square[1], random_class[0]]\n",
    "                / linear_probe_MDRRC[\n",
    "                    0, :, random_square[0], random_square[1], random_class[0]\n",
    "                ].norm()\n",
    "            )\n",
    "\n",
    "        decoder_vector = decoder_weights[:, feat_idx]\n",
    "\n",
    "        cos_sim_true = F.cosine_similarity(\n",
    "            linear_probe_vector.squeeze(), decoder_vector.squeeze(), dim=0\n",
    "        )\n",
    "        cos_sim_random1 = F.cosine_similarity(\n",
    "            random_linear_probe_vector.squeeze(), decoder_vector.squeeze(), dim=0\n",
    "        )\n",
    "        cos_sim_random2 = F.cosine_similarity(\n",
    "            random_vector.squeeze(), decoder_vector.squeeze(), dim=0\n",
    "        )\n",
    "\n",
    "        cos_sims_true.append((cos_sim_true.item(), num_classified_squares))\n",
    "        cos_sims_random1.append((cos_sim_random1.item(), num_classified_squares))\n",
    "        cos_sims_random2.append((cos_sim_random2.item(), num_classified_squares))\n",
    "\n",
    "    print(len(cos_sims_true))\n",
    "    # print(\"Cosine Similarity True:\", sum(cos_sims_true) / len(cos_sims_true))\n",
    "    # print(\"Cosine Similarity Random1:\", sum(cos_sims_random1) / len(cos_sims_random1))\n",
    "    # print(\"Cosine Similarity Random2:\", sum(cos_sims_random2) / len(cos_sims_random2))\n",
    "\n",
    "    return cos_sims_true, cos_sims_random1, cos_sims_random2\n",
    "\n",
    "\n",
    "def get_all_cos_sim_results(\n",
    "    autoencoder_group_paths: list[str],\n",
    "    linear_probe_dict_MDRRC: dict[str, t.Tensor],\n",
    "    df: pd.DataFrame,\n",
    "    high_threshold: float,\n",
    "    custom_functions: list[Callable],\n",
    "    idx_columns: list[str],\n",
    "    filename_filter: str = \"1000_\",\n",
    "    max_square_group_size: int = 30,\n",
    ") -> dict:\n",
    "    \"\"\"I'm not a big fan of how nested this function is, but it works for now and I'm just using it for exploration.\n",
    "    all_results is a nested dictionary with the following structure:\n",
    "    {\n",
    "        autoencoder_group_path: {\n",
    "            average_cos_sim_true: {\n",
    "                autoencoder_path: {\n",
    "                    func_name: {\n",
    "                        idx_column: float\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            all_cos_sims_true: {\n",
    "                autoencoder_path: {\n",
    "                    func_name: {\n",
    "                        idx_column: list[tuple[float, int]]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            ... for average_cos_sim_random_1, average_cos_sim_random2, all_cos_sims_random1, all_cos_sims_random2\n",
    "        }\"\"\"\n",
    "    all_results = {}\n",
    "\n",
    "    indexed_df = df.set_index(\"autoencoder_path\", inplace=False)\n",
    "\n",
    "    for ae_group_path in autoencoder_group_paths:\n",
    "\n",
    "        folders = eval_sae.get_nested_folders(ae_group_path)\n",
    "        print(folders)\n",
    "\n",
    "        group_results = {\n",
    "            \"average_cos_sim_true\": {},\n",
    "            \"average_cos_sim_random_1\": {},\n",
    "            \"average_cos_sim_random2\": {},\n",
    "            \"all_cos_sims_true\": {},\n",
    "            \"all_cos_sims_random1\": {},\n",
    "            \"all_cos_sims_random2\": {},\n",
    "        }\n",
    "\n",
    "        for autoencoder_path in folders:\n",
    "            print(autoencoder_path)\n",
    "            ae = get_ae(autoencoder_path)\n",
    "            feature_labels = get_feature_labels(\n",
    "                autoencoder_path, high_threshold, filename_filter, device\n",
    "            )\n",
    "\n",
    "            for results_dict in group_results:\n",
    "                group_results[results_dict][autoencoder_path] = {}\n",
    "\n",
    "            for function in custom_functions:\n",
    "                func_name = function.__name__\n",
    "                linear_probe_MDRRC = linear_probe_dict_MDRRC[func_name]\n",
    "\n",
    "                for results_dict in group_results:\n",
    "                    group_results[results_dict][autoencoder_path][func_name] = {}\n",
    "\n",
    "                for idx_column_ending in idx_columns:\n",
    "\n",
    "                    idx_column = func_name + idx_column_ending\n",
    "\n",
    "                    best_idx = indexed_df.at[autoencoder_path, idx_column]\n",
    "\n",
    "                    assert (\n",
    "                        func_name in feature_labels\n",
    "                    ), f\"Function {func_name} not found in feature labels\"\n",
    "\n",
    "                    cos_sims_true, cos_sims_random1, cos_sims_random2 = get_cos_sims(\n",
    "                        ae, feature_labels, func_name, best_idx, linear_probe_MDRRC\n",
    "                    )\n",
    "\n",
    "                    # if len(cos_sims_true) < max_square_group_size:\n",
    "                    #     continue\n",
    "\n",
    "                    group_results[\"all_cos_sims_true\"][autoencoder_path][func_name][idx_column] = cos_sims_true\n",
    "                    group_results[\"all_cos_sims_random1\"][autoencoder_path][func_name][\n",
    "                        idx_column\n",
    "                    ] = cos_sims_random1\n",
    "                    group_results[\"all_cos_sims_random2\"][autoencoder_path][func_name][\n",
    "                        idx_column\n",
    "                    ] = cos_sims_random2\n",
    "\n",
    "                    group_results[\"average_cos_sim_true\"][autoencoder_path][func_name][idx_column] = (\n",
    "                        get_average_from_list_of_tuples(cos_sims_true)\n",
    "                    )\n",
    "                    group_results[\"average_cos_sim_random_1\"][autoencoder_path][func_name][idx_column] = (\n",
    "                        get_average_from_list_of_tuples(cos_sims_random1)\n",
    "                    )\n",
    "                    group_results[\"average_cos_sim_random2\"][autoencoder_path][func_name][idx_column] = (\n",
    "                        get_average_from_list_of_tuples(cos_sims_random2)\n",
    "                    )\n",
    "\n",
    "        all_results[ae_group_path] = group_results\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_group_paths = [\"../autoencoders/chess_layer5_large_sweep/\"]\n",
    "ae_group_paths = [\n",
    "    # \"../autoencoders/group-2024-05-14_chess/group-2024-05-14_chess-gated/\",\n",
    "    \"../autoencoders/group-2024-05-14_chess/group-2024-05-14_chess-standard/\",\n",
    "    # \"../autoencoders/group-2024-05-14_chess/group-2024-05-14_chess-p_anneal/\",\n",
    "    # \"../autoencoders/group-2024-05-14_chess/group-2024-05-14_chess-gated_anneal/\",\n",
    "]\n",
    "ae_group_paths = [\n",
    "    \"../autoencoders/othello_5-21/othello-gated/\",\n",
    "    \"../autoencoders/othello_5-21/othello-standard/\",\n",
    "    \"../autoencoders/othello_5-21/othello-p_anneal/\",\n",
    "    \"../autoencoders/othello_5-21/othello-gated_anneal/\",\n",
    "]\n",
    "\n",
    "# ae_group_paths = [\"../autoencoders/othello_layer0/\"]\n",
    "\n",
    "def get_linear_probe_dict(custom_functions: list[Callable]) -> dict[str, t.Tensor]:\n",
    "\n",
    "    linear_probe_path_lookup = {\n",
    "        chess_utils.board_to_piece_state.__name__: \"tf_lens_lichess_8layers_ckpt_no_optimizer_chess_piece_probe_layer_5.pth\",\n",
    "        othello_utils.games_batch_to_state_stack_mine_yours_BLRRC.__name__: \"Othello-GPT-Transformer-Lens_othello_mine_yours_probe_layer_5.pth\",\n",
    "        othello_utils.games_batch_to_state_stack_mine_yours_blank_mask_BLRRC.__name__: \"Othello-GPT-Transformer-Lens_othello_mine_yours_probe_layer_5.pth\",\n",
    "        othello_utils.games_batch_to_valid_moves_BLRRC.__name__: \"Othello-GPT-Transformer-Lens_othello_valid_moves_probe_layer_5.pth\",\n",
    "    }\n",
    "\n",
    "    linear_probe_dict_MDRRC = {}\n",
    "    for function in custom_functions:\n",
    "        func_name = function.__name__\n",
    "        linear_probe_path = \"../linear_probes/\" + linear_probe_path_lookup[func_name]\n",
    "        linear_probe_dict_MDRRC[func_name] = get_linear_probe_MDRRC(linear_probe_path)\n",
    "\n",
    "        # Because the valid moves probe has 2 columns, we need to remove the first column\n",
    "        if function == othello_utils.games_batch_to_valid_moves_BLRRC:\n",
    "            linear_probe_dict_MDRRC[func_name] = linear_probe_dict_MDRRC[func_name][..., 1].unsqueeze(-1)\n",
    "    return linear_probe_dict_MDRRC\n",
    "\n",
    "custom_functions = [othello_utils.games_batch_to_state_stack_mine_yours_BLRRC, othello_utils.games_batch_to_valid_moves_BLRRC]\n",
    "# custom_functions = [othello_utils.games_batch_to_valid_moves_BLRRC]\n",
    "idx_columns = [\"_best_idx\"]\n",
    "linear_probe_dict_MDRRC = get_linear_probe_dict(custom_functions)\n",
    "\n",
    "threshold = 0.95\n",
    "\n",
    "filename = \"../autoencoders/group-2024-05-14_chess/chess_5_23_f1_results.csv\"\n",
    "filename = \"../autoencoders/othello_5-21/othello_f1_results.csv\"\n",
    "# filename = \"../autoencoders/othello_layer0/f1_results.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "all_results = get_all_cos_sim_results(ae_group_paths, linear_probe_dict_MDRRC, df, threshold, custom_functions, idx_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dataframe_with_cosine_sim(\n",
    "    df: pd.DataFrame,\n",
    "    all_results: dict,\n",
    "    idx_columns: list[str],\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    cos_sim_key = \"average_cos_sim_true\"\n",
    "    \n",
    "    assert df[\"autoencoder_path\"].is_unique\n",
    "    updates = []\n",
    "\n",
    "    for ae_group_path in all_results:\n",
    "        for autoencoder_path in all_results[ae_group_path][cos_sim_key]:\n",
    "            update_dict = {\"autoencoder_path\": autoencoder_path}\n",
    "            for func_name in all_results[ae_group_path][cos_sim_key][autoencoder_path]:\n",
    "                for idx_column_ending in idx_columns:\n",
    "                    idx_column = func_name + idx_column_ending\n",
    "                    df_cos_sim_column = func_name + idx_column_ending + \"_cos_sim\"\n",
    "                    update_dict[df_cos_sim_column] = all_results[ae_group_path][cos_sim_key][autoencoder_path][func_name][idx_column]\n",
    "\n",
    "            updates.append(update_dict)\n",
    "\n",
    "    update_df = pd.DataFrame(updates)\n",
    "    df = pd.merge(df, update_df, on=\"autoencoder_path\", how=\"outer\")\n",
    "    assert df[\"autoencoder_path\"].is_unique\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../autoencoders/group-2024-05-14_chess/chess_5_23_f1_results.csv\"\n",
    "filename = \"../autoencoders/othello_5-21/othello_f1_results.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "func_name = custom_functions[0].__name__\n",
    "\n",
    "top_k_f1 = 20\n",
    "\n",
    "column_name = f\"{func_name}_best_f1_score_per_square\"\n",
    "top_k_paths = df.nlargest(top_k_f1, column_name)['autoencoder_path']\n",
    "print(top_k_paths.to_list())\n",
    "\n",
    "best_ae_types = {}\n",
    "\n",
    "for path in top_k_paths:\n",
    "    for ae_type in ae_group_paths:\n",
    "        if ae_type in path and ae_type not in best_ae_types:\n",
    "            best_ae_types[ae_type] = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def create_histogram(\n",
    "    hist_list: list[float],\n",
    "    max_square_count: int,\n",
    "    group_name: str,\n",
    "    trainer_nums: list[str],\n",
    "    title: str,\n",
    "    full_title: Optional[str] = None,\n",
    "):\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(hist_list, bins=20, color=\"blue\", alpha=0.7, edgecolor=\"black\")\n",
    "    if full_title is not None:\n",
    "        plt.title(full_title)\n",
    "    else:\n",
    "        plt.title(\n",
    "            f\"{title } Maximum square count: {max_square_count} {group_name} trainers: {trainer_nums}\"\n",
    "        )\n",
    "    \n",
    "    # plt.xlim(-0.15, 1)\n",
    "    plt.xlabel(\"Cosine Similarity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for ae_type in ae_group_paths:\n",
    "\n",
    "    hist_list = []\n",
    "\n",
    "    sort_metric = \"average_cos_sim_true\"\n",
    "    func_name = custom_functions[0].__name__\n",
    "\n",
    "    metric = \"all_cos_sims_true\"\n",
    "    # metric = \"all_cos_sims_random1\"\n",
    "    \n",
    "    idx_name = func_name + idx_columns[0]\n",
    "\n",
    "    hist_list = []\n",
    "\n",
    "    max_val = 0\n",
    "    for i, ae_path in enumerate(all_results[ae_type][sort_metric]):\n",
    "        cos_sim = all_results[ae_type][sort_metric][ae_path][func_name][idx_name]\n",
    "        max_val = max(max_val, cos_sim)\n",
    "        hist_list.append(cos_sim)\n",
    "    print(max_val)\n",
    "\n",
    "    top_k = 5\n",
    "    max_square_count = 30\n",
    "\n",
    "    sorted_ae_paths = sorted(\n",
    "        all_results[ae_type][sort_metric],\n",
    "        key=lambda x: all_results[ae_type][sort_metric][x][func_name][idx_name],\n",
    "        reverse=True,\n",
    "    )\n",
    "    print(sorted_ae_paths[:top_k])\n",
    "\n",
    "    hist_list = []\n",
    "\n",
    "    trainer_nums = []\n",
    "\n",
    "    for i, ae_path in enumerate(sorted_ae_paths[:top_k]):\n",
    "        trainer_nums.append(ae_path.split(\"/\")[-2])\n",
    "        cos_sim = all_results[ae_type][metric][ae_path][func_name][idx_name]\n",
    "        # hist_list.append(cos_sim)\n",
    "        hist_list.extend(cos_sim)\n",
    "\n",
    "    if type(hist_list[0]) == tuple:\n",
    "        temp_hist_list = []\n",
    "\n",
    "        for cos_sims in hist_list:\n",
    "            if cos_sims[1] <= max_square_count:\n",
    "                temp_hist_list.append(cos_sims[0])\n",
    "        hist_list = temp_hist_list\n",
    "\n",
    "    # for cos_sims in all_cos_sims_true:\n",
    "    # # for cos_sims in all_cos_sims_random1:\n",
    "    #     if cos_sims[1] < 201:\n",
    "    #         hist_list.append(cos_sims[0])\n",
    "\n",
    "    # hist_list = all_results[ae_group_paths[group]][0]\n",
    "\n",
    "    create_histogram(\n",
    "        hist_list, max_square_count, ae_type.split(\"/\")[-2], trainer_nums, \"Best cos sims\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "max_square_count = 5\n",
    "top_k_f1 = 50\n",
    "column_name = f\"{func_name}_best_f1_score_per_square\"\n",
    "column_name = f\"{func_name}_best_average_f1\"\n",
    "\n",
    "top_k_paths = df.nlargest(top_k_f1, column_name)[\"autoencoder_path\"]\n",
    "print(top_k_paths.to_list())\n",
    "\n",
    "best_ae_types = {}\n",
    "\n",
    "for path in top_k_paths:\n",
    "    for ae_type in ae_group_paths:\n",
    "        if ae_type in path and ae_type not in best_ae_types:\n",
    "            best_ae_types[ae_type] = path\n",
    "\n",
    "group = 0\n",
    "metric = 3\n",
    "\n",
    "sort_metric = \"average_cos_sim_true\"\n",
    "func_name = custom_functions[0].__name__\n",
    "\n",
    "metric = \"all_cos_sims_true\"\n",
    "# metric = \"all_cos_sims_random1\"\n",
    "\n",
    "idx_name = func_name + idx_columns[0]\n",
    "\n",
    "\n",
    "for ae_type in best_ae_types:\n",
    "    hist_list = all_results[ae_type][metric][best_ae_types[ae_type]][func_name][idx_name]\n",
    "\n",
    "    if type(hist_list[0]) == tuple:\n",
    "        temp_hist_list = []\n",
    "\n",
    "        for cos_sims in hist_list:\n",
    "            if cos_sims[1] <= max_square_count:\n",
    "                temp_hist_list.append(cos_sims[0])\n",
    "        hist_list = temp_hist_list\n",
    "\n",
    "    trainer_nums = [best_ae_types[ae_type].split(\"/\")[-2]]\n",
    "\n",
    "    full_title = (\n",
    "        \"Cosine similarity for OthelloGPT board state random linear probe vectors in SAE with highest board reconstruction\"\n",
    "    )\n",
    "    full_title = None\n",
    "    create_histogram(\n",
    "        hist_list,\n",
    "        max_square_count,\n",
    "        ae_type.split(\"/\")[-2],\n",
    "        trainer_nums,\n",
    "        \"Cos sim for best board reconstruction\",\n",
    "        full_title=full_title,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cosine Similarity True:\", sum(cos_sims_true) / len(cos_sims_true))\n",
    "print(\"Cosine Similarity Random1:\", sum(cos_sims_random1) / len(cos_sims_random1))\n",
    "print(\"Cosine Similarity Random2:\", sum(cos_sims_random2) / len(cos_sims_random2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load SAE\n",
    "ae_path = '../autoencoders/chess_layer5_large_sweep/ef=16_lr=1e-03_l1=3e-02_layer_5'\n",
    "ae_path = '../autoencoders/chess_layer5_large_sweep/ef=4_lr=1e-03_l1=1e-01_layer_5'\n",
    "ae = AutoEncoder.from_pretrained(os.path.join(ae_path, 'ae.pt'), device='cuda:0')\n",
    "\n",
    "# load information about features\n",
    "with open(os.path.join(ae_path, 'indexing_find_dots_indices_n_inputs_1000_results.pkl'), 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "def to_device(d, device=device):\n",
    "    if isinstance(d, t.Tensor):\n",
    "        return d.to(device)\n",
    "    if isinstance(d, dict):\n",
    "        return {k: to_device(v, device) for k, v in d.items()}\n",
    "results = to_device(results)\n",
    "\n",
    "feature_labels, misc_stats = analysis.analyze_results_dict(results, \"\", device, high_threshold=0.95, save_results=False, print_results=False, verbose=False, mask=True)\n",
    "\n",
    "start = 0\n",
    "for idx in range(start, start + 600):\n",
    "    feat_idx = feature_labels['alive_features'][idx]\n",
    "    # print(feat_idx)\n",
    "\n",
    "    best_idx = 1\n",
    "\n",
    "    print(f\"\\n{idx}\")\n",
    "    # print(\"Board states that the feature classifies according to Adam's measurements:\")\n",
    "    print((feature_labels['board_to_piece_state'][best_idx][idx] > .95).nonzero())\n",
    "    # print(\"Number of such board states:\")\n",
    "    # print(results['board_to_piece_state'].shape)\n",
    "    print((feature_labels['board_to_piece_state'][best_idx][idx] > .95).sum())\n",
    "\n",
    "    # print(results['thresholds'].shape)\n",
    "    # print(results['thresholds'][best_idx][idx])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set idx to be the index of the (alive) feature you want to visualize\n",
    "idx = 1436\n",
    "idx = 18\n",
    "feat_idx = feature_labels['alive_features'][idx]\n",
    "print(feat_idx)\n",
    "\n",
    "best_idx = 1\n",
    "\n",
    "print(\"Board states that the feature classifies according to Adam's measurements:\")\n",
    "print((feature_labels['board_to_piece_state'][best_idx][idx] > .95).nonzero())\n",
    "\n",
    "labels = (feature_labels['board_to_piece_state'][best_idx][idx] > .95).nonzero()\n",
    "\n",
    "print(\"Number of such board states:\")\n",
    "print(feature_labels['board_to_piece_state'].shape)\n",
    "print((feature_labels['board_to_piece_state'][best_idx][idx] > .95).sum())\n",
    "\n",
    "print(feature_labels['thresholds'].shape)\n",
    "print(feature_labels['thresholds'][best_idx][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "linear_probe_path = \"../linear_probes/tf_lens_lichess_8layers_ckpt_no_optimizer_chess_piece_probe_layer_5.pth\"\n",
    "\n",
    "with open(linear_probe_path, \"rb\") as f:\n",
    "    state_dict = t.load(f, map_location=device)\n",
    "    print(state_dict.keys())\n",
    "    linear_probe_MDRRC = state_dict[\"linear_probe\"]\n",
    "\n",
    "linear_probe_vector = t.zeros(linear_probe_MDRRC.shape[1]).to(device)\n",
    "\n",
    "for label in labels:\n",
    "    print(label)\n",
    "    linear_probe_vector += linear_probe_MDRRC[0, :, label[0], label[1], label[2]]\n",
    "    linear_probe_vector += linear_probe_MDRRC[0, :, label[0], label[1], 1]\n",
    "    linear_probe_vector += linear_probe_MDRRC[0, :, label[0] + 1, label[1], label[2]]\n",
    "\n",
    "\n",
    "decoder_weights = ae.decoder.weight.data\n",
    "\n",
    "d_model, hidden_dim = decoder_weights.shape\n",
    "\n",
    "max_cosine_similarity = 0\n",
    "\n",
    "print(\"Hidden Dim:\", hidden_dim)\n",
    "for i in range(hidden_dim):\n",
    "    \n",
    "\n",
    "    decoder_vector = decoder_weights[:, i].to(device)\n",
    "\n",
    "    # Calculate norms\n",
    "    norm_linear_probe_vector = linear_probe_vector.norm()\n",
    "    norm_decoder_vector = decoder_vector.norm()\n",
    "\n",
    "    # Print norms\n",
    "    # print(\"Norm of linear probe vector:\", norm_linear_probe_vector.item())\n",
    "    # print(\"Norm of decoder vector:\", norm_decoder_vector.item())\n",
    "\n",
    "\n",
    "    cos_sim = F.cosine_similarity(linear_probe_vector.unsqueeze(0), decoder_vector.unsqueeze(0), dim=1)\n",
    "    # print(\"Cosine similarity:\", cos_sim.item())\n",
    "    max_cosine_similarity = max(max_cosine_similarity, cos_sim.item())\n",
    "\n",
    "cosine_similarities = []\n",
    "\n",
    "for i in range(hidden_dim):\n",
    "    decoder_vector = decoder_weights[:, i].to(device)\n",
    "\n",
    "    # Calculate the cosine similarity\n",
    "    cos_sim = F.cosine_similarity(linear_probe_vector.unsqueeze(0), decoder_vector.unsqueeze(0), dim=1).item()\n",
    "    cosine_similarities.append((i, cos_sim))\n",
    "\n",
    "# Get the top 10 cosine similarities\n",
    "top_10_cosine_similarities = sorted(cosine_similarities, key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "# Calculate the average cosine similarity\n",
    "average_cosine_similarity = sum(sim[1] for sim in cosine_similarities) / len(cosine_similarities)\n",
    "\n",
    "# Print the top 10 and average cosine similarities\n",
    "print(\"Top 10 Cosine Similarities:\", top_10_cosine_similarities)\n",
    "print(\"Average Cosine Similarity:\", average_cosine_similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine sim 2 color histogram over SAEs x axis is the cosine similarity, y axis is the number of features that have that cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_cos_sims = []\n",
    "for i in range(1000):\n",
    "    random_vector_1 = t.randn((512,)).to(device)\n",
    "    random_vector_2 = t.randn((512,)).to(device)\n",
    "    cos_sim = F.cosine_similarity(random_vector_1.unsqueeze(0), random_vector_2.unsqueeze(0), dim=1).item()\n",
    "    random_cos_sims.append(cos_sim)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(random_cos_sims, bins=20, color='blue', alpha=0.7, edgecolor='black')\n",
    "plt.title(f'Histogram of Cosine Similarities {ae_group_paths[group]}')\n",
    "plt.xlim(-0.15, 1)\n",
    "plt.xlabel('Cosine Similarity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
