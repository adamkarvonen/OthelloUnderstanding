{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight import LanguageModel\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import chess\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dictionary_learning import ActivationBuffer\n",
    "from nanogpt_to_hf_transformers import NanogptTokenizer, convert_nanogpt_model\n",
    "from dictionary_learning.utils import hf_dataset_to_generator\n",
    "from dictionary_learning import AutoEncoder\n",
    "\n",
    "import chess_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chess_utils.piece_config.custom_board_state_function.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Load the model, dictionary, data, and activation buffers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_PATH = \"../models/lichess_8layers_ckpt_no_optimizer.pt\"\n",
    "batch_size = 8\n",
    "\n",
    "autoencoder_path = \"../autoencoders/ef4_20k_resample/ef=4_lr=1e-03_l1=5e-02_layer=5/\"\n",
    "\n",
    "autoencoder_model_path = f\"{autoencoder_path}ae.pt\"\n",
    "autoencoder_config_path = f\"{autoencoder_path}config.json\"\n",
    "ae = AutoEncoder.from_pretrained(autoencoder_model_path, device=DEVICE)\n",
    "\n",
    "with open(autoencoder_config_path, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "context_length = config[\"buffer\"][\"ctx_len\"]\n",
    "layer = config[\"trainer\"][\"layer\"]\n",
    "\n",
    "tokenizer = NanogptTokenizer(meta_path=\"../models/meta.pkl\")\n",
    "model = convert_nanogpt_model(MODEL_PATH, torch.device(DEVICE))\n",
    "model = LanguageModel(model, device_map=DEVICE, tokenizer=tokenizer).to(DEVICE)\n",
    "\n",
    "submodule = model.transformer.h[layer].mlp  # layer 1 MLP\n",
    "activation_dim = config[\"trainer\"][\"activation_dim\"]  # output dimension of the MLP\n",
    "dictionary_size = config[\"trainer\"][\"dictionary_size\"]\n",
    "\n",
    "# chess_sae_test is 100MB of data, so no big deal to download it\n",
    "data = hf_dataset_to_generator(\"adamkarvonen/chess_sae_test\", streaming=False)\n",
    "buffer = ActivationBuffer(\n",
    "    data,\n",
    "    model,\n",
    "    submodule,\n",
    "    n_ctxs=512,\n",
    "    ctx_len=context_length,\n",
    "    refresh_batch_size=4,\n",
    "    io=\"out\",\n",
    "    d_submodule=activation_dim,\n",
    "    device=DEVICE,\n",
    "    out_batch_size=batch_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect feature activations on total_inputs inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_feature(\n",
    "    activations,\n",
    "    ae: AutoEncoder,\n",
    "    device,\n",
    "):\n",
    "    try:\n",
    "        x = next(activations).to(device)\n",
    "    except StopIteration:\n",
    "        raise StopIteration(\n",
    "            \"Not enough activations in buffer. Pass a buffer with a smaller batch size or more data.\"\n",
    "        )\n",
    "\n",
    "    x_hat, f = ae(x, output_features=True)\n",
    "\n",
    "    return f\n",
    "\n",
    "total_inputs = 8192\n",
    "assert total_inputs % batch_size == 0\n",
    "num_iters = total_inputs // batch_size\n",
    "\n",
    "features = torch.zeros((total_inputs, dictionary_size), device=DEVICE)\n",
    "for i in tqdm(range(num_iters), total=num_iters, desc=\"Extracting features\"):\n",
    "    feature = get_feature(buffer, ae, DEVICE) # (batch_size, dictionary_size)\n",
    "    features[i*batch_size:(i+1)*batch_size, :] = feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few plots about various statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firing_rate_per_feature = (features != 0).float().sum(dim=0).cpu() / total_inputs\n",
    "\n",
    "# Creating the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(firing_rate_per_feature, bins=50, alpha=0.75, color='blue')\n",
    "plt.title('Histogram of firing rates for features')\n",
    "plt.xlabel('Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "firing_rate_per_input = (features != 0).float().sum(dim=-1).cpu() / total_inputs\n",
    "\n",
    "# Creating the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(firing_rate_per_input, bins=50, alpha=0.75, color='blue')\n",
    "plt.title('Percentage of features firing per input')\n",
    "plt.xlabel('Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got this from: https://colab.research.google.com/drive/19Qo9wj5rGLjb6KsB9NkKNJkMiHcQhLqo?usp=sharing#scrollTo=WZMhAzLTvw-u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_prob = features.mean(0)\n",
    "print(feat_prob.shape)\n",
    "log_freq = (feat_prob + 1e-10).log10()\n",
    "print(log_freq.shape)\n",
    "\n",
    "log_freq_np = log_freq.cpu().numpy()\n",
    "\n",
    "# Creating the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(log_freq_np, bins=50, alpha=0.75, color='blue')\n",
    "plt.title('Histogram of log10 of Feature Probabilities')\n",
    "plt.xlabel('log10(Probability)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the L0 statistic. Then, get a list of indices for features that fire between 0 and 50% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features.shape)\n",
    "l0 = (features != 0).float().sum(dim=-1).mean()\n",
    "print(f\"l0: {l0}\")\n",
    "\n",
    "firing_rate_per_feature = (features != 0).float().sum(dim=0) / total_inputs\n",
    "\n",
    "assert firing_rate_per_feature.shape[0] == dictionary_size\n",
    "\n",
    "mask = (firing_rate_per_feature > 0) & (firing_rate_per_feature < 0.5)\n",
    "idx = torch.nonzero(mask, as_tuple=False).squeeze()\n",
    "print(idx.shape)\n",
    "print(f\"\\n\\nWe have {idx.shape[0]} features that fire between 0 and 50% of the time.\")\n",
    "print(idx[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we collect per dim stats, which include the top tokens it fires on, and the top k inputs and activations per input token.\n",
    "\n",
    "Rough ballpark times on my RTX 3050: \n",
    "\n",
    "2000 dims, 3000 inputs, batch size 50 = 42 seconds\n",
    "\n",
    "Note that I perform the activation processing on my CPU. This is comparable speed, but much lower VRAM usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import chess_interp\n",
    "importlib.reload(chess_interp)\n",
    "\n",
    "\n",
    "per_dim_stats = chess_interp.examine_dimension_chess(model, submodule, buffer, dictionary=ae, dims=idx[:], n_inputs=3000, k=30, batch_size=50, processing_device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell looks at syntax related features. Specifically, it looks for features that always fire on a PGN \"counting number\". In this PGN, I've wrapped the \"counting numbers\" in brackets.\n",
    "\n",
    ";<1.>e4 e5 <2.>Nf3 ...\n",
    "\n",
    "We can easily analyze different syntax related attributes by just passing in a different syntax function, such as one that just finds space indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(chess_utils)\n",
    "\n",
    "\n",
    "def syntax_analysis(per_dim_stats: dict, minimum_number_of_activations: int, top_k: int, max_dims: int, syntax_function: callable, verbose: bool = False) -> dict:\n",
    "\n",
    "    nonzero_count = 0\n",
    "    syntax_match_idx_count = 0\n",
    "    dim_count = 0\n",
    "    average_input_length = 0\n",
    "    length_tracker = []\n",
    "\n",
    "    for dim in per_dim_stats:\n",
    "        dim_count += 1\n",
    "        if dim_count > max_dims:\n",
    "            break\n",
    "\n",
    "        decoded_tokens = per_dim_stats[dim]['decoded_tokens']\n",
    "        activations = per_dim_stats[dim]['activations']\n",
    "        # If the dim doesn't have at least 10 firing activations, skip it\n",
    "        if activations[minimum_number_of_activations][-1].item() == 0:\n",
    "            continue\n",
    "        nonzero_count += 1\n",
    "\n",
    "        inputs = [\"\".join(string) for string in decoded_tokens]\n",
    "        inputs = inputs[:top_k]\n",
    "        \n",
    "        num_indices = []\n",
    "        count = 0\n",
    "        for i, pgn in enumerate(inputs[:top_k]):\n",
    "            # NOTE: Uncomment this line to view examples of common indices\n",
    "            # print(f\"dim: {dim} pgn: {pgn}, activation: {activations[i][-1].item()}\")\n",
    "            nums = syntax_function(pgn)\n",
    "            num_indices.append(nums)\n",
    "\n",
    "            # If the last token (which contains the max activation for that context) is a number\n",
    "            # Then we count this firing as a \"number index firing\"\n",
    "            if (len(pgn) - 1) in nums:\n",
    "                count += 1\n",
    "                average_input_length = sum(len(pgn) for pgn in inputs) / len(inputs)\n",
    "                length_tracker.append(average_input_length)\n",
    "                \n",
    "        if count == top_k:\n",
    "            # print(f\"All top {top_k} activations in dim: {dim} are on num indices\")\n",
    "            syntax_match_idx_count += 1\n",
    "\n",
    "    total_average_length = -1\n",
    "    if len(length_tracker) > 0:\n",
    "        total_average_length = sum(length_tracker) / len(length_tracker)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Out of {len(per_dim_stats)} features, {nonzero_count} had at least {minimum_number_of_activations} activations.\")\n",
    "        print(f\"{syntax_match_idx_count} features matched on all top {top_k} inputs for our syntax function {syntax_function.__name__}\")\n",
    "        print(f\"The average length of inputs of pattern matching features was {total_average_length}\")\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    results['dim_count'] = dim_count\n",
    "    results['nonzero_count'] = nonzero_count\n",
    "    results['syntax_match_idx_count'] = syntax_match_idx_count\n",
    "    results['average_input_length'] = total_average_length\n",
    "\n",
    "    return results\n",
    "\n",
    "syntax_analysis(per_dim_stats, 20, 20, 2500, chess_utils.find_num_indices, verbose=True)\n",
    "syntax_analysis(per_dim_stats, 20, 20, 2500, chess_utils.find_spaces_indices, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(chess_utils)\n",
    "from chess_utils import Config\n",
    "\n",
    "\n",
    "def board_analysis(\n",
    "    per_dim_stats: dict,\n",
    "    minimum_number_of_activations: int,\n",
    "    top_k: int,\n",
    "    max_dims: int,\n",
    "    threshold: float,\n",
    "    configs: list[Config],\n",
    "    device: str = \"cpu\",\n",
    "    verbose: bool = False,\n",
    ") -> dict:\n",
    "\n",
    "    nonzero_count = 0\n",
    "    dim_count = 0\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for config in configs:\n",
    "        board_tracker = torch.zeros(config.num_rows, config.num_cols, device=device)\n",
    "        num_classes = abs(config.min_val) + abs(config.max_val) + 1\n",
    "        per_class_dict = {key: 0 for key in range(0, num_classes)}\n",
    "\n",
    "        results[config.custom_board_state_function.__name__] = {\n",
    "            \"pattern_match_count\": 0,\n",
    "            \"total_average_length\": 0,\n",
    "            \"average_matches_per_dim\": 0,\n",
    "            \"per_class_dict\": per_class_dict,\n",
    "            \"board_tracker\": board_tracker,\n",
    "        }\n",
    "\n",
    "    for dim in tqdm(per_dim_stats, total=len(per_dim_stats), desc=\"Processing chess pgn strings\"):\n",
    "        dim_count += 1\n",
    "        if dim_count > max_dims:\n",
    "            break\n",
    "\n",
    "        decoded_tokens = per_dim_stats[dim][\"decoded_tokens\"]\n",
    "        activations = per_dim_stats[dim][\"activations\"]\n",
    "        # If the dim doesn't have at least minimum_number_of_activations firing activations, skip it\n",
    "        if activations[minimum_number_of_activations][-1].item() == 0:\n",
    "            continue\n",
    "        nonzero_count += 1\n",
    "\n",
    "        inputs = [\"\".join(string) for string in decoded_tokens]\n",
    "        inputs = inputs[:top_k]\n",
    "\n",
    "        num_indices = []\n",
    "        count = 0\n",
    "\n",
    "        chess_boards = [\n",
    "            chess_utils.pgn_string_to_board(pgn, allow_exception=True) for pgn in inputs\n",
    "        ]\n",
    "\n",
    "        for config in configs:\n",
    "\n",
    "            config_name = config.custom_board_state_function.__name__\n",
    "\n",
    "            one_hot_list = chess_utils.chess_boards_to_state_stack(chess_boards, device, config)\n",
    "            one_hot_list = chess_utils.mask_initial_board_states(one_hot_list, device, config)\n",
    "            averaged_one_hot = chess_utils.get_averaged_states(one_hot_list)\n",
    "            common_indices = chess_utils.find_common_states(averaged_one_hot, threshold)\n",
    "\n",
    "            if any(len(idx) > 0 for idx in common_indices):\n",
    "                results[config_name][\n",
    "                    \"pattern_match_count\"\n",
    "                ] += 1  # Increment if there are nonzero indices\n",
    "                average_input_length = sum(len(pgn) for pgn in inputs) / len(inputs)\n",
    "                results[config_name][\"total_average_length\"] += average_input_length\n",
    "\n",
    "            if config.num_rows == 8:\n",
    "                for idx in zip(*common_indices):\n",
    "                    value = averaged_one_hot[idx].item()\n",
    "                    # print(f\"Dim: {dim}, Average input length: {int(average_input_length):04}, Value: {value:.2f} at Index: {idx}\")\n",
    "                    results[config_name][\"board_tracker\"][idx[0], idx[1]] += 1\n",
    "                    results[config_name][\"per_class_dict\"][idx[2].item()] += 1\n",
    "                    results[config_name][\"average_matches_per_dim\"] += 1\n",
    "\n",
    "    for config in configs:\n",
    "        config_name = config.custom_board_state_function.__name__\n",
    "        match_count = results[config_name][\"pattern_match_count\"]\n",
    "        results[config_name][\"dim_count\"] = dim_count\n",
    "        results[config_name][\"nonzero_count\"] = nonzero_count\n",
    "        results[config_name][\"board_tracker\"] = results[config_name][\"board_tracker\"].flip(0).tolist()\n",
    "        if match_count > 0:\n",
    "            results[config_name][\"total_average_length\"] /= match_count\n",
    "            results[config_name][\"average_matches_per_dim\"] /= match_count\n",
    "\n",
    "    if verbose:\n",
    "        for config in configs:\n",
    "            config_name = config.custom_board_state_function.__name__\n",
    "            pattern_match_count = results[config_name][\"pattern_match_count\"]\n",
    "            total_average_length = results[config_name][\"total_average_length\"]\n",
    "            print(f\"\\n{config_name} Results:\")\n",
    "            print(\n",
    "                f\"Out of {dim_count} features, {nonzero_count} had at least {minimum_number_of_activations} activations.\"\n",
    "            )\n",
    "            print(\n",
    "                f\"{pattern_match_count} features matched on all top {top_k} inputs for our board to state function {config_name}\"\n",
    "            )\n",
    "            print(\n",
    "                f\"The average length of inputs of pattern matching features was {total_average_length}\"\n",
    "            )\n",
    "\n",
    "            if config.num_rows == 8:\n",
    "                per_class_dict = results[config_name][\"per_class_dict\"]\n",
    "                print(f\"\\nThe following square states had the following number of occurances:\")\n",
    "                for key, count in per_class_dict.items():\n",
    "                    print(f\"Index: {key}, Count: {count}\")\n",
    "\n",
    "                print(f\"\\nHere are the most common squares:\")\n",
    "                print(results[config_name][\"board_tracker\"])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_analysis(per_dim_stats, 20, 20, 2500, 0.99, [chess_utils.piece_config], device=\"cpu\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_analysis(per_dim_stats, 20, 20, 2500, 0.99, [chess_utils.threat_config], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_analysis(per_dim_stats, 20, 20, 2500, 0.99, [chess_utils.check_config], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_analysis(per_dim_stats, 20, 20, 2500, 0.99, [chess_utils.pin_config], verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "circuits",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
