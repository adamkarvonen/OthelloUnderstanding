{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from typing import Callable, Optional\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import circuits.analysis as analysis\n",
    "import circuits.eval_sae_as_classifier as eval_sae\n",
    "import circuits.utils as utils\n",
    "import circuits.f1_analysis as f1_analysis\n",
    "import circuits.dictionary_learning.dictionary as dictionary\n",
    "from circuits.dictionary_learning.dictionary import AutoEncoder\n",
    "import circuits.chess_utils as chess_utils\n",
    "import circuits.othello_utils as othello_utils\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key for mapping from the last entry of the board state tensor to pieces:\n",
    "* 0 => black king\n",
    "* 1 => black queen\n",
    "* 2 => black rook\n",
    "* 3 => black bishop\n",
    "* 4 => black knight\n",
    "* 5 => black pawn\n",
    "* 6 => empty\n",
    "* 7 => white pawn\n",
    "* 8 => white knight\n",
    "* 9 => white bishop\n",
    "* 10 => white rook\n",
    "* 11 => white queen\n",
    "* 12 => white king"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "d_model = 512  # output dimension of the layer\n",
    "layer = 6\n",
    "\n",
    "othello = True\n",
    "\n",
    "if not othello:\n",
    "    with open(\"models/meta.pkl\", \"rb\") as f:\n",
    "        meta = pickle.load(f)\n",
    "\n",
    "    context_length = 256\n",
    "    model_name = \"adamkarvonen/8LayerChessGPT2\"\n",
    "    model_type = \"chess\"\n",
    "else:\n",
    "    context_length = 59\n",
    "    model_name = \"Baidicoot/Othello-GPT-Transformer-Lens\"\n",
    "    model_type = \"othello\"\n",
    "\n",
    "model = utils.get_model(model_name, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load SAE\n",
    "# ae_path = '../autoencoders/chess_layer5_large_sweep/ef=16_lr=1e-03_l1=3e-02_layer_5'\n",
    "# ae_path = '../autoencoders/chess_layer5_large_sweep/ef=4_lr=1e-03_l1=1e-01_layer_5'\n",
    "\n",
    "ae_path = \"../autoencoders/othello_mlp_acts_identity_aes/layer_3/indexing_None_n_inputs_100_feature_labels.pkl\"\n",
    "\n",
    "def get_feature_labels(autoencoder_path: str, high_threshold: float, filename_filter: str, device):\n",
    "\n",
    "    results_filenames = analysis.get_all_results_file_names(autoencoder_path, filename_filter)\n",
    "    if len(results_filenames) > 1 or len(results_filenames) == 0:\n",
    "        raise ValueError(\"There are multiple results files\")\n",
    "    results_filename = results_filenames[0]\n",
    "\n",
    "    with open(os.path.join(autoencoder_path, results_filename), 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "    results = utils.to_device(results, device)\n",
    "    feature_labels, misc_stats = analysis.analyze_results_dict(results, \"\", device, high_threshold=high_threshold, save_results=False, print_results=False, verbose=False)\n",
    "    return feature_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_board(board_RR: torch.Tensor, title: str = \"Board\", png_filename: Optional[str] = None):\n",
    "    \"\"\"\n",
    "    Plots an 8x8 board with the value of the maximum square displayed in red text to two decimal places.\n",
    "\n",
    "    Args:\n",
    "        board_RR (torch.Tensor): A 2D tensor of shape (8, 8) with values from 0 to 1.\n",
    "        title (str): Title of the plot.\n",
    "    \"\"\"\n",
    "    assert board_RR.shape == (8, 8), \"board_RR must be of shape 8x8\"\n",
    "\n",
    "    # Flip the board vertically\n",
    "    # board_RR = torch.flip(board_RR, [0])\n",
    "\n",
    "    plt.imshow(board_RR, cmap='gray_r', interpolation='none')\n",
    "    plt.colorbar()  # Adds a colorbar to help identify the values\n",
    "    plt.title(title)\n",
    "\n",
    "    # Set labels for columns (A-H)\n",
    "    plt.xticks(range(8), ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'])\n",
    "\n",
    "    # Set labels for rows (1-8)\n",
    "    plt.yticks(range(8), range(8, 0, -1))\n",
    "\n",
    "    # Add gridlines mimicking a chess board\n",
    "    # plt.grid(True, color='black', linewidth=1, linestyle='-', alpha=0.5)\n",
    "    # plt.tick_params(bottom=False, left=False, labelbottom=True, labelleft=True)\n",
    "\n",
    "    # Offset gridlines by 0.5 in x and y\n",
    "    plt.gca().set_xticks([x - 0.5 for x in range(1, 9)], minor=True)\n",
    "    plt.gca().set_yticks([y - 0.51 for y in range(1, 9)], minor=True)\n",
    "    plt.grid(True, which='minor', color='black', linewidth=1, linestyle='-', alpha=0.5)\n",
    "\n",
    "    # Find the maximum value and its position\n",
    "    max_value, max_pos = torch.max(board_RR), torch.argmax(board_RR)\n",
    "    max_i, max_j = torch.div(max_pos, 8, rounding_mode='floor'), max_pos % 8\n",
    "\n",
    "    # Display the maximum value in red text at the corresponding position\n",
    "    plt.text(max_j, max_i, f\"{max_value:.0%}\", color='red', ha='center', va='center', fontsize=12)\n",
    "\n",
    "    # if png_filename is not None:\n",
    "    #     plt.savefig(png_filename)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_probe_MDRRC(linear_probe_path: str) -> torch.Tensor:\n",
    "\n",
    "    with open(linear_probe_path, \"rb\") as f:\n",
    "        state_dict = torch.load(f, map_location=device)\n",
    "        print(state_dict.keys())\n",
    "        linear_probe_MDRRC = state_dict[\"linear_probe\"]\n",
    "    return linear_probe_MDRRC.squeeze()\n",
    "\n",
    "def get_nanda_probe(nanda_probe_path: str) -> torch.Tensor:\n",
    "    with open(nanda_probe_path, \"rb\") as f:\n",
    "        state_dict = torch.load(f, map_location=device)\n",
    "    print(state_dict.shape)\n",
    "\n",
    "\n",
    "    full_linear_probe = state_dict\n",
    "\n",
    "    rows = 8\n",
    "    cols = 8 \n",
    "    options = 3\n",
    "    black_to_play_index = 0\n",
    "    white_to_play_index = 1\n",
    "    blank_index = 0\n",
    "    their_index = 1\n",
    "    my_index = 2\n",
    "    linear_probe = torch.zeros(512, rows, cols, options, device=device)\n",
    "    linear_probe[..., blank_index] = 0.5 * (full_linear_probe[black_to_play_index, ..., 0] + full_linear_probe[white_to_play_index, ..., 0])\n",
    "    linear_probe[..., their_index] = 0.5 * (full_linear_probe[black_to_play_index, ..., 1] + full_linear_probe[white_to_play_index, ..., 2])\n",
    "    linear_probe[..., my_index] = 0.5 * (full_linear_probe[black_to_play_index, ..., 2] + full_linear_probe[white_to_play_index, ..., 1])\n",
    "\n",
    "    return linear_probe\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "linear_probe_path = \"../linear_probes/Othello-GPT-Transformer-Lens_othello_mine_yours_probe_layer_5.pth\"\n",
    "nanda_linear_probe_path = \"../linear_probes/main_linear_probe.pth\"\n",
    "\n",
    "linear_probe_DRRC = get_nanda_probe(nanda_linear_probe_path)\n",
    "linear_probe_DRRC = get_linear_probe_MDRRC(linear_probe_path)\n",
    "\n",
    "layer = 1\n",
    "# print(model)\n",
    "print(model.blocks[layer].mlp.W_out.shape)\n",
    "\n",
    "neuron = 421\n",
    "sample_vector_D = model.blocks[layer].mlp.W_out[neuron]\n",
    "sample_vector_D = model.blocks[layer].mlp.W_out[neuron]\n",
    "\n",
    "probe_out_RRC = einops.einsum(sample_vector_D, linear_probe_DRRC, \"d, d r1 r2 c -> r1 r2 c\").squeeze()\n",
    "print(probe_out_RRC.shape)\n",
    "\n",
    "sample_vector_D111 = einops.rearrange(sample_vector_D, \"d -> d 1 1 1\")\n",
    "\n",
    "# Calculate dot product\n",
    "# dot_product_RRC = torch.sum(sample_vector_D111 * linear_probe_DRRC, dim=0)\n",
    "\n",
    "# # Calculate magnitude of linear probe vectors\n",
    "# linear_probe_magnitude_RRC = torch.norm(linear_probe_DRRC, dim=0)\n",
    "\n",
    "# # Calculate projection\n",
    "# projection_RRC = dot_product_RRC / linear_probe_magnitude_RRC\n",
    "\n",
    "# probe_out_RR = projection_RRC[..., 1]\n",
    "\n",
    "cos_sim_RRC = F.cosine_similarity(sample_vector_D111, linear_probe_DRRC, dim=0)\n",
    "\n",
    "print(cos_sim_RRC.shape)\n",
    "\n",
    "probe_out_RR = cos_sim_RRC[..., 2]\n",
    "\n",
    "# probe_out_RR = probe_out_RRC[..., 2]\n",
    "\n",
    "plot_board(probe_out_RR, title=\"Probe Output\", png_filename=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
