{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from typing import Callable\n",
    "import torch\n",
    "\n",
    "import circuits.eval_sae_as_classifier as eval_sae\n",
    "import circuits.analysis as analysis\n",
    "import circuits.test_board_reconstruction as test_board_reconstruction\n",
    "import circuits.get_eval_results as get_eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For multi-GPU evaluation\n",
    "from collections import deque\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from circuits.utils import to_device\n",
    "\n",
    "N_GPUS = 1\n",
    "RESOURCE_STACK = deque([f\"cuda:{i}\" for i in range(N_GPUS)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_dataframe() -> pd.DataFrame:\n",
    "    return pd.DataFrame(\n",
    "        columns=[\n",
    "            \"autoencoder_group_path\",\n",
    "            \"autoencoder_path\",\n",
    "            \"reconstruction_file\",\n",
    "            \"eval_results_n_inputs\",\n",
    "            \"l0\",\n",
    "            \"l1_loss\",\n",
    "            \"l2_loss\",\n",
    "            \"frac_alive\",\n",
    "            \"frac_variance_explained\",\n",
    "            \"cossim\",\n",
    "            \"l2_ratio\",\n",
    "            \"num_alive_features\",\n",
    "            \"board_reconstruction_board_count\",\n",
    "            \"best_idx\",\n",
    "            \"zero_L0\",\n",
    "            \"zero_f1_score\",\n",
    "            \"best_L0\",\n",
    "            \"best_f1_score\",\n",
    "            \"zero_num_true_positive_squares\",\n",
    "            \"best_num_true_positive_squares\",\n",
    "            \"zero_num_false_positive_squares\",\n",
    "            \"best_num_false_positive_squares\",\n",
    "            \"zero_percent_active_classifiers\",\n",
    "            \"best_percent_active_classifiers\",\n",
    "            \"zero_classifiers_per_token\",\n",
    "            \"best_classifiers_per_token\",\n",
    "            \"zero_classified_per_token\",\n",
    "            \"best_classified_per_token\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def append_results(\n",
    "    eval_results: dict,\n",
    "    board_reconstruction_results: dict,\n",
    "    custom_functions: list[Callable],\n",
    "    df: pd.DataFrame,\n",
    "    autoencoder_group_path: str,\n",
    "    autoencoder_path: str,\n",
    "    reconstruction_file: str,\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    print(eval_results)\n",
    "\n",
    "    for custom_function in custom_functions:\n",
    "        function_name = custom_function.__name__\n",
    "\n",
    "        best_idx = board_reconstruction_results[custom_function.__name__][\"f1_score\"].argmax()\n",
    "\n",
    "        new_row = {\n",
    "            \"autoencoder_group_path\": autoencoder_group_path,\n",
    "            \"autoencoder_path\": autoencoder_path,\n",
    "            \"reconstruction_file\": reconstruction_file,\n",
    "            \"eval_results_n_inputs\": eval_results[\"hyperparameters\"]['n_inputs'],\n",
    "            \"l0\": eval_results['eval_results'][\"l0\"],\n",
    "            \"l1_loss\": eval_results['eval_results'][\"l1_loss\"],\n",
    "            \"l2_loss\": eval_results['eval_results'][\"l2_loss\"],\n",
    "            \"frac_alive\": eval_results['eval_results'][\"frac_alive\"],\n",
    "            \"frac_variance_explained\": eval_results['eval_results'][\"frac_variance_explained\"],\n",
    "            \"cossim\": eval_results['eval_results'][\"cossim\"],\n",
    "            \"l2_ratio\": eval_results['eval_results'][\"l2_ratio\"],\n",
    "            \"num_alive_features\": board_reconstruction_results[\"alive_features\"].shape[0],\n",
    "            \"board_reconstruction_board_count\": board_reconstruction_results[function_name][\"num_boards\"],\n",
    "            \"best_idx\": best_idx.item(),\n",
    "            \"zero_L0\": board_reconstruction_results[\"active_per_token\"][0].item(),\n",
    "            \"best_L0\": board_reconstruction_results[\"active_per_token\"][best_idx].item(),\n",
    "            \"zero_f1_score\": board_reconstruction_results[function_name][\"f1_score\"][0].item(),\n",
    "            \"best_f1_score\": board_reconstruction_results[function_name][\"f1_score\"][\n",
    "                best_idx\n",
    "            ].item(),\n",
    "            \"zero_num_true_positive_squares\": board_reconstruction_results[function_name][\n",
    "                \"num_true_positive_squares\"\n",
    "            ][0].item(),\n",
    "            \"best_num_true_positive_squares\": board_reconstruction_results[function_name][\n",
    "                \"num_true_positive_squares\"\n",
    "            ][best_idx].item(),\n",
    "            \"zero_num_false_positive_squares\": board_reconstruction_results[function_name][\n",
    "                \"num_false_positive_squares\"\n",
    "            ][0].item(),\n",
    "            \"best_num_false_positive_squares\": board_reconstruction_results[function_name][\n",
    "                \"num_false_positive_squares\"\n",
    "            ][best_idx].item(),\n",
    "            \"zero_percent_active_classifiers\": (\n",
    "                board_reconstruction_results[function_name][\"classifiers_per_token\"][0]\n",
    "                / board_reconstruction_results[\"active_per_token\"][0]\n",
    "            ).item(),\n",
    "            \"best_percent_active_classifiers\": (\n",
    "                board_reconstruction_results[function_name][\"classifiers_per_token\"][best_idx]\n",
    "                / board_reconstruction_results[\"active_per_token\"][best_idx]\n",
    "            ).item(),\n",
    "            \"zero_classifiers_per_token\": board_reconstruction_results[function_name][\n",
    "                \"classifiers_per_token\"\n",
    "            ][0].item(),\n",
    "            \"best_classifiers_per_token\": board_reconstruction_results[function_name][\n",
    "                \"classifiers_per_token\"\n",
    "            ][best_idx].item(),\n",
    "            \"zero_classified_per_token\": board_reconstruction_results[function_name][\n",
    "                \"classified_per_token\"\n",
    "            ][0].item(),\n",
    "            \"best_classified_per_token\": board_reconstruction_results[function_name][\n",
    "                \"classified_per_token\"\n",
    "            ][best_idx].item(),\n",
    "        }\n",
    "\n",
    "        new_row_df = pd.DataFrame([new_row])\n",
    "        df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, just set `autoencoder_group_paths` and various hyperparameters and run it. If you already ran, for example, `eval_sae_as_classifier` and don't want to run it again, set `run_eval_sae` to False. Note that in this case, `eval_results_n_inputs` must match in order for it to load the file saved from the previous run.\n",
    "\n",
    "By default, we `save_results`, which means each of the 4 functions saves a `.pkl` file. By default, we also aggregate and format some of the results into a csv `output_file`. If you already have results `.pkl` files and want a csv, you can set all `run_...` to False, and it will load the results and put them into a csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing evaluation dataset\n",
      "board_to_piece_state\n",
      "Element size: 1 bytes\n",
      "Number of elements: 425984000\n",
      "Memory usage: 406.25 MB\n",
      "board_to_pin_state\n",
      "Element size: 1 bytes\n",
      "Number of elements: 512000\n",
      "Memory usage: 0.48828125 MB\n",
      "WARNING: using manual setting of layer to 5\n",
      "WARNING: using manual setting of layer to 5\n",
      "WARNING: using manual setting of layer to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: using manual setting of layer to 5\n",
      "WARNING: using manual setting of layer to 5\n",
      "WARNING: using manual setting of layer to 5\n",
      "WARNING: using manual setting of layer to 5\n",
      "WARNING: using manual setting of layer to 5\n",
      "AggregatingAggregating ../autoencoders/group-2024-05-07/PAnnealTrainer-chess-alpha0.04466836154460907L_p^p/\n",
      " ../autoencoders/group-2024-05-07/GatedSAETrainer-chess-alpha1.0/\n",
      "Aggregating ../autoencoders/group-2024-05-07/StandardTrainer-chess-alpha0.07943282276391983/\n",
      "Aggregating ../autoencoders/group-2024-05-07/GatedSAETrainer-chess-alpha0.7079457640647888/\n",
      "Aggregating ../autoencoders/group-2024-05-07/StandardTrainer-chess-alpha0.09440608322620392/\n",
      "WARNING: using manual setting of layer to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: using manual setting of layer to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting features:   0%|          | 0/1280 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating ../autoencoders/group-2024-05-07/PAnnealTrainer-chess-alpha0.05011872947216034L_p^p/\n",
      "Aggregating ../autoencoders/group-2024-05-07/StandardTrainer-chess-alpha0.11220184713602066/\n",
      "Aggregating ../autoencoders/group-2024-05-07/PAnnealTrainer-chess-alpha0.03981072083115578L_p^p/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting features:   0%|          | 0/1280 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: using manual setting of layer to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "Collecting features:   0%|          | 0/1280 [00:00<?, ?it/s]\u001b[A\u001b[A/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Collecting features:   0%|          | 1/1280 [00:02<1:01:52,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: using manual setting of layer to 5\n",
      "WARNING: using manual setting of layer to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Collecting features:   6%|▋         | 81/1280 [00:03<00:32, 37.41it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: using manual setting of layer to 5\n",
      "WARNING: using manual setting of layer to 5\n",
      "WARNING: using manual setting of layer to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Collecting features:   9%|▉         | 119/1280 [00:03<00:22, 52.11it/s]/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  13%|█▎        | 168/1280 [00:03<00:18, 61.65it/s]\n",
      "Collecting features:   0%|          | 1/1280 [00:03<1:03:54,  3.00s/it]\u001b[A\n",
      "Collecting features:  14%|█▍        | 184/1280 [00:04<00:17, 63.13it/s]\u001b[A\n",
      "Collecting features:  15%|█▌        | 197/1280 [00:04<00:15, 68.25it/s][A\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:   0%|          | 0/1280 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:   0%|          | 0/1280 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Collecting features:   4%|▍         | 52/1280 [00:03<00:35, 34.49it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:   0%|          | 0/1280 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  22%|██▏       | 284/1280 [00:04<00:05, 170.12it/s]A\u001b[A\u001b[A\u001b[A\n",
      "Collecting features:  32%|███▏      | 413/1280 [00:04<00:02, 342.08it/s]\u001b[A\n",
      "Collecting features:  42%|████▏     | 542/1280 [00:04<00:01, 512.33it/s]\u001b[A\n",
      "Collecting features:  52%|█████▎    | 672/1280 [00:04<00:00, 672.58it/s]\u001b[A\n",
      "Collecting features:  63%|██████▎   | 802/1280 [00:04<00:00, 813.06it/s]\u001b[A\n",
      "Collecting features:  71%|███████   | 910/1280 [00:05<00:00, 492.31it/s]\u001b[A\n",
      "Collecting features:  81%|████████  | 1034/1280 [00:05<00:00, 614.24it/s][A\n",
      "Collecting features:  91%|█████████ | 1160/1280 [00:05<00:00, 735.89it/s]\u001b[A\n",
      "Collecting features:  91%|█████████ | 1161/1280 [00:04<00:00, 799.98it/s]\u001b[A\n",
      "\n",
      "Collecting features: 100%|██████████| 1280/1280 [00:05<00:00, 232.68it/s][A\n",
      "\n",
      "Collecting features: 100%|██████████| 1280/1280 [00:04<00:00, 280.97it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 16384 features, on 128000 activations, 3792 are alive.\n",
      "Out of 16384 features, on 128000 activations, 8115 are alive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating statistics:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "\n",
      "Collecting features:   5%|▍         | 61/1280 [00:02<00:40, 29.76it/s]\u001b[A\u001b[A\n",
      "Aggregating statistics:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Collecting features:  15%|█▍        | 191/1280 [00:02<00:09, 112.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:  21%|██        | 265/1280 [00:03<00:10, 97.98it/s] \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Collecting features:   0%|          | 1/1280 [00:03<1:10:24,  3.30s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:  29%|██▉       | 371/1280 [00:03<00:05, 162.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Collecting features:   8%|▊         | 108/1280 [00:03<00:26, 44.64it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:  37%|███▋      | 477/1280 [00:04<00:03, 240.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Aggregating statistics:  10%|█         | 1/10 [00:01<00:11,  1.32s/it]s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:  47%|████▋     | 605/1280 [00:04<00:01, 356.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:  59%|█████▉    | 753/1280 [00:04<00:01, 509.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Collecting features:  23%|██▎       | 298/1280 [00:04<00:09, 108.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:   0%|          | 1/1280 [00:03<1:10:27,  3.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:   0%|          | 1/1280 [00:03<1:10:52,  3.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:   0%|          | 1/1280 [00:03<1:10:16,  3.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:  69%|██████▉   | 882/1280 [00:04<00:01, 350.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Collecting features:  33%|███▎      | 417/1280 [00:04<00:04, 182.46it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:   7%|▋         | 91/1280 [00:03<00:31, 37.67it/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:   0%|          | 1/1280 [00:03<1:13:09,  3.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:   0%|          | 2/1280 [00:03<30:33,  1.43s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:  76%|███████▌  | 969/1280 [00:04<00:00, 408.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:   6%|▌         | 76/1280 [00:03<00:38, 31.06it/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Collecting features:  39%|███▊      | 495/1280 [00:04<00:03, 234.25it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  11%|█▏        | 147/1280 [00:03<00:16, 66.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:   3%|▎         | 44/1280 [00:03<01:10, 17.44it/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:   4%|▍         | 56/1280 [00:03<00:40, 30.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  10%|█         | 128/1280 [00:03<00:19, 58.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:  82%|████████▏ | 1054/1280 [00:05<00:00, 432.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Collecting features:  45%|████▍     | 572/1280 [00:04<00:02, 281.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  16%|█▌        | 202/1280 [00:03<00:10, 102.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:   7%|▋         | 84/1280 [00:03<00:31, 38.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:   8%|▊         | 108/1280 [00:03<00:17, 66.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  14%|█▍        | 178/1280 [00:03<00:12, 90.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  10%|▉         | 124/1280 [00:03<00:18, 63.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  20%|██        | 256/1280 [00:03<00:07, 143.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  13%|█▎        | 162/1280 [00:03<00:10, 110.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:  88%|████████▊ | 1129/1280 [00:05<00:00, 453.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  18%|█▊        | 230/1280 [00:03<00:08, 131.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Aggregating statistics:  20%|██        | 2/10 [00:02<00:09,  1.24s/it]s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  13%|█▎        | 162/1280 [00:03<00:12, 93.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  24%|██▍       | 309/1280 [00:03<00:05, 188.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  17%|█▋        | 214/1280 [00:03<00:06, 159.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  22%|██▏       | 282/1280 [00:03<00:05, 176.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:  94%|█████████▎| 1198/1280 [00:05<00:00, 469.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Collecting features:  55%|█████▌    | 706/1280 [00:04<00:01, 359.72it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  16%|█▌        | 203/1280 [00:03<00:08, 130.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  21%|██        | 267/1280 [00:03<00:04, 213.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  28%|██▊       | 361/1280 [00:03<00:03, 235.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  26%|██▌       | 335/1280 [00:03<00:04, 227.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Collecting features:  60%|█████▉    | 767/1280 [00:04<00:01, 395.69it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Collecting features: 100%|██████████| 1280/1280 [00:05<00:00, 230.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  25%|██▍       | 316/1280 [00:04<00:03, 252.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  19%|█▉        | 241/1280 [00:04<00:06, 159.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  32%|███▏      | 413/1280 [00:04<00:03, 273.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  30%|███       | 385/1280 [00:04<00:03, 263.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 16384 features, on 128000 activations, 4981 are alive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Aggregating statistics:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Collecting features:  65%|██████▍   | 826/1280 [00:05<00:01, 407.46it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  30%|██▉       | 378/1280 [00:04<00:02, 323.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  22%|██▏       | 286/1280 [00:04<00:04, 206.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  37%|███▋      | 477/1280 [00:04<00:02, 342.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  35%|███▍      | 446/1280 [00:04<00:02, 329.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  35%|███▍      | 445/1280 [00:04<00:02, 397.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  26%|██▌       | 335/1280 [00:04<00:03, 260.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  43%|████▎     | 545/1280 [00:04<00:01, 414.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  40%|████      | 516/1280 [00:04<00:01, 408.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  41%|████      | 525/1280 [00:04<00:01, 491.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  31%|███       | 398/1280 [00:04<00:02, 337.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  49%|████▉     | 626/1280 [00:04<00:01, 506.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  47%|████▋     | 597/1280 [00:04<00:01, 501.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  47%|████▋     | 606/1280 [00:04<00:01, 570.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  36%|███▌      | 459/1280 [00:04<00:02, 400.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  55%|█████▌    | 706/1280 [00:04<00:00, 578.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  53%|█████▎    | 678/1280 [00:04<00:01, 578.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Collecting features:  69%|██████▉   | 882/1280 [00:05<00:01, 261.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  54%|█████▎    | 687/1280 [00:04<00:00, 633.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  41%|████      | 520/1280 [00:04<00:01, 452.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  62%|██████▏   | 789/1280 [00:04<00:00, 643.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  59%|█████▉    | 756/1280 [00:04<00:00, 631.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Collecting features:  74%|███████▍  | 949/1280 [00:05<00:01, 323.50it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  59%|█████▉    | 760/1280 [00:04<00:00, 643.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  45%|████▍     | 575/1280 [00:04<00:01, 467.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  67%|██████▋   | 863/1280 [00:04<00:00, 644.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  65%|██████▍   | 828/1280 [00:04<00:00, 640.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Collecting features:  79%|███████▉  | 1013/1280 [00:05<00:00, 379.24it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  65%|██████▍   | 831/1280 [00:04<00:00, 651.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  49%|████▉     | 629/1280 [00:04<00:01, 481.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Collecting features:  86%|████████▌ | 1103/1280 [00:05<00:00, 484.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  30%|███       | 3/10 [00:03<00:08,  1.20s/it]s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Collecting features:  96%|█████████▌| 1228/1280 [00:05<00:00, 653.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "Aggregating statistics:  10%|█         | 1/10 [00:03<00:32,  3.61s/it]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Collecting features: 100%|██████████| 1280/1280 [00:05<00:00, 216.09it/s][A\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 16384 features, on 128000 activations, 7202 are alive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  73%|███████▎  | 934/1280 [00:05<00:00, 358.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  70%|███████   | 899/1280 [00:05<00:01, 347.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  70%|███████   | 901/1280 [00:05<00:01, 364.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  83%|████████▎ | 1066/1280 [00:05<00:00, 524.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  80%|███████▉  | 1021/1280 [00:05<00:00, 497.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  80%|███████▉  | 1018/1280 [00:05<00:00, 508.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  93%|█████████▎| 1186/1280 [00:05<00:00, 657.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  89%|████████▉ | 1142/1280 [00:05<00:00, 637.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features: 100%|██████████| 1280/1280 [00:05<00:00, 239.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  97%|█████████▋| 1237/1280 [00:05<00:00, 705.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  70%|██████▉   | 890/1280 [00:05<00:01, 358.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 16384 features, on 128000 activations, 3885 are alive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features: 100%|██████████| 1280/1280 [00:05<00:00, 235.52it/s]A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features: 100%|██████████| 1280/1280 [00:05<00:00, 231.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  78%|███████▊  | 994/1280 [00:05<00:00, 461.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 16384 features, on 128000 activations, 9180 are alive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  86%|████████▌ | 1096/1280 [00:05<00:00, 567.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Aggregating statistics:  10%|█         | 1/10 [00:01<00:14,  1.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Collecting features: 100%|██████████| 1280/1280 [00:05<00:00, 221.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 16384 features, on 128000 activations, 5556 are alive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  40%|████      | 4/10 [00:04<00:07,  1.19s/it]A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 16384 features, on 128000 activations, 2983 are alive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Aggregating statistics:  20%|██        | 2/10 [00:03<00:12,  1.53s/it]\u001b[A\u001b[A\n",
      "Aggregating statistics:  50%|█████     | 5/10 [00:05<00:05,  1.18s/it]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  10%|█         | 1/10 [00:01<00:17,  1.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Aggregating statistics:  10%|█         | 1/10 [00:02<00:21,  2.34s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  10%|█         | 1/10 [00:02<00:18,  2.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  60%|██████    | 6/10 [00:07<00:04,  1.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  20%|██        | 2/10 [00:03<00:11,  1.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Aggregating statistics:  30%|███       | 3/10 [00:04<00:10,  1.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  10%|█         | 1/10 [00:03<00:30,  3.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  20%|██        | 2/10 [00:01<00:07,  1.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  70%|███████   | 7/10 [00:08<00:03,  1.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Aggregating statistics:  20%|██        | 2/10 [00:04<00:17,  2.24s/it]\u001b[A\u001b[A\u001b[A\n",
      "Aggregating statistics:  30%|███       | 3/10 [00:08<00:18,  2.65s/it]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  30%|███       | 3/10 [00:04<00:09,  1.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  30%|███       | 3/10 [00:02<00:06,  1.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Aggregating statistics:  80%|████████  | 8/10 [00:09<00:02,  1.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  40%|████      | 4/10 [00:03<00:05,  1.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  40%|████      | 4/10 [00:05<00:07,  1.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  30%|███       | 3/10 [00:05<00:12,  1.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Aggregating statistics:  50%|█████     | 5/10 [00:07<00:07,  1.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  20%|██        | 2/10 [00:06<00:23,  2.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Aggregating statistics:  30%|███       | 3/10 [00:06<00:15,  2.20s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  90%|█████████ | 9/10 [00:10<00:01,  1.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  50%|█████     | 5/10 [00:06<00:06,  1.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Aggregating statistics:  40%|████      | 4/10 [00:10<00:15,  2.56s/it]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  60%|██████    | 6/10 [00:05<00:03,  1.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics: 100%|██████████| 10/10 [00:11<00:00,  1.18s/it][A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Aggregating statistics:  60%|██████    | 6/10 [00:09<00:06,  1.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  60%|██████    | 6/10 [00:07<00:04,  1.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  70%|███████   | 7/10 [00:06<00:02,  1.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Aggregating statistics:  40%|████      | 4/10 [00:08<00:13,  2.19s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonzero classifiers per feature per threshold: tensor([1238, 1202, 1173, 1158, 1116, 1065,  965,  812,  545,  184,    4],\n",
      "       device='cuda:0')\n",
      "Total classified squares per feature per threshold: tensor([14950, 14624, 14615, 14863, 15104, 15620, 14917, 13942, 11593,  6185,\n",
      "          256], device='cuda:0')\n",
      "Out of 3792 features, 1238 were classifiers.\n",
      "The following are counts of squares classified per classifier per feature:\n",
      "Min count: 1, average count: 12.075929641723633, max count: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating statistics:  30%|███       | 3/10 [00:08<00:20,  2.92s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  70%|███████   | 7/10 [00:09<00:03,  1.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  80%|████████  | 8/10 [00:07<00:01,  1.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Aggregating statistics:  50%|█████     | 5/10 [00:13<00:12,  2.52s/it]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  50%|█████     | 5/10 [00:08<00:08,  1.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Aggregating statistics:  70%|███████   | 7/10 [00:10<00:04,  1.50s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing board reconstruction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  90%|█████████ | 9/10 [00:08<00:00,  1.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  80%|████████  | 8/10 [00:10<00:02,  1.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: using manual setting of layer to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating statistics:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "Aggregating statistics:  50%|█████     | 5/10 [00:10<00:10,  2.18s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Aggregating statistics:  80%|████████  | 8/10 [00:12<00:03,  1.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  60%|██████    | 6/10 [00:10<00:06,  1.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics: 100%|██████████| 10/10 [00:09<00:00,  1.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Aggregating statistics:  10%|█         | 1/10 [00:01<00:14,  1.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  90%|█████████ | 9/10 [00:12<00:01,  1.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Aggregating statistics:  60%|██████    | 6/10 [00:16<00:10,  2.69s/it]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  40%|████      | 4/10 [00:12<00:17,  2.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Aggregating statistics:  90%|█████████ | 9/10 [00:13<00:01,  1.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  70%|███████   | 7/10 [00:12<00:05,  1.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics: 100%|██████████| 10/10 [00:12<00:00,  1.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonzero classifiers per feature per threshold: tensor([920, 894, 906, 884, 858, 825, 771, 655, 477, 130,   0],\n",
      "       device='cuda:5')\n",
      "Total classified squares per feature per threshold: tensor([ 9769,  9030,  9839,  9886, 10560, 11459, 12014, 11754, 10485,  4697,\n",
      "            0], device='cuda:5')\n",
      "Out of 2983 features, 920 were classifiers.\n",
      "The following are counts of squares classified per classifier per feature:\n",
      "Min count: 1, average count: 10.618477821350098, max count: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  60%|██████    | 6/10 [00:13<00:08,  2.18s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing board reconstruction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating statistics:  20%|██        | 2/10 [00:02<00:09,  1.21s/it]\n",
      "\n",
      "Aggregating statistics: 100%|██████████| 10/10 [00:15<00:00,  1.51s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonzero classifiers per feature per threshold: tensor([1208, 1165, 1194, 1206, 1155, 1094,  998,  832,  542,  165,    0],\n",
      "       device='cuda:6')\n",
      "Total classified squares per feature per threshold: tensor([12688, 11671, 12457, 13531, 14121, 14691, 15247, 14249, 10976,  5290,\n",
      "            0], device='cuda:6')\n",
      "Out of 3885 features, 1208 were classifiers.\n",
      "The following are counts of squares classified per classifier per feature:\n",
      "Min count: 1, average count: 10.503311157226562, max count: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Aggregating statistics:  70%|███████   | 7/10 [00:18<00:07,  2.43s/it]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  80%|████████  | 8/10 [00:13<00:03,  1.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing board reconstruction\n",
      "WARNING: using manual setting of layer to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  50%|█████     | 5/10 [00:14<00:13,  2.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Aggregating statistics:  30%|███       | 3/10 [00:04<00:10,  1.48s/it]\n",
      "\n",
      "\n",
      "Aggregating statistics:  70%|███████   | 7/10 [00:15<00:06,  2.18s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonzero classifiers per feature per threshold: tensor([1618, 1503, 1536, 1543, 1482, 1378, 1256, 1025,  630,  174,    0],\n",
      "       device='cuda:7')\n",
      "Total classified squares per feature per threshold: tensor([17521, 15061, 15744, 16922, 17463, 18044, 18047, 16541, 11913,  5159,\n",
      "            0], device='cuda:7')\n",
      "Out of 4981 features, 1618 were classifiers.\n",
      "The following are counts of squares classified per classifier per feature:\n",
      "Min count: 1, average count: 10.828801155090332, max count: 64\n",
      "Testing board reconstruction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  90%|█████████ | 9/10 [00:15<00:01,  1.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "Aggregating statistics:  10%|█         | 1/10 [00:01<00:12,  1.42s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: using manual setting of layer to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Aggregating statistics:  80%|████████  | 8/10 [00:20<00:04,  2.43s/it]\u001b[A\n",
      "\n",
      "Aggregating statistics:  40%|████      | 4/10 [00:06<00:10,  1.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Aggregating statistics:  80%|████████  | 8/10 [00:17<00:04,  2.17s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  60%|██████    | 6/10 [00:17<00:11,  2.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: using manual setting of layer to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics: 100%|██████████| 10/10 [00:17<00:00,  1.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  10%|█         | 1/10 [00:01<00:15,  1.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  50%|█████     | 5/10 [00:07<00:07,  1.49s/it]A\u001b[A\n",
      "\n",
      "Aggregating statistics:  30%|███       | 3/10 [00:03<00:08,  1.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  20%|██        | 2/10 [00:02<00:10,  1.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Aggregating statistics:  90%|█████████ | 9/10 [00:22<00:02,  2.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonzero classifiers per feature per threshold: tensor([1684, 1642, 1630, 1578, 1540, 1416, 1231,  967,  609,  184,    4],\n",
      "       device='cuda:1')\n",
      "Total classified squares per feature per threshold: tensor([19489, 19326, 19774, 19309, 19918, 19529, 18722, 16326, 12351,  5740,\n",
      "          256], device='cuda:1')\n",
      "Out of 5556 features, 1684 were classifiers.\n",
      "The following are counts of squares classified per classifier per feature:\n",
      "Min count: 1, average count: 11.573040962219238, max count: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  60%|██████    | 6/10 [00:09<00:06,  1.58s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing board reconstruction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Aggregating statistics:  40%|████      | 4/10 [00:05<00:08,  1.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  70%|███████   | 7/10 [00:19<00:08,  2.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  10%|█         | 1/10 [00:02<00:19,  2.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  30%|███       | 3/10 [00:04<00:09,  1.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: using manual setting of layer to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Aggregating statistics:  50%|█████     | 5/10 [00:06<00:06,  1.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  20%|██        | 2/10 [00:03<00:12,  1.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Aggregating statistics: 100%|██████████| 10/10 [00:25<00:00,  2.54s/it]\u001b[A\n",
      "Aggregating statistics:  70%|███████   | 7/10 [00:10<00:04,  1.58s/it]\n",
      "\n",
      "\n",
      "Aggregating statistics: 100%|██████████| 10/10 [00:21<00:00,  2.18s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  40%|████      | 4/10 [00:05<00:08,  1.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  80%|████████  | 8/10 [00:22<00:05,  2.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Aggregating statistics:  60%|██████    | 6/10 [00:08<00:05,  1.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  10%|█         | 1/10 [00:02<00:19,  2.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonzero classifiers per feature per threshold: tensor([2227, 2188, 2091, 1937, 1782, 1553, 1301,  981,  571,  174,    1],\n",
      "       device='cuda:3')\n",
      "Total classified squares per feature per threshold: tensor([29929, 30141, 29693, 28322, 27043, 24070, 21194, 17137, 11470,  5073,\n",
      "           11], device='cuda:3')\n",
      "Out of 8115 features, 2227 were classifiers.\n",
      "The following are counts of squares classified per classifier per feature:\n",
      "Min count: 1, average count: 13.439156532287598, max count: 64\n",
      "Nonzero classifiers per feature per threshold: tensor([1990, 1955, 1883, 1760, 1610, 1434, 1186,  927,  555,  174,    1],\n",
      "       device='cuda:2')\n",
      "Total classified squares per feature per threshold: tensor([27516, 28066, 28080, 27028, 25281, 23091, 19311, 16378, 11479,  5218,\n",
      "            9], device='cuda:2')\n",
      "Out of 7202 features, 1990 were classifiers.\n",
      "The following are counts of squares classified per classifier per feature:\n",
      "Min count: 1, average count: 13.82713508605957, max count: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregating statistics:  80%|████████  | 8/10 [00:13<00:03,  1.88s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  50%|█████     | 5/10 [00:07<00:08,  1.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  30%|███       | 3/10 [00:05<00:14,  2.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing board reconstruction\n",
      "Testing board reconstruction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Aggregating statistics:  70%|███████   | 7/10 [00:09<00:04,  1.58s/it]\u001b[A\u001b[A/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: using manual setting of layer to 5\n",
      "WARNING: using manual setting of layer to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Aggregating statistics:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  90%|█████████ | 9/10 [00:25<00:02,  2.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  90%|█████████ | 9/10 [00:15<00:01,  1.82s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  60%|██████    | 6/10 [00:09<00:06,  1.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Aggregating statistics:  80%|████████  | 8/10 [00:11<00:02,  1.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  40%|████      | 4/10 [00:08<00:12,  2.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Aggregating statistics: 100%|██████████| 10/10 [00:16<00:00,  1.69s/it][A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  10%|█         | 1/10 [00:02<00:25,  2.84s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  70%|███████   | 7/10 [00:12<00:05,  1.95s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/tmp/ipykernel_2513515/2329706948.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row_df], ignore_index=True)\n",
      "\n",
      "Aggregating statistics:  10%|█         | 1/10 [00:03<00:28,  3.22s/it]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  30%|███       | 3/10 [00:07<00:17,  2.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hyperparameters': {'n_inputs': 1000, 'context_length': 256}, 'eval_results': {'l2_loss': 1.869858980178833, 'l1_loss': 23.012340545654297, 'l0': 15.707000732421875, 'frac_alive': 0.0009586792439222336, 'frac_variance_explained': 0.9729184508323669, 'cossim': 0.968239426612854, 'l2_ratio': 0.9659726023674011}}\n",
      "Finished ../autoencoders/group-2024-05-07/GatedSAETrainer-chess-alpha1.0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  50%|█████     | 5/10 [00:10<00:10,  2.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics: 100%|██████████| 10/10 [00:28<00:00,  2.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: using manual setting of layer to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "Aggregating statistics: 100%|██████████| 10/10 [00:14<00:00,  1.49s/it]\u001b[A\u001b[A\n",
      "/tmp/ipykernel_2513515/2329706948.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row_df], ignore_index=True)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  80%|████████  | 8/10 [00:14<00:03,  1.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hyperparameters': {'n_inputs': 1000, 'context_length': 256}, 'eval_results': {'l2_loss': 2.0228612422943115, 'l1_loss': 14.537116050720215, 'l0': 27.304000854492188, 'frac_alive': 0.0016665039584040642, 'frac_variance_explained': 0.9657015800476074, 'cossim': 0.9598084092140198, 'l2_ratio': 0.906217098236084}}\n",
      "Finished ../autoencoders/group-2024-05-07/StandardTrainer-chess-alpha0.11220184713602066/\n",
      "Aggregating ../autoencoders/group-2024-05-07/GatedSAETrainer-chess-alpha1.4125375747680664/\n",
      "Nonzero classifiers per feature per threshold: tensor([2429, 2423, 2323, 2162, 1943, 1694, 1377, 1018,  567,  166,    0],\n",
      "       device='cuda:4')\n",
      "Total classified squares per feature per threshold: tensor([32830, 33863, 33453, 31616, 29298, 26598, 22602, 17622, 11377,  4809,\n",
      "            0], device='cuda:4')\n",
      "Out of 9180 features, 2429 were classifiers.\n",
      "The following are counts of squares classified per classifier per feature:\n",
      "Min count: 1, average count: 13.515850067138672, max count: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  20%|██        | 2/10 [00:05<00:23,  2.95s/it]\u001b[A\u001b[A\u001b[A\n",
      "Aggregating statistics:  20%|██        | 2/10 [00:06<00:24,  3.05s/it]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  60%|██████    | 6/10 [00:13<00:09,  2.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  40%|████      | 4/10 [00:10<00:16,  2.73s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: using manual setting of layer to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  90%|█████████ | 9/10 [00:15<00:01,  1.91s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing board reconstruction\n",
      "WARNING: using manual setting of layer to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: using manual setting of layer to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Aggregating statistics:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "\n",
      "Collecting features:   0%|          | 0/1280 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  70%|███████   | 7/10 [00:15<00:07,  2.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics: 100%|██████████| 10/10 [00:17<00:00,  1.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating ../autoencoders/group-2024-05-07/GatedAnnealTrainer-chess-alpha0.3981071710586548L_p^p/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_2513515/2329706948.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row_df], ignore_index=True)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  50%|█████     | 5/10 [00:13<00:15,  3.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Aggregating statistics:  30%|███       | 3/10 [00:09<00:23,  3.31s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hyperparameters': {'n_inputs': 1000, 'context_length': 256}, 'eval_results': {'l2_loss': 1.8137911558151245, 'l1_loss': 15.704079627990723, 'l0': 37.21500015258789, 'frac_alive': 0.0022714233491569757, 'frac_variance_explained': 0.9723506569862366, 'cossim': 0.9677205681800842, 'l2_ratio': 0.9240405559539795}}\n",
      "Finished ../autoencoders/group-2024-05-07/StandardTrainer-chess-alpha0.09440608322620392/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Aggregating statistics:  30%|███       | 3/10 [00:09<00:23,  3.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: using manual setting of layer to 5\n",
      "WARNING: using manual setting of layer to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "Collecting features:   0%|          | 1/1280 [00:02<59:18,  2.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  80%|████████  | 8/10 [00:18<00:04,  2.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:   2%|▏         | 22/1280 [00:02<01:58, 10.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:   0%|          | 0/1280 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:  11%|█         | 135/1280 [00:02<00:13, 83.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:  21%|██        | 269/1280 [00:03<00:05, 190.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:  31%|███▏      | 402/1280 [00:03<00:02, 313.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:  42%|████▏     | 535/1280 [00:03<00:01, 449.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  10%|█         | 1/10 [00:03<00:33,  3.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:  51%|█████     | 649/1280 [00:03<00:01, 484.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:  61%|██████    | 779/1280 [00:03<00:00, 618.96it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating ../autoencoders/group-2024-05-07/GatedAnnealTrainer-chess-alpha0.5623413324356079L_p^p/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  40%|████      | 4/10 [00:11<00:17,  2.89s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:  69%|██████▉   | 886/1280 [00:04<00:01, 336.52it/s]\u001b[A\u001b[A/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "Collecting features:  75%|███████▌  | 965/1280 [00:04<00:00, 386.20it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: using manual setting of layer to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting features:  83%|████████▎ | 1063/1280 [00:04<00:00, 444.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:   0%|          | 0/1280 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:  89%|████████▉ | 1138/1280 [00:04<00:00, 436.63it/s]\u001b[A\u001b[A\n",
      "Aggregating statistics:  40%|████      | 4/10 [00:12<00:19,  3.23s/it]\u001b[A\n",
      "\n",
      "Collecting features: 100%|██████████| 1280/1280 [00:04<00:00, 260.82it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 16384 features, on 128000 activations, 2505 are alive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Aggregating statistics:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  90%|█████████ | 9/10 [00:20<00:02,  2.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  70%|███████   | 7/10 [00:17<00:07,  2.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:   0%|          | 1/1280 [00:02<59:39,  2.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Aggregating statistics:  20%|██        | 2/10 [00:00<00:03,  2.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  20%|██        | 2/10 [00:06<00:24,  3.02s/it]]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  15%|█▍        | 191/1280 [00:03<00:11, 95.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  25%|██▌       | 324/1280 [00:03<00:04, 195.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  35%|███▌      | 453/1280 [00:03<00:02, 308.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  46%|████▌     | 586/1280 [00:03<00:01, 440.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  55%|█████▌    | 705/1280 [00:03<00:01, 556.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Aggregating statistics:  30%|███       | 3/10 [00:01<00:03,  1.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  64%|██████▍   | 819/1280 [00:03<00:00, 564.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Aggregating statistics:  50%|█████     | 5/10 [00:14<00:14,  2.82s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics: 100%|██████████| 10/10 [00:22<00:00,  2.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "/tmp/ipykernel_2513515/2329706948.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row_df], ignore_index=True)\n",
      "\n",
      "\n",
      "Aggregating statistics:  40%|████      | 4/10 [00:02<00:05,  1.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  72%|███████▏  | 916/1280 [00:05<00:01, 196.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hyperparameters': {'n_inputs': 1000, 'context_length': 256}, 'eval_results': {'l2_loss': 1.627392292022705, 'l1_loss': 16.864665985107422, 'l0': 49.8280029296875, 'frac_alive': 0.0030412599444389343, 'frac_variance_explained': 0.9777706861495972, 'cossim': 0.9741085171699524, 'l2_ratio': 0.9376888871192932}}\n",
      "Finished ../autoencoders/group-2024-05-07/StandardTrainer-chess-alpha0.07943282276391983/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  80%|████████  | 8/10 [00:20<00:04,  2.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Aggregating statistics:  50%|█████     | 5/10 [00:16<00:16,  3.23s/it]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  77%|███████▋  | 985/1280 [00:05<00:01, 213.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  87%|████████▋ | 1117/1280 [00:05<00:00, 311.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:   0%|          | 1/1280 [00:03<1:17:28,  3.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features: 100%|██████████| 1280/1280 [00:05<00:00, 234.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:   8%|▊         | 98/1280 [00:03<00:31, 36.95it/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 16384 features, on 128000 activations, 7152 are alive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  16%|█▋        | 209/1280 [00:03<00:11, 91.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  23%|██▎       | 291/1280 [00:04<00:08, 121.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Aggregating statistics:  50%|█████     | 5/10 [00:03<00:04,  1.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "Aggregating statistics:  30%|███       | 3/10 [00:10<00:24,  3.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  10%|█         | 1/10 [00:01<00:14,  1.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Aggregating statistics:  60%|██████    | 6/10 [00:17<00:12,  3.03s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  27%|██▋       | 350/1280 [00:05<00:11, 83.75it/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  37%|███▋      | 476/1280 [00:05<00:05, 148.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  48%|████▊     | 608/1280 [00:05<00:02, 234.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  58%|█████▊    | 740/1280 [00:05<00:01, 337.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  68%|██████▊   | 872/1280 [00:05<00:00, 453.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  90%|█████████ | 9/10 [00:23<00:02,  2.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  77%|███████▋  | 984/1280 [00:06<00:00, 359.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Aggregating statistics:  80%|████████  | 8/10 [00:06<00:01,  1.26it/s]\u001b[A\u001b[A/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  85%|████████▍ | 1087/1280 [00:06<00:00, 439.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: using manual setting of layer to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Collecting features:  93%|█████████▎| 1192/1280 [00:06<00:00, 512.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Collecting features: 100%|██████████| 1280/1280 [00:06<00:00, 194.49it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 16384 features, on 128000 activations, 5491 are alive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Aggregating statistics:  60%|██████    | 6/10 [00:19<00:13,  3.41s/it]\u001b[A\n",
      "\n",
      "Aggregating statistics: 100%|██████████| 10/10 [00:07<00:00,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  20%|██        | 2/10 [00:03<00:14,  1.81s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  10%|█         | 1/10 [00:00<00:07,  1.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating ../autoencoders/group-2024-05-07/GatedAnnealTrainer-chess-alpha0.7943282127380371L_p^p/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  70%|███████   | 7/10 [00:20<00:08,  2.85s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics: 100%|██████████| 10/10 [00:25<00:00,  2.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Aggregating statistics:  40%|████      | 4/10 [00:13<00:19,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hyperparameters': {'n_inputs': 1000, 'context_length': 256}, 'eval_results': {'l2_loss': 1.6255600452423096, 'l1_loss': 24.73455238342285, 'l0': 22.929000854492188, 'frac_alive': 0.0013994751498103142, 'frac_variance_explained': 0.9795665740966797, 'cossim': 0.9763676524162292, 'l2_ratio': 0.9762305021286011}}\n",
      "Finished ../autoencoders/group-2024-05-07/GatedSAETrainer-chess-alpha0.7079457640647888/\n",
      "WARNING: using manual setting of layer to 5\n",
      "Nonzero classifiers per feature per threshold: tensor([840, 828, 816, 805, 777, 752, 709, 611, 437, 178,   2],\n",
      "       device='cuda:0')\n",
      "Total classified squares per feature per threshold: tensor([ 9187,  9057,  9686, 10052, 10163, 10872, 11200, 10377,  9168,  5623,\n",
      "          110], device='cuda:0')\n",
      "Out of 2505 features, 840 were classifiers.\n",
      "The following are counts of squares classified per classifier per feature:\n",
      "Min count: 1, average count: 10.936904907226562, max count: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2513515/2329706948.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row_df], ignore_index=True)\n",
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  20%|██        | 2/10 [00:02<00:11,  1.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  30%|███       | 3/10 [00:05<00:14,  2.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing board reconstruction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: using manual setting of layer to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Collecting features:   0%|          | 0/1280 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "Aggregating statistics:  70%|███████   | 7/10 [00:22<00:09,  3.27s/it]\u001b[A/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  10%|█         | 1/10 [00:00<00:02,  3.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  30%|███       | 3/10 [00:04<00:10,  1.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  20%|██        | 2/10 [00:01<00:06,  1.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Aggregating statistics:  80%|████████  | 8/10 [00:24<00:06,  3.14s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  50%|█████     | 5/10 [00:17<00:17,  3.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  40%|████      | 4/10 [00:05<00:09,  1.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:   0%|          | 1/1280 [00:02<1:03:41,  2.99s/it]\u001b[A\u001b[A\n",
      "Aggregating statistics:  80%|████████  | 8/10 [00:25<00:06,  3.18s/it]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  30%|███       | 3/10 [00:02<00:07,  1.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:   9%|▉         | 117/1280 [00:03<00:21, 53.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:  14%|█▍        | 185/1280 [00:03<00:12, 88.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:  25%|██▍       | 317/1280 [00:03<00:05, 183.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:  35%|███▍      | 447/1280 [00:03<00:02, 294.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:  45%|████▌     | 579/1280 [00:03<00:01, 422.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:  56%|█████▌    | 712/1280 [00:03<00:01, 559.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:  66%|██████▌   | 845/1280 [00:03<00:00, 695.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  50%|█████     | 5/10 [00:10<00:10,  2.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  50%|█████     | 5/10 [00:07<00:07,  1.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:  76%|███████▌  | 968/1280 [00:04<00:00, 480.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  40%|████      | 4/10 [00:04<00:06,  1.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Collecting features:  85%|████████▌ | 1093/1280 [00:04<00:00, 593.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "Collecting features: 100%|██████████| 1280/1280 [00:04<00:00, 288.89it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 16384 features, on 128000 activations, 3961 are alive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Aggregating statistics:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Aggregating statistics:  90%|█████████ | 9/10 [00:27<00:03,  3.09s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Aggregating statistics:  10%|█         | 1/10 [00:00<00:03,  2.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  60%|██████    | 6/10 [00:20<00:13,  3.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  60%|██████    | 6/10 [00:09<00:06,  1.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  60%|██████    | 6/10 [00:12<00:08,  2.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Aggregating statistics:  90%|█████████ | 9/10 [00:28<00:03,  3.14s/it]\u001b[A\n",
      "\n",
      "Aggregating statistics:  20%|██        | 2/10 [00:01<00:07,  1.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  60%|██████    | 6/10 [00:06<00:04,  1.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Aggregating statistics: 100%|██████████| 10/10 [00:29<00:00,  2.99s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Aggregating statistics:  30%|███       | 3/10 [00:03<00:09,  1.38s/it]\u001b[A\u001b[A/tmp/ipykernel_2513515/2329706948.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row_df], ignore_index=True)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  70%|███████   | 7/10 [00:11<00:05,  1.84s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  70%|███████   | 7/10 [00:14<00:06,  2.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hyperparameters': {'n_inputs': 1000, 'context_length': 256}, 'eval_results': {'l2_loss': 1.73408043384552, 'l1_loss': 18.087629318237305, 'l0': 12.952000617980957, 'frac_alive': 0.0007905273814685643, 'frac_variance_explained': 0.9730545878410339, 'cossim': 0.9698538184165955, 'l2_ratio': 0.9646522402763367}}\n",
      "Finished ../autoencoders/group-2024-05-07/PAnnealTrainer-chess-alpha0.05011872947216034L_p^p/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  70%|███████   | 7/10 [00:08<00:04,  1.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Aggregating statistics:  70%|███████   | 7/10 [00:24<00:10,  3.44s/it]\u001b[A\u001b[A\n",
      "Aggregating statistics: 100%|██████████| 10/10 [00:31<00:00,  3.19s/it]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "/tmp/ipykernel_2513515/2329706948.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row_df], ignore_index=True)\n",
      "Aggregating statistics:  80%|████████  | 8/10 [00:13<00:03,  1.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Aggregating statistics:  50%|█████     | 5/10 [00:05<00:05,  1.15s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hyperparameters': {'n_inputs': 1000, 'context_length': 256}, 'eval_results': {'l2_loss': 1.699897050857544, 'l1_loss': 19.32272720336914, 'l0': 16.142000198364258, 'frac_alive': 0.0009852295042946935, 'frac_variance_explained': 0.9766021370887756, 'cossim': 0.9721130728721619, 'l2_ratio': 0.9680718779563904}}\n",
      "Finished ../autoencoders/group-2024-05-07/PAnnealTrainer-chess-alpha0.04466836154460907L_p^p/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  80%|████████  | 8/10 [00:16<00:04,  2.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  80%|████████  | 8/10 [00:10<00:03,  1.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  90%|█████████ | 9/10 [00:14<00:01,  1.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Aggregating statistics:  60%|██████    | 6/10 [00:06<00:04,  1.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  90%|█████████ | 9/10 [00:11<00:01,  1.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Aggregating statistics:  70%|███████   | 7/10 [00:07<00:03,  1.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  90%|█████████ | 9/10 [00:18<00:02,  2.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics: 100%|██████████| 10/10 [00:15<00:00,  1.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics: 100%|██████████| 10/10 [00:12<00:00,  1.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Aggregating statistics:  80%|████████  | 8/10 [00:27<00:06,  3.49s/it]/tmp/ipykernel_2513515/2329706948.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row_df], ignore_index=True)\n",
      "\n",
      "\n",
      "Aggregating statistics:  80%|████████  | 8/10 [00:08<00:02,  1.19s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hyperparameters': {'n_inputs': 1000, 'context_length': 256}, 'eval_results': {'l2_loss': 2.1417288780212402, 'l1_loss': 20.995946884155273, 'l0': 10.462000846862793, 'frac_alive': 0.0006385498563759029, 'frac_variance_explained': 0.9608203768730164, 'cossim': 0.9563363194465637, 'l2_ratio': 0.9557435512542725}}\n",
      "Finished ../autoencoders/group-2024-05-07/GatedSAETrainer-chess-alpha1.4125375747680664/\n",
      "Nonzero classifiers per feature per threshold: tensor([1233, 1232, 1217, 1194, 1156, 1101, 1008,  859,  582,  207,    4],\n",
      "       device='cuda:6')\n",
      "Total classified squares per feature per threshold: tensor([19218, 19235, 19212, 19021, 18779, 17957, 17016, 15091, 11725,  5771,\n",
      "          237], device='cuda:6')\n",
      "Out of 5491 features, 1233 were classifiers.\n",
      "The following are counts of squares classified per classifier per feature:\n",
      "Min count: 1, average count: 15.586374282836914, max count: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics: 100%|██████████| 10/10 [00:20<00:00,  2.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Aggregating statistics:  90%|█████████ | 9/10 [00:10<00:01,  1.18s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing board reconstruction\n",
      "WARNING: using manual setting of layer to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\n",
      "Aggregating statistics:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Aggregating statistics: 100%|██████████| 10/10 [00:11<00:00,  1.13s/it]\u001b[A\u001b[A\n",
      "Aggregating statistics:  90%|█████████ | 9/10 [00:31<00:03,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonzero classifiers per feature per threshold: tensor([1567, 1562, 1535, 1503, 1447, 1353, 1215,  986,  615,  185,    5],\n",
      "       device='cuda:5')\n",
      "Total classified squares per feature per threshold: tensor([22558, 22537, 22281, 22241, 21901, 21031, 19315, 16927, 12310,  5615,\n",
      "          320], device='cuda:5')\n",
      "Out of 7152 features, 1567 were classifiers.\n",
      "The following are counts of squares classified per classifier per feature:\n",
      "Min count: 1, average count: 14.395660400390625, max count: 64\n",
      "Testing board reconstruction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Aggregating statistics:  10%|█         | 1/10 [00:01<00:12,  1.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonzero classifiers per feature per threshold: tensor([972, 971, 960, 944, 929, 897, 848, 731, 534, 201,   2],\n",
      "       device='cuda:7')\n",
      "Total classified squares per feature per threshold: tensor([15125, 15216, 15131, 15016, 15203, 15068, 14676, 13231, 10932,  5751,\n",
      "          128], device='cuda:7')\n",
      "Out of 3961 features, 972 were classifiers.\n",
      "The following are counts of squares classified per classifier per feature:\n",
      "Min count: 1, average count: 15.560699462890625, max count: 64\n",
      "WARNING: using manual setting of layer to 5\n",
      "Testing board reconstruction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "Aggregating statistics:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: using manual setting of layer to 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rangell_umass_edu/miniconda3/envs/sae/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Aggregating statistics:  10%|█         | 1/10 [00:00<00:07,  1.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "Aggregating statistics: 100%|██████████| 10/10 [00:34<00:00,  3.47s/it][A\n",
      "\n",
      "\n",
      "Aggregating statistics:  10%|█         | 1/10 [00:02<00:23,  2.66s/it]\u001b[A\u001b[A/tmp/ipykernel_2513515/2329706948.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row_df], ignore_index=True)\n",
      "/tmp/ipykernel_2513515/2329706948.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hyperparameters': {'n_inputs': 1000, 'context_length': 256}, 'eval_results': {'l2_loss': 1.6193091869354248, 'l1_loss': 20.3377628326416, 'l0': 18.822999954223633, 'frac_alive': 0.0011488647432997823, 'frac_variance_explained': 0.9788535237312317, 'cossim': 0.9749823212623596, 'l2_ratio': 0.9709648489952087}}\n",
      "Finished ../autoencoders/group-2024-05-07/PAnnealTrainer-chess-alpha0.03981072083115578L_p^p/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Aggregating statistics:  20%|██        | 2/10 [00:03<00:14,  1.76s/it]\u001b[A\u001b[A\u001b[A\n",
      "Aggregating statistics:  30%|███       | 3/10 [00:06<00:15,  2.26s/it]\u001b[A\n",
      "\n",
      "Aggregating statistics:  20%|██        | 2/10 [00:04<00:19,  2.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Aggregating statistics:  30%|███       | 3/10 [00:04<00:11,  1.68s/it]\u001b[A\u001b[A\u001b[A\n",
      "Aggregating statistics:  40%|████      | 4/10 [00:08<00:13,  2.20s/it]\u001b[A\n",
      "\n",
      "\n",
      "Aggregating statistics:  40%|████      | 4/10 [00:06<00:09,  1.65s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Aggregating statistics:  30%|███       | 3/10 [00:07<00:17,  2.51s/it]\u001b[A\u001b[A\n",
      "Aggregating statistics:  50%|█████     | 5/10 [00:10<00:10,  2.16s/it]\u001b[A\n",
      "\n",
      "\n",
      "Aggregating statistics:  50%|█████     | 5/10 [00:08<00:08,  1.62s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Aggregating statistics:  40%|████      | 4/10 [00:10<00:15,  2.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Aggregating statistics:  60%|██████    | 6/10 [00:09<00:06,  1.66s/it]\u001b[A\u001b[A\u001b[A\n",
      "Aggregating statistics:  60%|██████    | 6/10 [00:12<00:08,  2.19s/it]\u001b[A\n",
      "\n",
      "\n",
      "Aggregating statistics:  70%|███████   | 7/10 [00:11<00:04,  1.66s/it]\u001b[A\u001b[A\u001b[A\n",
      "Aggregating statistics:  70%|███████   | 7/10 [00:14<00:06,  2.16s/it]\u001b[A\n",
      "\n",
      "Aggregating statistics:  50%|█████     | 5/10 [00:12<00:13,  2.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Aggregating statistics:  80%|████████  | 8/10 [00:13<00:03,  1.64s/it]\u001b[A\u001b[A\u001b[A\n",
      "Aggregating statistics:  80%|████████  | 8/10 [00:16<00:04,  2.15s/it]\u001b[A\n",
      "\n",
      "\n",
      "Aggregating statistics:  90%|█████████ | 9/10 [00:14<00:01,  1.63s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Aggregating statistics:  60%|██████    | 6/10 [00:15<00:10,  2.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Aggregating statistics: 100%|██████████| 10/10 [00:16<00:00,  1.62s/it]\u001b[A\u001b[A\u001b[A\n",
      "/tmp/ipykernel_2513515/2329706948.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row_df], ignore_index=True)\n",
      "\n",
      "Aggregating statistics:  90%|█████████ | 9/10 [00:19<00:02,  2.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hyperparameters': {'n_inputs': 1000, 'context_length': 256}, 'eval_results': {'l2_loss': 2.5791163444519043, 'l1_loss': 20.726863861083984, 'l0': 5.12000036239624, 'frac_alive': 0.00031250002211891115, 'frac_variance_explained': 0.9461272358894348, 'cossim': 0.9302018284797668, 'l2_ratio': 0.9287645220756531}}\n",
      "Finished ../autoencoders/group-2024-05-07/GatedAnnealTrainer-chess-alpha0.7943282127380371L_p^p/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Aggregating statistics:  70%|███████   | 7/10 [00:18<00:07,  2.65s/it]\u001b[A\u001b[A\n",
      "Aggregating statistics: 100%|██████████| 10/10 [00:21<00:00,  2.11s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hyperparameters': {'n_inputs': 1000, 'context_length': 256}, 'eval_results': {'l2_loss': 2.1893229484558105, 'l1_loss': 23.305150985717773, 'l0': 7.521000385284424, 'frac_alive': 0.000459045433672145, 'frac_variance_explained': 0.9575729966163635, 'cossim': 0.950599193572998, 'l2_ratio': 0.9501383304595947}}\n",
      "Finished ../autoencoders/group-2024-05-07/GatedAnnealTrainer-chess-alpha0.5623413324356079L_p^p/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2513515/2329706948.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row_df], ignore_index=True)\n",
      "\n",
      "\n",
      "Aggregating statistics:  80%|████████  | 8/10 [00:21<00:05,  2.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "Aggregating statistics:  90%|█████████ | 9/10 [00:24<00:02,  2.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "Aggregating statistics: 100%|██████████| 10/10 [00:27<00:00,  2.71s/it]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hyperparameters': {'n_inputs': 1000, 'context_length': 256}, 'eval_results': {'l2_loss': 1.9210543632507324, 'l1_loss': 26.373027801513672, 'l0': 11.141000747680664, 'frac_alive': 0.0006799927214160562, 'frac_variance_explained': 0.9678363800048828, 'cossim': 0.9638010859489441, 'l2_ratio': 0.9648488759994507}}\n",
      "Finished ../autoencoders/group-2024-05-07/GatedAnnealTrainer-chess-alpha0.3981071710586548L_p^p/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2513515/2329706948.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(eval_sae)\n",
    "importlib.reload(analysis)\n",
    "importlib.reload(test_board_reconstruction)\n",
    "importlib.reload(get_eval_results)\n",
    "import circuits.chess_utils as chess_utils\n",
    "importlib.reload(chess_utils)\n",
    "\n",
    "# NOTE: This script makes a major assumption here: That all autoencoders in a given group are trained on chess XOR Othello\n",
    "# We do this so we don't have to reconstruct the dataset for each autoencoder in the group\n",
    "# autoencoder_group_paths = [\"../autoencoders/othello_layer5_ef4/\"]\n",
    "# autoencoder_group_paths = [\"../autoencoders/chess_layer5/\"]\n",
    "autoencoder_group_paths = [\"../autoencoders/group-2024-05-07/\"]\n",
    "\n",
    "\n",
    "eval_sae_n_inputs = 1000\n",
    "batch_size = 100\n",
    "#device = \"cuda\"\n",
    "model_path = \"../models/\"\n",
    "save_results = True\n",
    "\n",
    "eval_results_n_inputs = 1000\n",
    "board_reconstruction_n_inputs = 1000\n",
    "\n",
    "analysis_high_threshold = 0.95\n",
    "analysis_low_threshold = 0.1\n",
    "analysis_significance_threshold = 10\n",
    "\n",
    "run_eval_results = True # We don't check for this as eval_results are pretty quick to collect\n",
    "\n",
    "# To skip any of the following steps, set the corresponding variable to False\n",
    "# The results must have been saved previously\n",
    "run_eval_sae = True\n",
    "run_analysis = True\n",
    "run_board_reconstruction = True\n",
    "\n",
    "dataset_size = max(eval_sae_n_inputs, eval_results_n_inputs, board_reconstruction_n_inputs)\n",
    "\n",
    "if dataset_size == eval_results_n_inputs:\n",
    "    dataset_size *= 2\n",
    "\n",
    "for autoencoder_group_path in autoencoder_group_paths:\n",
    "    othello = eval_sae.check_if_autoencoder_is_othello(autoencoder_group_path)\n",
    "\n",
    "    indexing_functions = eval_sae.get_recommended_indexing_functions(othello)\n",
    "    indexing_function = indexing_functions[0]\n",
    "\n",
    "    custom_functions = eval_sae.get_recommended_custom_functions(othello)\n",
    "\n",
    "    model_name = eval_sae.get_model_name(othello)\n",
    "\n",
    "    precompute = True\n",
    "\n",
    "    print(\"Constructing evaluation dataset\")\n",
    "    device = RESOURCE_STACK.pop()\n",
    "    data = eval_sae.construct_dataset(othello, custom_functions, dataset_size, device, models_path=model_path)\n",
    "    RESOURCE_STACK.append(device)\n",
    "    del device\n",
    "    \n",
    "    folders = eval_sae.get_nested_folders(autoencoder_group_path)\n",
    "\n",
    "    def full_eval_pipeline(autoencoder_path):\n",
    "        \n",
    "        # Grab a GPU off the stack to use\n",
    "        device = RESOURCE_STACK.pop()\n",
    "        \n",
    "        # For debugging\n",
    "        # if \"ef=4_lr=1e-03_l1=1e-01_layer=5\" not in autoencoder_path:\n",
    "        #     continue\n",
    "\n",
    "        # If this is set, everything below should be reproducible\n",
    "        # Then we can just save results from 1 run, make optimizations, and check that the results are the same\n",
    "        # The determinism is only needed for getting activations from the activation buffer for finding alive features\n",
    "        torch.manual_seed(0)\n",
    "        eval_results = get_eval_results.get_evals(\n",
    "            autoencoder_path,\n",
    "            eval_results_n_inputs,\n",
    "            device,\n",
    "            model_path,\n",
    "            model_name,\n",
    "            to_device(data.copy(), device),\n",
    "            othello=othello,\n",
    "            save_results=save_results,\n",
    "        )\n",
    "\n",
    "\n",
    "        expected_aggregation_output_location = eval_sae.get_output_location(\n",
    "                autoencoder_path, n_inputs=eval_sae_n_inputs, indexing_function=indexing_function\n",
    "            )\n",
    "        \n",
    "        if run_eval_sae:\n",
    "            print(\"Aggregating\", autoencoder_path)\n",
    "            aggregation_results = (\n",
    "                eval_sae.aggregate_statistics(\n",
    "                    custom_functions=custom_functions,\n",
    "                    autoencoder_path=autoencoder_path,\n",
    "                    n_inputs=eval_sae_n_inputs,\n",
    "                    batch_size=batch_size,\n",
    "                    device=device,\n",
    "                    model_path=model_path,\n",
    "                    model_name=model_name,\n",
    "                    data=to_device(data.copy(), device),\n",
    "                    indexing_function=indexing_function,\n",
    "                    othello=othello,\n",
    "                    save_results=save_results,\n",
    "                    precomputed=precompute,\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            with open(expected_aggregation_output_location, \"rb\") as f:\n",
    "                aggregation_results = pickle.load(f)\n",
    "\n",
    "        expected_feature_labels_output_location = expected_aggregation_output_location.replace(\n",
    "            \"results.pkl\", \"feature_labels.pkl\"\n",
    "        )\n",
    "        if run_analysis:\n",
    "            feature_labels = analysis.analyze_results_dict(\n",
    "                aggregation_results,\n",
    "                output_path=expected_feature_labels_output_location,\n",
    "                device=device,\n",
    "                high_threshold=analysis_high_threshold,\n",
    "                low_threshold=analysis_low_threshold,\n",
    "                significance_threshold=analysis_significance_threshold,\n",
    "                verbose=False,\n",
    "                print_results=False,\n",
    "                save_results=save_results,\n",
    "            )\n",
    "        else:\n",
    "            with open(expected_feature_labels_output_location, \"rb\") as f:\n",
    "                feature_labels = pickle.load(f)\n",
    "\n",
    "        expected_reconstruction_output_location = expected_aggregation_output_location.replace(\n",
    "            \"results.pkl\", \"reconstruction.pkl\"\n",
    "        )\n",
    "\n",
    "        if run_board_reconstruction:\n",
    "            print(\"Testing board reconstruction\")\n",
    "            board_reconstruction_results = test_board_reconstruction.test_board_reconstructions(\n",
    "                    custom_functions=custom_functions,\n",
    "                    autoencoder_path=autoencoder_path,\n",
    "                    feature_labels=feature_labels,\n",
    "                    output_file=expected_reconstruction_output_location,\n",
    "                    n_inputs=board_reconstruction_n_inputs,\n",
    "                    batch_size=batch_size,\n",
    "                    device=device,\n",
    "                    model_name=model_name,\n",
    "                    data=to_device(data.copy(), device),\n",
    "                    othello=othello,\n",
    "                    print_results=False,\n",
    "                    save_results=save_results,\n",
    "            )\n",
    "        else:\n",
    "            with open(expected_reconstruction_output_location, \"rb\") as f:\n",
    "                board_reconstruction_results = pickle.load(f)\n",
    "\n",
    "        df = initialize_dataframe()\n",
    "        df = append_results(\n",
    "            eval_results,\n",
    "            board_reconstruction_results,\n",
    "            custom_functions,\n",
    "            df,\n",
    "            autoencoder_group_path,\n",
    "            autoencoder_path,\n",
    "            expected_reconstruction_output_location,\n",
    "        )\n",
    "\n",
    "        print(\"Finished\", autoencoder_path)\n",
    "\n",
    "        # Save the dataframe after each autoencoder so we don't lose data if the script crashes\n",
    "        output_file = autoencoder_path + \"/\" + \"results.csv\"\n",
    "        df.to_csv(output_file)\n",
    "        \n",
    "        # Put the GPU back on the stack after we're done\n",
    "        RESOURCE_STACK.append(device)\n",
    "        return df\n",
    "    \n",
    "    dfs = Parallel(n_jobs=N_GPUS, require=\"sharedmem\")(delayed(full_eval_pipeline)(autoencoder_path) for autoencoder_path in folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2513515/614852007.py:2: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat(dfs, axis=0, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>autoencoder_group_path</th>\n",
       "      <th>autoencoder_path</th>\n",
       "      <th>reconstruction_file</th>\n",
       "      <th>eval_results_n_inputs</th>\n",
       "      <th>l0</th>\n",
       "      <th>l1_loss</th>\n",
       "      <th>l2_loss</th>\n",
       "      <th>frac_alive</th>\n",
       "      <th>frac_variance_explained</th>\n",
       "      <th>cossim</th>\n",
       "      <th>...</th>\n",
       "      <th>zero_num_true_positive_squares</th>\n",
       "      <th>best_num_true_positive_squares</th>\n",
       "      <th>zero_num_false_positive_squares</th>\n",
       "      <th>best_num_false_positive_squares</th>\n",
       "      <th>zero_percent_active_classifiers</th>\n",
       "      <th>best_percent_active_classifiers</th>\n",
       "      <th>zero_classifiers_per_token</th>\n",
       "      <th>best_classifiers_per_token</th>\n",
       "      <th>zero_classified_per_token</th>\n",
       "      <th>best_classified_per_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../autoencoders/group-2024-05-07/</td>\n",
       "      <td>../autoencoders/group-2024-05-07/StandardTrain...</td>\n",
       "      <td>../autoencoders/group-2024-05-07/StandardTrain...</td>\n",
       "      <td>1000</td>\n",
       "      <td>49.828003</td>\n",
       "      <td>16.864666</td>\n",
       "      <td>1.627392</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>0.977771</td>\n",
       "      <td>0.974109</td>\n",
       "      <td>...</td>\n",
       "      <td>653280</td>\n",
       "      <td>0</td>\n",
       "      <td>34524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../autoencoders/group-2024-05-07/</td>\n",
       "      <td>../autoencoders/group-2024-05-07/StandardTrain...</td>\n",
       "      <td>../autoencoders/group-2024-05-07/StandardTrain...</td>\n",
       "      <td>1000</td>\n",
       "      <td>49.828003</td>\n",
       "      <td>16.864666</td>\n",
       "      <td>1.627392</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>0.977771</td>\n",
       "      <td>0.974109</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../autoencoders/group-2024-05-07/</td>\n",
       "      <td>../autoencoders/group-2024-05-07/StandardTrain...</td>\n",
       "      <td>../autoencoders/group-2024-05-07/StandardTrain...</td>\n",
       "      <td>1000</td>\n",
       "      <td>37.215000</td>\n",
       "      <td>15.704080</td>\n",
       "      <td>1.813791</td>\n",
       "      <td>0.002271</td>\n",
       "      <td>0.972351</td>\n",
       "      <td>0.967721</td>\n",
       "      <td>...</td>\n",
       "      <td>609570</td>\n",
       "      <td>0</td>\n",
       "      <td>30270</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../autoencoders/group-2024-05-07/</td>\n",
       "      <td>../autoencoders/group-2024-05-07/StandardTrain...</td>\n",
       "      <td>../autoencoders/group-2024-05-07/StandardTrain...</td>\n",
       "      <td>1000</td>\n",
       "      <td>37.215000</td>\n",
       "      <td>15.704080</td>\n",
       "      <td>1.813791</td>\n",
       "      <td>0.002271</td>\n",
       "      <td>0.972351</td>\n",
       "      <td>0.967721</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../autoencoders/group-2024-05-07/</td>\n",
       "      <td>../autoencoders/group-2024-05-07/StandardTrain...</td>\n",
       "      <td>../autoencoders/group-2024-05-07/StandardTrain...</td>\n",
       "      <td>1000</td>\n",
       "      <td>27.304001</td>\n",
       "      <td>14.537116</td>\n",
       "      <td>2.022861</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.965702</td>\n",
       "      <td>0.959808</td>\n",
       "      <td>...</td>\n",
       "      <td>587846</td>\n",
       "      <td>0</td>\n",
       "      <td>27072</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>../autoencoders/group-2024-05-07/</td>\n",
       "      <td>../autoencoders/group-2024-05-07/StandardTrain...</td>\n",
       "      <td>../autoencoders/group-2024-05-07/StandardTrain...</td>\n",
       "      <td>1000</td>\n",
       "      <td>27.304001</td>\n",
       "      <td>14.537116</td>\n",
       "      <td>2.022861</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.965702</td>\n",
       "      <td>0.959808</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>../autoencoders/group-2024-05-07/</td>\n",
       "      <td>../autoencoders/group-2024-05-07/PAnnealTraine...</td>\n",
       "      <td>../autoencoders/group-2024-05-07/PAnnealTraine...</td>\n",
       "      <td>1000</td>\n",
       "      <td>18.823000</td>\n",
       "      <td>20.337763</td>\n",
       "      <td>1.619309</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.978854</td>\n",
       "      <td>0.974982</td>\n",
       "      <td>...</td>\n",
       "      <td>816315</td>\n",
       "      <td>0</td>\n",
       "      <td>32057</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>../autoencoders/group-2024-05-07/</td>\n",
       "      <td>../autoencoders/group-2024-05-07/PAnnealTraine...</td>\n",
       "      <td>../autoencoders/group-2024-05-07/PAnnealTraine...</td>\n",
       "      <td>1000</td>\n",
       "      <td>18.823000</td>\n",
       "      <td>20.337763</td>\n",
       "      <td>1.619309</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.978854</td>\n",
       "      <td>0.974982</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>../autoencoders/group-2024-05-07/</td>\n",
       "      <td>../autoencoders/group-2024-05-07/PAnnealTraine...</td>\n",
       "      <td>../autoencoders/group-2024-05-07/PAnnealTraine...</td>\n",
       "      <td>1000</td>\n",
       "      <td>16.142000</td>\n",
       "      <td>19.322727</td>\n",
       "      <td>1.699897</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.976602</td>\n",
       "      <td>0.972113</td>\n",
       "      <td>...</td>\n",
       "      <td>812246</td>\n",
       "      <td>867426</td>\n",
       "      <td>29864</td>\n",
       "      <td>24811</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>../autoencoders/group-2024-05-07/</td>\n",
       "      <td>../autoencoders/group-2024-05-07/PAnnealTraine...</td>\n",
       "      <td>../autoencoders/group-2024-05-07/PAnnealTraine...</td>\n",
       "      <td>1000</td>\n",
       "      <td>16.142000</td>\n",
       "      <td>19.322727</td>\n",
       "      <td>1.699897</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.976602</td>\n",
       "      <td>0.972113</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>../autoencoders/group-2024-05-07/</td>\n",
       "      <td>../autoencoders/group-2024-05-07/PAnnealTraine...</td>\n",
       "      <td>../autoencoders/group-2024-05-07/PAnnealTraine...</td>\n",
       "      <td>1000</td>\n",
       "      <td>12.952001</td>\n",
       "      <td>18.087629</td>\n",
       "      <td>1.734080</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.973055</td>\n",
       "      <td>0.969854</td>\n",
       "      <td>...</td>\n",
       "      <td>810815</td>\n",
       "      <td>847587</td>\n",
       "      <td>27773</td>\n",
       "      <td>22844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>../autoencoders/group-2024-05-07/</td>\n",
       "      <td>../autoencoders/group-2024-05-07/PAnnealTraine...</td>\n",
       "      <td>../autoencoders/group-2024-05-07/PAnnealTraine...</td>\n",
       "      <td>1000</td>\n",
       "      <td>12.952001</td>\n",
       "      <td>18.087629</td>\n",
       "      <td>1.734080</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.973055</td>\n",
       "      <td>0.969854</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>../autoencoders/group-2024-05-07/</td>\n",
       "      <td>../autoencoders/group-2024-05-07/GatedSAETrain...</td>\n",
       "      <td>../autoencoders/group-2024-05-07/GatedSAETrain...</td>\n",
       "      <td>1000</td>\n",
       "      <td>22.929001</td>\n",
       "      <td>24.734552</td>\n",
       "      <td>1.625560</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.979567</td>\n",
       "      <td>0.976368</td>\n",
       "      <td>...</td>\n",
       "      <td>719368</td>\n",
       "      <td>793975</td>\n",
       "      <td>35514</td>\n",
       "      <td>23217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>../autoencoders/group-2024-05-07/</td>\n",
       "      <td>../autoencoders/group-2024-05-07/GatedSAETrain...</td>\n",
       "      <td>../autoencoders/group-2024-05-07/GatedSAETrain...</td>\n",
       "      <td>1000</td>\n",
       "      <td>22.929001</td>\n",
       "      <td>24.734552</td>\n",
       "      <td>1.625560</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.979567</td>\n",
       "      <td>0.976368</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>../autoencoders/group-2024-05-07/</td>\n",
       "      <td>../autoencoders/group-2024-05-07/GatedSAETrain...</td>\n",
       "      <td>../autoencoders/group-2024-05-07/GatedSAETrain...</td>\n",
       "      <td>1000</td>\n",
       "      <td>15.707001</td>\n",
       "      <td>23.012341</td>\n",
       "      <td>1.869859</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.972918</td>\n",
       "      <td>0.968239</td>\n",
       "      <td>...</td>\n",
       "      <td>700080</td>\n",
       "      <td>738885</td>\n",
       "      <td>30036</td>\n",
       "      <td>19790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>../autoencoders/group-2024-05-07/</td>\n",
       "      <td>../autoencoders/group-2024-05-07/GatedSAETrain...</td>\n",
       "      <td>../autoencoders/group-2024-05-07/GatedSAETrain...</td>\n",
       "      <td>1000</td>\n",
       "      <td>15.707001</td>\n",
       "      <td>23.012341</td>\n",
       "      <td>1.869859</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.972918</td>\n",
       "      <td>0.968239</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>../autoencoders/group-2024-05-07/</td>\n",
       "      <td>../autoencoders/group-2024-05-07/GatedSAETrain...</td>\n",
       "      <td>../autoencoders/group-2024-05-07/GatedSAETrain...</td>\n",
       "      <td>1000</td>\n",
       "      <td>10.462001</td>\n",
       "      <td>20.995947</td>\n",
       "      <td>2.141729</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.960820</td>\n",
       "      <td>0.956336</td>\n",
       "      <td>...</td>\n",
       "      <td>660149</td>\n",
       "      <td>669640</td>\n",
       "      <td>25080</td>\n",
       "      <td>16998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>../autoencoders/group-2024-05-07/</td>\n",
       "      <td>../autoencoders/group-2024-05-07/GatedSAETrain...</td>\n",
       "      <td>../autoencoders/group-2024-05-07/GatedSAETrain...</td>\n",
       "      <td>1000</td>\n",
       "      <td>10.462001</td>\n",
       "      <td>20.995947</td>\n",
       "      <td>2.141729</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.960820</td>\n",
       "      <td>0.956336</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>../autoencoders/group-2024-05-07/</td>\n",
       "      <td>../autoencoders/group-2024-05-07/GatedAnnealTr...</td>\n",
       "      <td>../autoencoders/group-2024-05-07/GatedAnnealTr...</td>\n",
       "      <td>1000</td>\n",
       "      <td>11.141001</td>\n",
       "      <td>26.373028</td>\n",
       "      <td>1.921054</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.967836</td>\n",
       "      <td>0.963801</td>\n",
       "      <td>...</td>\n",
       "      <td>733778</td>\n",
       "      <td>736523</td>\n",
       "      <td>19536</td>\n",
       "      <td>16141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>../autoencoders/group-2024-05-07/</td>\n",
       "      <td>../autoencoders/group-2024-05-07/GatedAnnealTr...</td>\n",
       "      <td>../autoencoders/group-2024-05-07/GatedAnnealTr...</td>\n",
       "      <td>1000</td>\n",
       "      <td>11.141001</td>\n",
       "      <td>26.373028</td>\n",
       "      <td>1.921054</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.967836</td>\n",
       "      <td>0.963801</td>\n",
       "      <td>...</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>../autoencoders/group-2024-05-07/</td>\n",
       "      <td>../autoencoders/group-2024-05-07/GatedAnnealTr...</td>\n",
       "      <td>../autoencoders/group-2024-05-07/GatedAnnealTr...</td>\n",
       "      <td>1000</td>\n",
       "      <td>7.521000</td>\n",
       "      <td>23.305151</td>\n",
       "      <td>2.189323</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.957573</td>\n",
       "      <td>0.950599</td>\n",
       "      <td>...</td>\n",
       "      <td>671518</td>\n",
       "      <td>672333</td>\n",
       "      <td>14906</td>\n",
       "      <td>14191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>../autoencoders/group-2024-05-07/</td>\n",
       "      <td>../autoencoders/group-2024-05-07/GatedAnnealTr...</td>\n",
       "      <td>../autoencoders/group-2024-05-07/GatedAnnealTr...</td>\n",
       "      <td>1000</td>\n",
       "      <td>7.521000</td>\n",
       "      <td>23.305151</td>\n",
       "      <td>2.189323</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.957573</td>\n",
       "      <td>0.950599</td>\n",
       "      <td>...</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>../autoencoders/group-2024-05-07/</td>\n",
       "      <td>../autoencoders/group-2024-05-07/GatedAnnealTr...</td>\n",
       "      <td>../autoencoders/group-2024-05-07/GatedAnnealTr...</td>\n",
       "      <td>1000</td>\n",
       "      <td>5.120000</td>\n",
       "      <td>20.726864</td>\n",
       "      <td>2.579116</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.946127</td>\n",
       "      <td>0.930202</td>\n",
       "      <td>...</td>\n",
       "      <td>624442</td>\n",
       "      <td>634445</td>\n",
       "      <td>13928</td>\n",
       "      <td>13387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>../autoencoders/group-2024-05-07/</td>\n",
       "      <td>../autoencoders/group-2024-05-07/GatedAnnealTr...</td>\n",
       "      <td>../autoencoders/group-2024-05-07/GatedAnnealTr...</td>\n",
       "      <td>1000</td>\n",
       "      <td>5.120000</td>\n",
       "      <td>20.726864</td>\n",
       "      <td>2.579116</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.946127</td>\n",
       "      <td>0.930202</td>\n",
       "      <td>...</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               autoencoder_group_path  \\\n",
       "0   ../autoencoders/group-2024-05-07/   \n",
       "1   ../autoencoders/group-2024-05-07/   \n",
       "2   ../autoencoders/group-2024-05-07/   \n",
       "3   ../autoencoders/group-2024-05-07/   \n",
       "4   ../autoencoders/group-2024-05-07/   \n",
       "5   ../autoencoders/group-2024-05-07/   \n",
       "6   ../autoencoders/group-2024-05-07/   \n",
       "7   ../autoencoders/group-2024-05-07/   \n",
       "8   ../autoencoders/group-2024-05-07/   \n",
       "9   ../autoencoders/group-2024-05-07/   \n",
       "10  ../autoencoders/group-2024-05-07/   \n",
       "11  ../autoencoders/group-2024-05-07/   \n",
       "12  ../autoencoders/group-2024-05-07/   \n",
       "13  ../autoencoders/group-2024-05-07/   \n",
       "14  ../autoencoders/group-2024-05-07/   \n",
       "15  ../autoencoders/group-2024-05-07/   \n",
       "16  ../autoencoders/group-2024-05-07/   \n",
       "17  ../autoencoders/group-2024-05-07/   \n",
       "18  ../autoencoders/group-2024-05-07/   \n",
       "19  ../autoencoders/group-2024-05-07/   \n",
       "20  ../autoencoders/group-2024-05-07/   \n",
       "21  ../autoencoders/group-2024-05-07/   \n",
       "22  ../autoencoders/group-2024-05-07/   \n",
       "23  ../autoencoders/group-2024-05-07/   \n",
       "\n",
       "                                     autoencoder_path  \\\n",
       "0   ../autoencoders/group-2024-05-07/StandardTrain...   \n",
       "1   ../autoencoders/group-2024-05-07/StandardTrain...   \n",
       "2   ../autoencoders/group-2024-05-07/StandardTrain...   \n",
       "3   ../autoencoders/group-2024-05-07/StandardTrain...   \n",
       "4   ../autoencoders/group-2024-05-07/StandardTrain...   \n",
       "5   ../autoencoders/group-2024-05-07/StandardTrain...   \n",
       "6   ../autoencoders/group-2024-05-07/PAnnealTraine...   \n",
       "7   ../autoencoders/group-2024-05-07/PAnnealTraine...   \n",
       "8   ../autoencoders/group-2024-05-07/PAnnealTraine...   \n",
       "9   ../autoencoders/group-2024-05-07/PAnnealTraine...   \n",
       "10  ../autoencoders/group-2024-05-07/PAnnealTraine...   \n",
       "11  ../autoencoders/group-2024-05-07/PAnnealTraine...   \n",
       "12  ../autoencoders/group-2024-05-07/GatedSAETrain...   \n",
       "13  ../autoencoders/group-2024-05-07/GatedSAETrain...   \n",
       "14  ../autoencoders/group-2024-05-07/GatedSAETrain...   \n",
       "15  ../autoencoders/group-2024-05-07/GatedSAETrain...   \n",
       "16  ../autoencoders/group-2024-05-07/GatedSAETrain...   \n",
       "17  ../autoencoders/group-2024-05-07/GatedSAETrain...   \n",
       "18  ../autoencoders/group-2024-05-07/GatedAnnealTr...   \n",
       "19  ../autoencoders/group-2024-05-07/GatedAnnealTr...   \n",
       "20  ../autoencoders/group-2024-05-07/GatedAnnealTr...   \n",
       "21  ../autoencoders/group-2024-05-07/GatedAnnealTr...   \n",
       "22  ../autoencoders/group-2024-05-07/GatedAnnealTr...   \n",
       "23  ../autoencoders/group-2024-05-07/GatedAnnealTr...   \n",
       "\n",
       "                                  reconstruction_file eval_results_n_inputs  \\\n",
       "0   ../autoencoders/group-2024-05-07/StandardTrain...                  1000   \n",
       "1   ../autoencoders/group-2024-05-07/StandardTrain...                  1000   \n",
       "2   ../autoencoders/group-2024-05-07/StandardTrain...                  1000   \n",
       "3   ../autoencoders/group-2024-05-07/StandardTrain...                  1000   \n",
       "4   ../autoencoders/group-2024-05-07/StandardTrain...                  1000   \n",
       "5   ../autoencoders/group-2024-05-07/StandardTrain...                  1000   \n",
       "6   ../autoencoders/group-2024-05-07/PAnnealTraine...                  1000   \n",
       "7   ../autoencoders/group-2024-05-07/PAnnealTraine...                  1000   \n",
       "8   ../autoencoders/group-2024-05-07/PAnnealTraine...                  1000   \n",
       "9   ../autoencoders/group-2024-05-07/PAnnealTraine...                  1000   \n",
       "10  ../autoencoders/group-2024-05-07/PAnnealTraine...                  1000   \n",
       "11  ../autoencoders/group-2024-05-07/PAnnealTraine...                  1000   \n",
       "12  ../autoencoders/group-2024-05-07/GatedSAETrain...                  1000   \n",
       "13  ../autoencoders/group-2024-05-07/GatedSAETrain...                  1000   \n",
       "14  ../autoencoders/group-2024-05-07/GatedSAETrain...                  1000   \n",
       "15  ../autoencoders/group-2024-05-07/GatedSAETrain...                  1000   \n",
       "16  ../autoencoders/group-2024-05-07/GatedSAETrain...                  1000   \n",
       "17  ../autoencoders/group-2024-05-07/GatedSAETrain...                  1000   \n",
       "18  ../autoencoders/group-2024-05-07/GatedAnnealTr...                  1000   \n",
       "19  ../autoencoders/group-2024-05-07/GatedAnnealTr...                  1000   \n",
       "20  ../autoencoders/group-2024-05-07/GatedAnnealTr...                  1000   \n",
       "21  ../autoencoders/group-2024-05-07/GatedAnnealTr...                  1000   \n",
       "22  ../autoencoders/group-2024-05-07/GatedAnnealTr...                  1000   \n",
       "23  ../autoencoders/group-2024-05-07/GatedAnnealTr...                  1000   \n",
       "\n",
       "           l0    l1_loss   l2_loss  frac_alive  frac_variance_explained  \\\n",
       "0   49.828003  16.864666  1.627392    0.003041                 0.977771   \n",
       "1   49.828003  16.864666  1.627392    0.003041                 0.977771   \n",
       "2   37.215000  15.704080  1.813791    0.002271                 0.972351   \n",
       "3   37.215000  15.704080  1.813791    0.002271                 0.972351   \n",
       "4   27.304001  14.537116  2.022861    0.001667                 0.965702   \n",
       "5   27.304001  14.537116  2.022861    0.001667                 0.965702   \n",
       "6   18.823000  20.337763  1.619309    0.001149                 0.978854   \n",
       "7   18.823000  20.337763  1.619309    0.001149                 0.978854   \n",
       "8   16.142000  19.322727  1.699897    0.000985                 0.976602   \n",
       "9   16.142000  19.322727  1.699897    0.000985                 0.976602   \n",
       "10  12.952001  18.087629  1.734080    0.000791                 0.973055   \n",
       "11  12.952001  18.087629  1.734080    0.000791                 0.973055   \n",
       "12  22.929001  24.734552  1.625560    0.001399                 0.979567   \n",
       "13  22.929001  24.734552  1.625560    0.001399                 0.979567   \n",
       "14  15.707001  23.012341  1.869859    0.000959                 0.972918   \n",
       "15  15.707001  23.012341  1.869859    0.000959                 0.972918   \n",
       "16  10.462001  20.995947  2.141729    0.000639                 0.960820   \n",
       "17  10.462001  20.995947  2.141729    0.000639                 0.960820   \n",
       "18  11.141001  26.373028  1.921054    0.000680                 0.967836   \n",
       "19  11.141001  26.373028  1.921054    0.000680                 0.967836   \n",
       "20   7.521000  23.305151  2.189323    0.000459                 0.957573   \n",
       "21   7.521000  23.305151  2.189323    0.000459                 0.957573   \n",
       "22   5.120000  20.726864  2.579116    0.000313                 0.946127   \n",
       "23   5.120000  20.726864  2.579116    0.000313                 0.946127   \n",
       "\n",
       "      cossim  ...  zero_num_true_positive_squares  \\\n",
       "0   0.974109  ...                          653280   \n",
       "1   0.974109  ...                              14   \n",
       "2   0.967721  ...                          609570   \n",
       "3   0.967721  ...                               0   \n",
       "4   0.959808  ...                          587846   \n",
       "5   0.959808  ...                               0   \n",
       "6   0.974982  ...                          816315   \n",
       "7   0.974982  ...                               0   \n",
       "8   0.972113  ...                          812246   \n",
       "9   0.972113  ...                              51   \n",
       "10  0.969854  ...                          810815   \n",
       "11  0.969854  ...                              14   \n",
       "12  0.976368  ...                          719368   \n",
       "13  0.976368  ...                               0   \n",
       "14  0.968239  ...                          700080   \n",
       "15  0.968239  ...                               0   \n",
       "16  0.956336  ...                          660149   \n",
       "17  0.956336  ...                               0   \n",
       "18  0.963801  ...                          733778   \n",
       "19  0.963801  ...                             236   \n",
       "20  0.950599  ...                          671518   \n",
       "21  0.950599  ...                             182   \n",
       "22  0.930202  ...                          624442   \n",
       "23  0.930202  ...                             107   \n",
       "\n",
       "   best_num_true_positive_squares zero_num_false_positive_squares  \\\n",
       "0                               0                           34524   \n",
       "1                               0                               0   \n",
       "2                               0                           30270   \n",
       "3                               0                               0   \n",
       "4                               0                           27072   \n",
       "5                               0                               0   \n",
       "6                               0                           32057   \n",
       "7                               0                               0   \n",
       "8                          867426                           29864   \n",
       "9                               0                               0   \n",
       "10                         847587                           27773   \n",
       "11                              0                               0   \n",
       "12                         793975                           35514   \n",
       "13                              0                               0   \n",
       "14                         738885                           30036   \n",
       "15                              0                               0   \n",
       "16                         669640                           25080   \n",
       "17                              0                               0   \n",
       "18                         736523                           19536   \n",
       "19                              0                               7   \n",
       "20                         672333                           14906   \n",
       "21                              0                               2   \n",
       "22                         634445                           13928   \n",
       "23                              0                               1   \n",
       "\n",
       "   best_num_false_positive_squares  zero_percent_active_classifiers  \\\n",
       "0                                0                              0.0   \n",
       "1                                0                              0.0   \n",
       "2                                0                              0.0   \n",
       "3                                0                              0.0   \n",
       "4                                0                              0.0   \n",
       "5                                0                              0.0   \n",
       "6                                0                              0.0   \n",
       "7                                0                              0.0   \n",
       "8                            24811                              0.0   \n",
       "9                                0                              0.0   \n",
       "10                           22844                              0.0   \n",
       "11                               0                              0.0   \n",
       "12                           23217                              0.0   \n",
       "13                               0                              0.0   \n",
       "14                           19790                              0.0   \n",
       "15                               0                              0.0   \n",
       "16                           16998                              0.0   \n",
       "17                               0                              0.0   \n",
       "18                           16141                              0.0   \n",
       "19                               0                              0.0   \n",
       "20                           14191                              0.0   \n",
       "21                               0                              0.0   \n",
       "22                           13387                              0.0   \n",
       "23                               0                              0.0   \n",
       "\n",
       "    best_percent_active_classifiers  zero_classifiers_per_token  \\\n",
       "0                               0.0                         0.0   \n",
       "1                               0.0                         0.0   \n",
       "2                               0.0                         0.0   \n",
       "3                               0.0                         0.0   \n",
       "4                               0.0                         0.0   \n",
       "5                               0.0                         0.0   \n",
       "6                               0.0                         0.0   \n",
       "7                               0.0                         0.0   \n",
       "8                               0.0                         0.0   \n",
       "9                               0.0                         0.0   \n",
       "10                              0.0                         0.0   \n",
       "11                              0.0                         0.0   \n",
       "12                              0.0                         0.0   \n",
       "13                              0.0                         0.0   \n",
       "14                              0.0                         0.0   \n",
       "15                              0.0                         0.0   \n",
       "16                              0.0                         0.0   \n",
       "17                              0.0                         0.0   \n",
       "18                              0.0                         0.0   \n",
       "19                              0.0                         0.0   \n",
       "20                              0.0                         0.0   \n",
       "21                              0.0                         0.0   \n",
       "22                              0.0                         0.0   \n",
       "23                              0.0                         0.0   \n",
       "\n",
       "    best_classifiers_per_token zero_classified_per_token  \\\n",
       "0                          0.0                       0.0   \n",
       "1                          0.0                       0.0   \n",
       "2                          0.0                       0.0   \n",
       "3                          0.0                       0.0   \n",
       "4                          0.0                       0.0   \n",
       "5                          0.0                       0.0   \n",
       "6                          0.0                       0.0   \n",
       "7                          0.0                       0.0   \n",
       "8                          0.0                       0.0   \n",
       "9                          0.0                       0.0   \n",
       "10                         0.0                       0.0   \n",
       "11                         0.0                       0.0   \n",
       "12                         0.0                       0.0   \n",
       "13                         0.0                       0.0   \n",
       "14                         0.0                       0.0   \n",
       "15                         0.0                       0.0   \n",
       "16                         0.0                       0.0   \n",
       "17                         0.0                       0.0   \n",
       "18                         0.0                       0.0   \n",
       "19                         0.0                       0.0   \n",
       "20                         0.0                       0.0   \n",
       "21                         0.0                       0.0   \n",
       "22                         0.0                       0.0   \n",
       "23                         0.0                       0.0   \n",
       "\n",
       "   best_classified_per_token  \n",
       "0                        0.0  \n",
       "1                        0.0  \n",
       "2                        0.0  \n",
       "3                        0.0  \n",
       "4                        0.0  \n",
       "5                        0.0  \n",
       "6                        0.0  \n",
       "7                        0.0  \n",
       "8                        0.0  \n",
       "9                        0.0  \n",
       "10                       0.0  \n",
       "11                       0.0  \n",
       "12                       0.0  \n",
       "13                       0.0  \n",
       "14                       0.0  \n",
       "15                       0.0  \n",
       "16                       0.0  \n",
       "17                       0.0  \n",
       "18                       0.0  \n",
       "19                       0.0  \n",
       "20                       0.0  \n",
       "21                       0.0  \n",
       "22                       0.0  \n",
       "23                       0.0  \n",
       "\n",
       "[24 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: merge results.csv from all of the folders\n",
    "df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of gathering top k contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import circuits.chess_interp as chess_interp\n",
    "importlib.reload(chess_interp)\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "autoencoder_group_path = autoencoder_group_paths[0]\n",
    "\n",
    "othello = eval_sae.check_if_autoencoder_is_othello(autoencoder_group_path)\n",
    "\n",
    "indexing_functions = eval_sae.get_recommended_indexing_functions(othello)\n",
    "indexing_function = indexing_functions[0]\n",
    "\n",
    "custom_functions = eval_sae.get_recommended_custom_functions(othello)\n",
    "\n",
    "model_name = eval_sae.get_model_name(othello)\n",
    "\n",
    "device = RESOURCE_STACK.pop()\n",
    "print(\"Constructing evaluation dataset\")\n",
    "data = eval_sae.construct_dataset(othello, custom_functions, dataset_size, device, models_path=model_path)\n",
    "\n",
    "\n",
    "dataset_size = dataset_size * 2  # x2 to make sure we have enough data for loss_recovered()\n",
    "\n",
    "data, ae_bundle, pgn_strings, encoded_inputs = eval_sae.prep_firing_rate_data(\n",
    "    autoencoder_path, dataset_size, model_path, model_name, data, device, dataset_size, othello\n",
    ")\n",
    "\n",
    "dims = torch.tensor([10], device=device)\n",
    "chess_interp.examine_dimension_chess(ae_bundle, 100, dims)\n",
    "\n",
    "RESOURCE_STACK.append(device)\n",
    "del device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOURCE_STACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-sae]",
   "language": "python",
   "name": "conda-env-miniconda3-sae-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
