{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from typing import Callable, Optional\n",
    "import torch\n",
    "import os\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import circuits.eval_sae_as_classifier as eval_sae\n",
    "import circuits.analysis as analysis\n",
    "import circuits.eval_board_reconstruction as eval_board_reconstruction\n",
    "import circuits.get_eval_results as get_eval_results\n",
    "import circuits.f1_analysis as f1_analysis\n",
    "import circuits.utils as utils\n",
    "import circuits.pipeline_config as pipeline_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "autoencoder_group_path = \"../autoencoders/testing_chess/\"\n",
    "autoencoder_path = \"../autoencoders/testing_chess/trainer4/\"\n",
    "\n",
    "othello = eval_sae.check_if_autoencoder_is_othello(autoencoder_group_path)\n",
    "config = pipeline_config.Config()\n",
    "\n",
    "# These both significantly reduce peak GPU memory usage\n",
    "config.batch_size = 5\n",
    "config.analysis_on_cpu = True\n",
    "\n",
    "# Precompute will create both datasets and save them as pickle files\n",
    "# If precompute == False, it creates the dataset on the fly\n",
    "# This is far slower when evaluating multiple SAEs, but for an exploratory run it is fine\n",
    "config.precompute = False\n",
    "\n",
    "config.eval_results_n_inputs = 500\n",
    "config.eval_sae_n_inputs = 500\n",
    "config.board_reconstruction_n_inputs = 500\n",
    "\n",
    "# Once you have ran the analysis, you can set this to False and it will load the saved results\n",
    "config.run_analysis = True\n",
    "config.run_board_reconstruction = True\n",
    "config.run_eval_sae = False\n",
    "config.run_eval_results = True\n",
    "\n",
    "# If you want to save the results of the analysis\n",
    "config.save_results = True\n",
    "config.save_feature_labels = True\n",
    "\n",
    "print(f\"Is Othello: {othello}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = max(config.eval_sae_n_inputs, config.board_reconstruction_n_inputs)\n",
    "\n",
    "# We have plenty of data and eval_results_data doesn't use VRAM, so we can afford to make it large\n",
    "# So we don't hit the end of the activation buffer\n",
    "eval_results_dataset_size = config.eval_results_n_inputs * 10\n",
    "\n",
    "indexing_functions = eval_sae.get_recommended_indexing_functions(othello)\n",
    "indexing_function = indexing_functions[0]\n",
    "\n",
    "if othello:\n",
    "    custom_functions = config.othello_functions\n",
    "    game_name = \"othello\"\n",
    "else:\n",
    "    custom_functions = config.chess_functions\n",
    "    game_name = \"chess\"\n",
    "\n",
    "train_dataset_name = f\"{game_name}_train_dataset.pkl\"\n",
    "test_dataset_name = f\"{game_name}_test_dataset.pkl\"\n",
    "\n",
    "if os.path.exists(train_dataset_name) and config.precompute:\n",
    "    print(\"Loading statistics aggregation dataset\")\n",
    "    with open(train_dataset_name, \"rb\") as f:\n",
    "        train_data = pickle.load(f)\n",
    "else:\n",
    "    print(\"Constructing statistics aggregation dataset\")\n",
    "    train_data = eval_sae.construct_dataset(\n",
    "        othello,\n",
    "        custom_functions,\n",
    "        dataset_size,\n",
    "        split=\"train\",\n",
    "        device=device,\n",
    "        precompute_dataset=config.precompute,\n",
    "    )\n",
    "    if config.precompute:\n",
    "        print(\"Saving statistics aggregation dataset\")\n",
    "        with open(train_dataset_name, \"wb\") as f:\n",
    "            pickle.dump(train_data, f)\n",
    "\n",
    "if os.path.exists(test_dataset_name) and config.precompute:\n",
    "    print(\"Loading test dataset\")\n",
    "    with open(test_dataset_name, \"rb\") as f:\n",
    "        test_data = pickle.load(f)\n",
    "else:\n",
    "    print(\"Constructing test dataset\")\n",
    "    test_data = eval_sae.construct_dataset(\n",
    "        othello,\n",
    "        custom_functions,\n",
    "        dataset_size,\n",
    "        split=\"test\",\n",
    "        device=device,\n",
    "        precompute_dataset=config.precompute,\n",
    "    )\n",
    "    if config.precompute:\n",
    "        print(\"Saving test dataset\")\n",
    "        with open(test_dataset_name, \"wb\") as f:\n",
    "            pickle.dump(test_data, f)\n",
    "\n",
    "eval_results_data = eval_sae.construct_dataset(\n",
    "    othello,\n",
    "    [],\n",
    "    eval_results_dataset_size,\n",
    "    split=\"train\",\n",
    "    device=device,\n",
    "    precompute_dataset=config.precompute,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_eval_results_output_location = get_eval_results.get_output_location(\n",
    "    autoencoder_path, n_inputs=config.eval_results_n_inputs\n",
    ")\n",
    "\n",
    "if config.run_eval_results:\n",
    "\n",
    "    # If this is set, everything below should be reproducible\n",
    "    # Then we can just save results from 1 run, make optimizations, and check that the results are the same\n",
    "    # The determinism is only needed for getting activations from the activation buffer for finding alive features\n",
    "    torch.manual_seed(0)\n",
    "    eval_results = get_eval_results.get_evals(\n",
    "        autoencoder_path,\n",
    "        config.eval_results_n_inputs,\n",
    "        config.batch_size,\n",
    "        device,\n",
    "        utils.to_device(eval_results_data.copy(), device),\n",
    "        othello=othello,\n",
    "        save_results=config.save_results,\n",
    "    )\n",
    "else:\n",
    "    with open(expected_eval_results_output_location, \"rb\") as f:\n",
    "        eval_results = pickle.load(f)\n",
    "    eval_results = utils.to_device(eval_results, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"L0: {eval_results['eval_results']['l0']}\")\n",
    "print(f\"Loss recovered: {eval_results['eval_results']['frac_recovered']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_aggregation_output_location = eval_sae.get_output_location(\n",
    "    autoencoder_path,\n",
    "    n_inputs=config.eval_sae_n_inputs,\n",
    "    indexing_function=indexing_function,\n",
    ")\n",
    "\n",
    "if config.run_eval_sae:\n",
    "    print(\"Aggregating\", autoencoder_path)\n",
    "    aggregation_results = eval_sae.aggregate_statistics(\n",
    "        custom_functions=custom_functions,\n",
    "        autoencoder_path=autoencoder_path,\n",
    "        n_inputs=config.eval_sae_n_inputs,\n",
    "        batch_size=config.batch_size,\n",
    "        device=device,\n",
    "        data=utils.to_device(train_data.copy(), device),\n",
    "        thresholds_T=config.f1_analysis_thresholds,\n",
    "        indexing_function=indexing_function,\n",
    "        othello=othello,\n",
    "        save_results=config.save_results,\n",
    "        precomputed=config.precompute,\n",
    "    )\n",
    "else:\n",
    "    with open(expected_aggregation_output_location, \"rb\") as f:\n",
    "        aggregation_results = pickle.load(f)\n",
    "    aggregation_results = utils.to_device(aggregation_results, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.analysis_on_cpu:\n",
    "    aggregation_results = utils.to_device(aggregation_results, \"cpu\")\n",
    "    analysis_device = \"cpu\"\n",
    "else:\n",
    "    analysis_device = device\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "expected_feature_labels_output_location = expected_aggregation_output_location.replace(\n",
    "    \"results.pkl\", \"feature_labels.pkl\"\n",
    ")\n",
    "if config.run_analysis:\n",
    "    feature_labels, misc_stats = analysis.analyze_results_dict(\n",
    "        aggregation_results,\n",
    "        output_path=expected_feature_labels_output_location,\n",
    "        device=analysis_device,\n",
    "        high_threshold=config.analysis_high_threshold,\n",
    "        low_threshold=config.analysis_low_threshold,\n",
    "        significance_threshold=config.analysis_significance_threshold,\n",
    "        verbose=False,\n",
    "        print_results=False,\n",
    "        save_results=config.save_feature_labels,\n",
    "    )\n",
    "else:\n",
    "    with open(expected_feature_labels_output_location, \"rb\") as f:\n",
    "        feature_labels = pickle.load(f)\n",
    "    feature_labels = utils.to_device(feature_labels, analysis_device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rc_to_square_notation(row, col):\n",
    "    letters = \"ABCDEFGH\"\n",
    "    number = row + 1\n",
    "    letter = letters[col]\n",
    "    return f\"{letter}{number}\"\n",
    "\n",
    "def plot_board(board_RR: torch.Tensor, title: str = \"Board\", png_filename: Optional[str] = None):\n",
    "    \"\"\"\n",
    "    Plots an 8x8 board with values greater than 0.8 displayed in red text to two decimal places.\n",
    "    \n",
    "    Args:\n",
    "    board_RR (torch.Tensor): A 2D tensor of shape (8, 8) with values from 0 to 1.\n",
    "    title (str): Title of the plot.\n",
    "    \"\"\"\n",
    "    assert board_RR.shape == (8, 8), \"board_RR must be of shape 8x8\"\n",
    "    \n",
    "    plt.imshow(board_RR, cmap='gray_r', interpolation='none', vmin=0, vmax=1)\n",
    "    plt.colorbar()  # Adds a colorbar to help identify the values\n",
    "    plt.grid(False)  # Turn off the grid lines\n",
    "    plt.title(title)\n",
    "\n",
    "    # Iterate over each element in the tensor to display values\n",
    "    for i in range(board_RR.shape[0]):\n",
    "        for j in range(board_RR.shape[1]):\n",
    "            value = board_RR[i, j]\n",
    "            if value > 0.8:\n",
    "                # Display the value in red text at the corresponding position\n",
    "                plt.text(j, i, f\"{value:.0%}\", color='red', ha='center', va='center', fontsize=12)\n",
    "\n",
    "    if png_filename is not None:\n",
    "        plt.savefig(png_filename)\n",
    "    plt.show()\n",
    "\n",
    "num_to_class = {0: \"Black King\", 1: \"Black Queen\", 2: \"Black Rook\", 3: \"Black Bishop\", 4: \"Black Knight\", 5: \"Black Pawn\",\n",
    "                6: \"Blank\", 7: \"White Pawn\", 8: \"White Knight\", 9: \"White Bishop\", 10: \"White Rook\", 11: \"White Queen\", 12: \"White King\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_state_feature_labels_TFRRC = feature_labels['board_to_piece_masked_blank_and_initial_state']\n",
    "print(f\"Board state feature labels: {board_state_feature_labels_TFRRC.shape}\")\n",
    "threshold = 5\n",
    "\n",
    "board_state_feature_labels_FRRC = board_state_feature_labels_TFRRC[threshold]\n",
    "board_state_counts_F = einops.reduce(board_state_feature_labels_FRRC, \"F R1 R2 C -> F\", \"sum\")\n",
    "\n",
    "max_features = 175\n",
    "demo_idx = 0\n",
    "for i in range(max_features):\n",
    "    if board_state_counts_F[i] > 0:\n",
    "        print(f\"Feature {i} has {board_state_counts_F[i]} classified squares\")\n",
    "        demo_idx = i\n",
    "\n",
    "demo_feature_labels_RRC = board_state_feature_labels_FRRC[demo_idx]\n",
    "print(f\"\\nFeature {demo_idx} has {board_state_counts_F[demo_idx].sum().item()} classified squares\")\n",
    "\n",
    "classified_squares = torch.where(demo_feature_labels_RRC == 1)\n",
    "print(f\"Classified squares as tensors: {classified_squares}\")\n",
    "\n",
    "row, column, classes = classified_squares\n",
    "\n",
    "print(\"\\nClassified squares:\")\n",
    "for i in range(row.shape[0]):\n",
    "    print(rc_to_square_notation(row[i].item(), column[i].item()), num_to_class[classes[i].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aggregation_results['on_count'].shape)\n",
    "\n",
    "T, F = aggregation_results[\"on_count\"].shape\n",
    "\n",
    "print(f\"For all {F} alive features over {T} thresholds, on_count is the number of times each feature is on above every threshold\")\n",
    "\n",
    "formatted_results = analysis.add_off_tracker(aggregation_results, custom_functions, analysis_device)\n",
    "\n",
    "formatted_results = analysis.normalize_tracker(\n",
    "    formatted_results,\n",
    "    \"on\",\n",
    "    custom_functions,\n",
    "    analysis_device,\n",
    ")\n",
    "\n",
    "formatted_results = analysis.normalize_tracker(\n",
    "    formatted_results,\n",
    "    \"off\",\n",
    "    custom_functions,\n",
    "    analysis_device,\n",
    ")\n",
    "\n",
    "print(formatted_results[\"board_to_piece_masked_blank_and_initial_state\"]['on_normalized'].shape)\n",
    "\n",
    "board_results_TFRRC = formatted_results[\"board_to_piece_masked_blank_and_initial_state\"]['on_normalized']\n",
    "\n",
    "def plot_feature_board_states(board_results_TFRRC: torch.Tensor, feature_idx: int, threshold: int, piece_type: int):\n",
    "    results_RRC = board_results_TFRRC[threshold, feature_idx]\n",
    "\n",
    "    feature_on_count = formatted_results['on_count'][threshold, feature_idx]\n",
    "\n",
    "    print(f\"Feature {feature_idx} had {int(feature_on_count)} activations over threshold {(threshold * 10)}%\")\n",
    "\n",
    "    print(results_RRC.shape)\n",
    "    results_RR = results_RRC[..., piece_type]\n",
    "    print(results_RR)\n",
    "\n",
    "    title = f\"Average {num_to_class[piece_type]} activation for \\nfeature {feature_idx} over threshold {(threshold * 10)}%\"\n",
    "    png_filename = f\"feature_{feature_idx}_threshold_{threshold}_piece_{piece_type}.png\"\n",
    "    plot_board(results_RR, title, png_filename)\n",
    "\n",
    "plot_feature_board_states(board_results_TFRRC, demo_idx, 0, 8)\n",
    "plot_feature_board_states(board_results_TFRRC, demo_idx, 2, 8)\n",
    "plot_feature_board_states(board_results_TFRRC, demo_idx, 2, 5)\n",
    "plot_feature_board_states(board_results_TFRRC, demo_idx, 0, 3)\n",
    "plot_feature_board_states(board_results_TFRRC, demo_idx, 5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.analysis_on_cpu:\n",
    "    aggregation_results = utils.to_device(aggregation_results, device)\n",
    "    feature_labels = utils.to_device(feature_labels, device)\n",
    "    misc_stats = utils.to_device(misc_stats, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optionally, this can be sped up by\n",
    "# config.board_reconstruction_n_inputs = 100\n",
    "\n",
    "expected_reconstruction_output_location = expected_aggregation_output_location.replace(\n",
    "    \"results.pkl\", \"reconstruction.pkl\"\n",
    ")\n",
    "\n",
    "if config.run_board_reconstruction:\n",
    "    print(\"Testing board reconstruction\")\n",
    "    board_reconstruction_results = eval_board_reconstruction.test_board_reconstructions(\n",
    "        custom_functions=custom_functions,\n",
    "        autoencoder_path=autoencoder_path,\n",
    "        feature_labels=feature_labels,\n",
    "        output_file=expected_reconstruction_output_location,\n",
    "        n_inputs=config.board_reconstruction_n_inputs,\n",
    "        batch_size=config.batch_size,\n",
    "        device=device,\n",
    "        data=utils.to_device(test_data.copy(), device),\n",
    "        othello=othello,\n",
    "        print_results=False,\n",
    "        save_results=config.save_results,\n",
    "        precomputed=config.precompute,\n",
    "    )\n",
    "else:\n",
    "    with open(expected_reconstruction_output_location, \"rb\") as f:\n",
    "        board_reconstruction_results = pickle.load(f)\n",
    "    board_reconstruction_results = utils.to_device(board_reconstruction_results, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "circuits",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
