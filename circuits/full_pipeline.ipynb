{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import circuits.eval_sae_as_classifier as eval_sae\n",
    "import circuits.analysis as analysis\n",
    "import circuits.test_board_reconstruction as test_board_reconstruction\n",
    "import circuits.get_eval_results as get_eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, just set `autoencoder_group_paths` and various hyperparameters and run it. If you already ran, for example, `eval_sae_as_classifier` and don't want to run it again, set `run_eval_sae` to False. Note that in this case, `eval_results_n_inputs` must match in order for it to load the file saved from the previous run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(eval_sae)\n",
    "importlib.reload(analysis)\n",
    "importlib.reload(test_board_reconstruction)\n",
    "importlib.reload(get_eval_results)\n",
    "\n",
    "# NOTE: This script makes a major assumption here: That all autoencoders in a given group are trained on chess XOR Othello\n",
    "# We do this so we don't have to reconstruct the dataset for each autoencoder in the group\n",
    "autoencoder_group_paths = [\"../autoencoders/othello_layer5_ef4/\"]\n",
    "autoencoder_group_paths = [\"../autoencoders/chess_layer5/\"]\n",
    "\n",
    "eval_sae_n_inputs = 10\n",
    "batch_size = 10\n",
    "device = \"cuda\"\n",
    "model_path = \"../models/\"\n",
    "save_results = True\n",
    "\n",
    "eval_results_n_inputs = 100\n",
    "board_reconstruction_n_inputs = 10\n",
    "\n",
    "analysis_high_threshold = 0.95\n",
    "analysis_low_threshold = 0.1\n",
    "analysis_significance_threshold = 10\n",
    "\n",
    "run_eval_results = True # We don't check for this as eval_results are pretty quick to collect\n",
    "\n",
    "# To skip any of the following steps, set the corresponding variable to False\n",
    "# The results must have been saved previously\n",
    "run_eval_sae = True\n",
    "run_analysis = True\n",
    "run_board_reconstruction = True\n",
    "\n",
    "dataset_size = max(eval_sae_n_inputs, eval_results_n_inputs, board_reconstruction_n_inputs)\n",
    "\n",
    "if dataset_size == eval_results_n_inputs:\n",
    "    dataset_size *= 2\n",
    "\n",
    "\n",
    "for autoencoder_group_path in autoencoder_group_paths:\n",
    "    othello = eval_sae.check_if_autoencoder_is_othello(autoencoder_group_path)\n",
    "\n",
    "    indexing_functions = eval_sae.get_recommended_indexing_functions(othello)\n",
    "    indexing_function = indexing_functions[0]\n",
    "\n",
    "    custom_functions = eval_sae.get_recommended_custom_functions(othello)\n",
    "\n",
    "    model_name = eval_sae.get_model_name(othello)\n",
    "\n",
    "    print(\"Constructing evaluation dataset\")\n",
    "    data = eval_sae.construct_dataset(othello, custom_functions, dataset_size, device, models_path=model_path)\n",
    "\n",
    "    folders = eval_sae.get_nested_folders(autoencoder_group_path)\n",
    "\n",
    "    for autoencoder_path in folders:\n",
    "\n",
    "        # For debugging\n",
    "        if \"ef=4_lr=1e-03_l1=1e-01_layer=5\" not in autoencoder_path:\n",
    "            continue\n",
    "\n",
    "        eval_results = get_eval_results.get_evals(\n",
    "            autoencoder_path,\n",
    "            eval_results_n_inputs,\n",
    "            device,\n",
    "            model_path,\n",
    "            model_name,\n",
    "            data.copy(),\n",
    "            othello=othello,\n",
    "            save_results=save_results,\n",
    "        )\n",
    "\n",
    "        expected_aggregation_output_location = eval_sae.get_output_location(\n",
    "                autoencoder_path, n_inputs=eval_sae_n_inputs, indexing_function=indexing_function\n",
    "            )\n",
    "        \n",
    "        if run_eval_sae:\n",
    "            print(\"Aggregating\", autoencoder_path)\n",
    "            aggregation_results = (\n",
    "                eval_sae.aggregate_statistics(\n",
    "                    custom_functions=custom_functions,\n",
    "                    autoencoder_path=autoencoder_path,\n",
    "                    n_inputs=eval_sae_n_inputs,\n",
    "                    batch_size=batch_size,\n",
    "                    device=device,\n",
    "                    model_path=model_path,\n",
    "                    model_name=model_name,\n",
    "                    data=data.copy(),\n",
    "                    indexing_function=indexing_function,\n",
    "                    othello=othello,\n",
    "                    save_results=save_results,\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            with open(expected_aggregation_output_location, \"rb\") as f:\n",
    "                aggregation_results = pickle.load(f)\n",
    "\n",
    "        expected_feature_labels_output_location = expected_aggregation_output_location.replace(\n",
    "            \"results.pkl\", \"feature_labels.pkl\"\n",
    "        )\n",
    "        if run_analysis:\n",
    "            feature_labels = analysis.analyze_results_dict(\n",
    "                aggregation_results,\n",
    "                output_path=expected_feature_labels_output_location,\n",
    "                device=device,\n",
    "                high_threshold=analysis_high_threshold,\n",
    "                low_threshold=analysis_low_threshold,\n",
    "                significance_threshold=analysis_significance_threshold,\n",
    "                verbose=False,\n",
    "                print_results=False,\n",
    "                save_results=save_results,\n",
    "            )\n",
    "        else:\n",
    "            with open(expected_feature_labels_output_location, \"rb\") as f:\n",
    "                feature_labels = pickle.load(f)\n",
    "\n",
    "        expected_reconstruction_output_location = expected_aggregation_output_location.replace(\n",
    "            \"results.pkl\", \"reconstruction.pkl\"\n",
    "        )\n",
    "\n",
    "        if run_board_reconstruction:\n",
    "            print(\"Testing board reconstruction\")\n",
    "            board_reconstruction_results = test_board_reconstruction.test_board_reconstructions(\n",
    "                    custom_functions=custom_functions,\n",
    "                    autoencoder_path=autoencoder_path,\n",
    "                    feature_labels=feature_labels,\n",
    "                    output_file=expected_reconstruction_output_location,\n",
    "                    n_inputs=board_reconstruction_n_inputs,\n",
    "                    batch_size=batch_size,\n",
    "                    device=device,\n",
    "                    model_name=model_name,\n",
    "                    data=data.copy(),\n",
    "                    othello=othello,\n",
    "                    print_results=False,\n",
    "                    save_results=save_results,\n",
    "            )\n",
    "        else:\n",
    "            with open(expected_reconstruction_output_location, \"rb\") as f:\n",
    "                board_reconstruction_results = pickle.load(f)\n",
    "\n",
    "        print(\"Finished\", autoencoder_path)\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of gathering top k contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import circuits.chess_interp as chess_interp\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "autoencoder_group_path = autoencoder_group_paths[0]\n",
    "\n",
    "othello = eval_sae.check_if_autoencoder_is_othello(autoencoder_group_path)\n",
    "\n",
    "indexing_functions = eval_sae.get_recommended_indexing_functions(othello)\n",
    "indexing_function = indexing_functions[0]\n",
    "\n",
    "custom_functions = eval_sae.get_recommended_custom_functions(othello)\n",
    "\n",
    "model_name = eval_sae.get_model_name(othello)\n",
    "\n",
    "print(\"Constructing evaluation dataset\")\n",
    "data = eval_sae.construct_dataset(othello, custom_functions, dataset_size, device, models_path=model_path)\n",
    "\n",
    "dataset_size = dataset_size * 2  # x2 to make sure we have enough data for loss_recovered()\n",
    "\n",
    "data, ae_bundle, pgn_strings, encoded_inputs = eval_sae.prep_firing_rate_data(\n",
    "    autoencoder_path, dataset_size, model_path, model_name, data, device, dataset_size, othello\n",
    ")\n",
    "\n",
    "dims = torch.tensor([10], device=device)\n",
    "chess_interp.examine_dimension_chess(ae_bundle, 100, dims, model_path=model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "circuits",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
