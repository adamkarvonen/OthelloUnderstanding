{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import einops\n",
    "from collections import defaultdict\n",
    "from typing import Callable, Optional\n",
    "import os\n",
    "import importlib\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import circuits.utils as utils\n",
    "import circuits.othello_utils as othello_utils\n",
    "import neuron_simulation.simulation_config as sim_config\n",
    "import neuron_simulation.simulate_activations_with_dts as sim_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_config = sim_config.selected_config\n",
    "device = \"cpu\"\n",
    "\n",
    "# If desired, you can run simulate_activations_with_dts.py from this cell\n",
    "# Values from default config will also be used later on in the notebook to filter out saved pickle files\n",
    "\n",
    "# Example of filtering out certain configurations\n",
    "\n",
    "# default_config.n_batches = 2\n",
    "\n",
    "# for combination in default_config.combinations:\n",
    "#     combination.ablate_not_selected = [True]\n",
    "\n",
    "# sim_activations.run_simulations(default_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ablation_pickle_files(\n",
    "    directory: str,\n",
    "    dataset_size: int,\n",
    "    ablation_method: str,\n",
    "    ablate_not_selected: bool,\n",
    "    add_error: bool,\n",
    "):\n",
    "    data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".pkl\") and \"ablation\" in filename:\n",
    "            with open(os.path.join(directory, filename), \"rb\") as f:\n",
    "                single_data = pickle.load(f)\n",
    "\n",
    "            hyperparams = single_data[\"hyperparameters\"]\n",
    "            if hyperparams[\"ablate_not_selected\"] != ablate_not_selected:\n",
    "                continue\n",
    "\n",
    "            if hyperparams[\"input_location\"] != \"mlp_neuron\":\n",
    "                if hyperparams[\"add_error\"] != add_error:\n",
    "                    continue\n",
    "\n",
    "            if hyperparams[\"ablation_method\"] != ablation_method:\n",
    "                continue\n",
    "\n",
    "            if hyperparams[\"dataset_size\"] != dataset_size:\n",
    "                continue\n",
    "            data.append(single_data)\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_kl_divergence(\n",
    "    data: list[dict],\n",
    "    custom_function_name: str,\n",
    "):\n",
    "    nested_kl_div = {}\n",
    "    for run in data:\n",
    "        hyperparams = run[\"hyperparameters\"]\n",
    "        input_location = hyperparams[\"input_location\"]\n",
    "        trainer_id = hyperparams[\"trainer_id\"]\n",
    "\n",
    "        if input_location not in nested_kl_div:\n",
    "            nested_kl_div[input_location] = {}\n",
    "        if trainer_id not in nested_kl_div[input_location]:\n",
    "            nested_kl_div[input_location][trainer_id] = {}\n",
    "\n",
    "        for layer_tuple, func_results in run[\"results\"].items():\n",
    "            if custom_function_name in func_results:\n",
    "                kl_div = func_results[custom_function_name]\n",
    "                if len(layer_tuple) == 1:\n",
    "                    layer = layer_tuple[0]\n",
    "                    if layer not in nested_kl_div[input_location][trainer_id]:\n",
    "                        nested_kl_div[input_location][trainer_id][layer] = []\n",
    "                    nested_kl_div[input_location][trainer_id][layer].append(kl_div)\n",
    "                else:\n",
    "                    raise ValueError(\"Layer tuple length is not 1\")\n",
    "\n",
    "    return nested_kl_div\n",
    "\n",
    "\n",
    "def min_kl_div_per_layer(nested_kl_div):\n",
    "    min_kl_div = {}\n",
    "    for input_location, trainer_ids in nested_kl_div.items():\n",
    "        min_kl_div[input_location] = {}\n",
    "        all_layers = set()\n",
    "        for layer_results in trainer_ids.values():\n",
    "            all_layers.update(layer_results.keys())\n",
    "\n",
    "        for layer in all_layers:\n",
    "            min_kl = float(\"inf\")\n",
    "            for trainer_id, layer_results in trainer_ids.items():\n",
    "                if layer in layer_results:\n",
    "                    min_kl = min(min_kl, min(layer_results[layer]))\n",
    "            min_kl_div[input_location][layer] = min_kl\n",
    "\n",
    "    return min_kl_div\n",
    "\n",
    "\n",
    "def plot_kl_divergence(nested_kl_div):\n",
    "    for input_location, trainer_ids in nested_kl_div.items():\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for trainer_id, layer_results in trainer_ids.items():\n",
    "            layers = sorted(layer_results.keys())\n",
    "            means = [np.mean(layer_results[layer]) for layer in layers]\n",
    "            stds = [np.std(layer_results[layer]) for layer in layers]\n",
    "\n",
    "            plt.errorbar(\n",
    "                layers, means, yerr=stds, fmt=\"o-\", capsize=5, label=f\"Trainer {trainer_id}\"\n",
    "            )\n",
    "\n",
    "        plt.xlabel(\"Layer\")\n",
    "        plt.ylabel(\"KL Divergence\")\n",
    "        plt.title(f\"KL Divergence per Layer ({input_location}, {ablation_method} ablation)\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_min_kl_divergence(min_kl_div):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for input_location, layer_results in min_kl_div.items():\n",
    "        layers = sorted(layer_results.keys())\n",
    "        kl_values = [layer_results[layer] for layer in layers]\n",
    "\n",
    "        plt.plot(layers, kl_values, \"o-\", label=input_location)\n",
    "\n",
    "    plt.xlabel(\"Layer\")\n",
    "    plt.ylabel(\"min KL Divergence\")\n",
    "    plt.title(f\"min KL Divergence per Layer ({ablation_method} ablation)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "directory = \"decision_trees\"\n",
    "custom_function_name = (\n",
    "    othello_utils.games_batch_to_input_tokens_flipped_bs_valid_moves_classifier_input_BLC.__name__\n",
    ")\n",
    "\n",
    "default_config = sim_config.selected_config\n",
    "dataset_size = default_config.batch_size * default_config.n_batches\n",
    "\n",
    "ablation_method = \"dt\"\n",
    "ablate_not_selected = True\n",
    "add_error = False\n",
    "\n",
    "data = load_ablation_pickle_files(directory, dataset_size, ablation_method, ablate_not_selected, add_error)\n",
    "\n",
    "example_dict = data[0]\n",
    "\n",
    "print(example_dict[\"hyperparameters\"].keys())\n",
    "\n",
    "kl_div_per_layer = extract_kl_divergence(data, custom_function_name)\n",
    "plot_kl_divergence(kl_div_per_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_kl_div = min_kl_div_per_layer(kl_div_per_layer)\n",
    "plot_min_kl_divergence(min_kl_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_3var_results(kl_div_per_layer: dict, eval_df: pd.DataFrame, layer: int, input_location: str):\n",
    "    # Filter the evaluation dataframe\n",
    "    eval_df_filtered = eval_df[eval_df['layer_idx'] == layer]\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    l0 = []\n",
    "    frac_recovered = []\n",
    "    kl_values = []\n",
    "    \n",
    "    for trainer_id, layer_results in kl_div_per_layer[input_location].items():\n",
    "        if layer in layer_results:\n",
    "            # Find matching row in eval_df_filtered\n",
    "            eval_row = eval_df_filtered[eval_df_filtered['trainer_idx'] == int(trainer_id)]\n",
    "            if not eval_row.empty:\n",
    "                l0.append(eval_row['l0'].values[0])\n",
    "                frac_recovered.append(eval_row['frac_recovered'].values[0])\n",
    "                kl_values.append(np.mean(layer_results[layer]))\n",
    "    \n",
    "    # Create the 2D plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Plot the points\n",
    "    scatter = plt.scatter(l0, frac_recovered, c=kl_values, cmap='viridis', s=50)\n",
    "    \n",
    "    # Set labels and title\n",
    "    plt.xlabel('L0', fontsize=12)\n",
    "    plt.ylabel('Fraction Recovered', fontsize=12)\n",
    "    plt.title(f'L0 vs Fraction Recovered vs Neuron Simulation KL Divergence\\n'\n",
    "              f'Layer {layer}, {input_location}', fontsize=14)\n",
    "    \n",
    "    # Add a color bar\n",
    "    cbar = plt.colorbar(scatter)\n",
    "    cbar.set_label(f'Layer {layer} KL Divergence', fontsize=12)\n",
    "    \n",
    "    # Add grid lines\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Improve layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(f\"l0_vs_frac_recovered_vs_kl_divergence_{input_location}_layer_{layer}.png\")\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Load evaluation data\n",
    "sae_mlp_out_eval = pd.read_csv(\"sae_eval_csvs/sae_mlp_out_feature_evaluations.csv\")\n",
    "transcoder_eval = pd.read_csv(\"sae_eval_csvs/transcoder_evaluations.csv\")\n",
    "\n",
    "# Example usage\n",
    "layer = 1 \n",
    "\n",
    "# Plot for sae_mlp_out_feature\n",
    "graph_3var_results(kl_div_per_layer, sae_mlp_out_eval, layer, 'sae_mlp_out_feature')\n",
    "\n",
    "# Plot for transcoder\n",
    "graph_3var_results(kl_div_per_layer, transcoder_eval, layer, 'transcoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently broken, just need to get the dictionary keys right\n",
    "# This can be used to plot multiple thresholds for a single location / custom function combination\n",
    "\n",
    "# colors = ['b', 'g', 'r']  # Colors for different thresholds\n",
    "# markers = ['o', 's', '^']  # Markers for different thresholds\n",
    "\n",
    "# for custom_function in custom_functions:\n",
    "#     function_name = custom_function.__name__\n",
    "    \n",
    "#     plt.figure(figsize=(12, 7))\n",
    "    \n",
    "#     for i, threshold in enumerate(thresholds):\n",
    "#         f1_counts = accuracy_by_layer[function_name][threshold]\n",
    "        \n",
    "#         plt.plot(intervention_layers, f1_counts, color=colors[i], marker=markers[i], \n",
    "#                  label=f'Threshold: {threshold}', linewidth=2, markersize=8)\n",
    "        \n",
    "#         # Optionally, add value labels on each point\n",
    "#         for j, count in enumerate(f1_counts):\n",
    "#             plt.annotate(str(count), (intervention_layers[j], count), \n",
    "#                          textcoords=\"offset points\", xytext=(0,5), ha='center', \n",
    "#                          fontsize=8, color=colors[i])\n",
    "    \n",
    "#     plt.title(f'Number of Neurons with F1 > Threshold for \\n{function_labels[custom_function]} by Layer \\n{dataset_size} datapoints Input location: {input_location} depth: {max_depth}', fontsize=14)\n",
    "#     plt.xlabel('Layer Number', fontsize=12)\n",
    "#     plt.ylabel('F1 Count', fontsize=12)\n",
    "#     plt.legend(loc='best', fontsize=10)\n",
    "#     plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     output_filename = f\"images/{input_location}_{function_name}_inputs_{dataset_size}_depth_{max_depth}_f1_count_by_layer_all_thresholds.png\"\n",
    "#     plt.savefig(output_filename, dpi=300, bbox_inches='tight')\n",
    "#     plt.show()\n",
    "\n",
    "# print(\"All graphs have been created and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently broken, just need to get the dictionary keys right\n",
    "\n",
    "# layer = 1\n",
    "# neuron_idx = 421\n",
    "# custom_function_name = custom_functions[0].__name__\n",
    "\n",
    "# decision_tree_filename = f\"decision_trees/decision_trees_{input_location}_{dataset_size}.pkl\"\n",
    "\n",
    "# with open(decision_tree_filename, \"rb\") as f:\n",
    "#     decision_tree = pickle.load(f)\n",
    "\n",
    "# layer_dt = decision_tree[layer][custom_function_name]['decision_tree']['model']\n",
    "# layer_dt = decision_tree[layer][custom_function_name]['binary_decision_tree']['model']\n",
    "\n",
    "# games_BLC = train_data[custom_function_name]\n",
    "\n",
    "# feature_names = []\n",
    "\n",
    "# X_binary_train, X_binary_test, y_binary_train, y_binary_test = prepare_data(\n",
    "#     games_BLC, binary_acts[layer]\n",
    "# )\n",
    "# accuracy, precision, recall, f1 = calculate_binary_metrics(\n",
    "#     decision_tree[layer][custom_function_name][\"binary_decision_tree\"][\"model\"], X_binary_test, y_binary_test\n",
    "# )\n",
    "\n",
    "# print(f\"Neuron 421 F1: {f1[neuron_idx]}\")\n",
    "\n",
    "# for i in range(games_BLC.shape[2]):\n",
    "#     if i < 64:\n",
    "#         square = idx_to_square_notation(i)\n",
    "#         feature_names.append(f\"Input_{square}\")\n",
    "#     elif i < 128:\n",
    "#         j = i - 64\n",
    "#         square = idx_to_square_notation(j)\n",
    "#         feature_names.append(f\"Occupied_{square}\")\n",
    "#     else:\n",
    "#         feature_names.append(f\"Output_{i}\")\n",
    "\n",
    "# print_decision_tree_rules(layer_dt, feature_names=feature_names, neuron_index=neuron_idx, max_depth=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "othello",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
