{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import pandas as pd\n",
    "\n",
    "import circuits.othello_utils as othello_utils\n",
    "import neuron_simulation.simulation_config as sim_config\n",
    "import neuron_simulation.simulate_activations_with_dts as sim_activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: This notebook is deprecated in favor of `graph_dt_results.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_config = sim_config.selected_config\n",
    "\n",
    "def set_notebook_path(config: sim_config.SimulationConfig):\n",
    "    config.repo_dir = \"../\"\n",
    "    config.output_location = \"\"\n",
    "    return config\n",
    "\n",
    "\n",
    "# If desired, you can run simulate_activations_with_dts.py from this cell\n",
    "# Values from default config will also be used later on in the notebook to filter out saved pickle files\n",
    "\n",
    "# Example of filtering out certain configurations\n",
    "\n",
    "# default_config.n_batches = 2\n",
    "\n",
    "# for combination in default_config.combinations:\n",
    "#     combination.ablate_not_selected = [True]\n",
    "\n",
    "# sim_activations.run_simulations(default_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results_pickle_files(directory: str, dataset_size: int) -> List[Dict[str, Any]]:\n",
    "    data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.pkl') and \"ablation\" not in filename:\n",
    "            with open(os.path.join(directory, filename), 'rb') as f:\n",
    "                single_data = pickle.load(f)\n",
    "\n",
    "            if single_data['hyperparameters']['dataset_size'] != dataset_size:\n",
    "                continue\n",
    "            data.append(single_data)\n",
    "    return data\n",
    "\n",
    "def calculate_good_features(results: Dict[str, Any], threshold: float) -> Tuple[int, int]:\n",
    "    dt_r2 = torch.tensor(results[\"decision_tree\"][\"r2\"])\n",
    "    good_dt_r2 = (dt_r2 > threshold).sum().item()\n",
    "\n",
    "    f1 = torch.tensor(results[\"binary_decision_tree\"][\"f1\"])\n",
    "    good_f1 = (f1 > threshold).sum().item()\n",
    "\n",
    "    return good_dt_r2, good_f1\n",
    "\n",
    "def extract_good_features(data: List[Dict[str, Any]], threshold: float, func_name: str) -> Dict[str, Dict[str, Dict[int, Dict[str, Dict[str, int]]]]]:\n",
    "    nested_good_features: Dict[str, Dict[str, Dict[int, Dict[str, Dict[str, int]]]]] = {}\n",
    "    for run in data:\n",
    "        hyperparams = run['hyperparameters']\n",
    "        input_location: str = hyperparams['input_location']\n",
    "        trainer_id: str = hyperparams['trainer_id']\n",
    "\n",
    "        if input_location not in nested_good_features:\n",
    "            nested_good_features[input_location] = {}\n",
    "        if trainer_id not in nested_good_features[input_location]:\n",
    "            nested_good_features[input_location][trainer_id] = {}\n",
    "\n",
    "        run = run['results']\n",
    "        for layer, results in run.items():\n",
    "            results = results[func_name]\n",
    "            good_dt_r2, good_f1 = calculate_good_features(results, threshold)\n",
    "            if layer not in nested_good_features[input_location][trainer_id]:\n",
    "                nested_good_features[input_location][trainer_id][layer] = {}\n",
    "            nested_good_features[input_location][trainer_id][layer] = good_f1\n",
    "            \n",
    "\n",
    "    return nested_good_features\n",
    "\n",
    "def max_counts_per_layer(nested_counts):\n",
    "    max_counts = {}\n",
    "    for input_location, trainer_ids in nested_counts.items():\n",
    "        max_counts[input_location] = {}\n",
    "        all_layers = set()\n",
    "        for layer_results in trainer_ids.values():\n",
    "            all_layers.update(layer_results.keys())\n",
    "        \n",
    "        for layer in all_layers:\n",
    "            max_count = 0\n",
    "            for trainer_id, layer_results in trainer_ids.items():\n",
    "                if layer in layer_results:\n",
    "                    max_count = max(max_count, layer_results[layer])\n",
    "            max_counts[input_location][layer] = max_count\n",
    "    \n",
    "    return max_counts\n",
    "\n",
    "def plot_good_features(nested_good_features: Dict[str, Dict[str, Dict[int, Dict[str, Dict[str, int]]]]], metric: str = 'f1', threshold: float = 0.8):\n",
    "    for input_location, trainer_ids in nested_good_features.items():\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for trainer_id, layers in trainer_ids.items():\n",
    "            sorted_layers = sorted(layers.keys())\n",
    "            values = [layers[layer] for layer in sorted_layers]\n",
    "\n",
    "            plt.plot(sorted_layers, values, 'o-', label=f'Trainer {trainer_id}')\n",
    "\n",
    "        plt.xlabel(\"Layer\")\n",
    "        plt.ylabel(f\"Number of good features ({metric} > {threshold})\")\n",
    "        plt.title(f\"Good features per Layer ({input_location}, {metric} > {threshold})\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "def plot_max_counts(max_counts):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for input_location, layer_results in max_counts.items():\n",
    "        layers = sorted(layer_results.keys())\n",
    "        counts = [layer_results[layer] for layer in layers]\n",
    "        \n",
    "        plt.plot(layers, counts, 'o-', label=input_location)\n",
    "    \n",
    "    plt.xlabel(\"Layer\")\n",
    "    plt.ylabel(\"Max Count\")\n",
    "    plt.title(f\"Max Count per Layer)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Usage\n",
    "directory: str = 'decision_trees'\n",
    "threshold: float = 0.7\n",
    "\n",
    "func_name: str = othello_utils.games_batch_to_input_tokens_flipped_bs_valid_moves_probe_classifier_input_BLC.__name__\n",
    "\n",
    "# dataset_size = default_config.batch_size * default_config.n_batches\n",
    "dataset_size = 100\n",
    "\n",
    "data: List[Dict[str, Any]] = load_results_pickle_files(directory, dataset_size=dataset_size)\n",
    "nested_good_features: Dict[str, Dict[str, Dict[int, Dict[str, Dict[str, int]]]]] = extract_good_features(data, threshold, func_name)\n",
    "\n",
    "# Plot for F1 score\n",
    "# plot_good_features(nested_good_features, metric='f1', threshold=threshold)\n",
    "\n",
    "# Plot for Decision Tree R2\n",
    "plot_good_features(nested_good_features, metric='dt_r2', threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_counts = max_counts_per_layer(nested_good_features)\n",
    "\n",
    "for input_location, layer_results in max_counts.items():\n",
    "    print(input_location, layer_results)\n",
    "\n",
    "plot_max_counts(max_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_3var_results(nested_good_features: dict, eval_df: pd.DataFrame, layer: int, input_location: str):\n",
    "    # Filter the evaluation dataframe\n",
    "    eval_df_filtered = eval_df[eval_df['layer_idx'] == layer]\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    l0 = []\n",
    "    frac_recovered = []\n",
    "    kl_values = []\n",
    "    \n",
    "    for trainer_id, layer_results in nested_good_features[input_location].items():\n",
    "        if layer in layer_results:\n",
    "            # Find matching row in eval_df_filtered\n",
    "            eval_row = eval_df_filtered[eval_df_filtered['trainer_idx'] == int(trainer_id)]\n",
    "            if not eval_row.empty:\n",
    "                l0.append(eval_row['l0'].values[0])\n",
    "                frac_recovered.append(eval_row['frac_recovered'].values[0])\n",
    "                kl_values.append(np.mean(layer_results[layer]))\n",
    "    \n",
    "    # Create the 2D plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Plot the points\n",
    "    scatter = plt.scatter(l0, frac_recovered, c=kl_values, cmap='viridis', s=50)\n",
    "    \n",
    "    # Set labels and title\n",
    "    plt.xlabel('L0', fontsize=12)\n",
    "    plt.ylabel('Fraction Recovered', fontsize=12)\n",
    "    plt.title(f'L0 vs Fraction Recovered vs Neuron Simulation KL Divergence\\n'\n",
    "              f'Layer {layer}, {input_location}', fontsize=14)\n",
    "    \n",
    "    # Add a color bar\n",
    "    cbar = plt.colorbar(scatter)\n",
    "    cbar.set_label(f'Layer {layer} KL Divergence', fontsize=12)\n",
    "    \n",
    "    # Add grid lines\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Improve layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(f\"l0_vs_frac_recovered_vs_kl_divergence_{input_location}_layer_{layer}.png\")\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Load evaluation data\n",
    "sae_mlp_out_eval = pd.read_csv(\"sae_eval_csvs/sae_mlp_out_feature_evaluations.csv\")\n",
    "transcoder_eval = pd.read_csv(\"sae_eval_csvs/transcoder_evaluations.csv\")\n",
    "\n",
    "# Example usage\n",
    "\n",
    "for layer in range(8):\n",
    "\n",
    "    # Plot for sae_mlp_out_feature\n",
    "    graph_3var_results(nested_good_features, sae_mlp_out_eval, layer, 'sae_mlp_out_feature')\n",
    "\n",
    "    # Plot for transcoder\n",
    "    graph_3var_results(nested_good_features, transcoder_eval, layer, 'transcoder')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "othello",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
