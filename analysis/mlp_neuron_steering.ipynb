{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from huggingface_hub import hf_hub_download\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import numpy as np\n",
    "import einops\n",
    "from tqdm import tqdm\n",
    "from typing import Callable\n",
    "import os\n",
    "\n",
    "from circuits.dictionary_learning.dictionary import AutoEncoder, AutoEncoderNew, GatedAutoEncoder, IdentityDict\n",
    "from circuits.utils import (\n",
    "    othello_hf_dataset_to_generator,\n",
    "    get_model,\n",
    "    get_submodule,\n",
    "    get_mlp_activations_submodule,\n",
    ")\n",
    "\n",
    "from feature_viz_othello_utils import (\n",
    "    get_acts_IEs_VN,\n",
    "    plot_lenses,\n",
    "    plot_mean_metrics,\n",
    "    plot_top_k_games,\n",
    "    BoardPlayer,\n",
    ")\n",
    "\n",
    "import circuits.utils as utils\n",
    "import circuits.analysis as analysis\n",
    "import feature_viz_othello_utils as viz_utils\n",
    "from circuits.othello_utils import games_batch_to_state_stack_length_lines_mine_BLRCC\n",
    "from circuits.othello_engine_utils import to_board_label, to_string, to_int, stoi_indices #to_string: mode_output_vocab to interpretable square index\n",
    "import circuits.eval_sae_as_classifier as eval_sae\n",
    "\n",
    "device = 'cuda:0'\n",
    "tracer_kwargs = {'validate' : False, 'scan' : False}\n",
    "repo_dir = '/share/u/can/chess-gpt-circuits'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model, submodule, ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Baidicoot/Othello-GPT-Transformer-Lens\"\n",
    "model = get_model(model_name, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 5\n",
    "# node_type = \"sae_feature\"\n",
    "node_type = \"mlp_neuron\"\n",
    "\n",
    "\n",
    "if node_type == \"sae_feature\":\n",
    "    ae_group_name = 'all_layers_othello_p_anneal_0530_with_lines'\n",
    "    ae_type = 'p_anneal'\n",
    "    trainer_id = 0\n",
    "    ae_path = f'{repo_dir}/autoencoders/{ae_group_name}/layer_{layer}/trainer{trainer_id}'\n",
    "    submodule = get_submodule(model_name, layer, model)\n",
    "elif node_type == \"mlp_neuron\":\n",
    "    ae_group_name = 'othello_mlp_acts_identity_aes' # with_lines\n",
    "    ae_type = 'identity'\n",
    "    ae_path = f'{repo_dir}/autoencoders/{ae_group_name}/layer_{layer}'\n",
    "    submodule = get_mlp_activations_submodule(model_name, layer, model)\n",
    "else:\n",
    "    raise ValueError('Invalid node_type')\n",
    "\n",
    "# download data from huggingface if needed\n",
    "if not os.path.exists(f'{repo_dir}/autoencoders/{ae_group_name}'):\n",
    "    hf_hub_download(repo_id='adamkarvonen/othello_saes', filename=f'{ae_group_name}.zip', local_dir=f'{repo_dir}/autoencoders')\n",
    "    # unzip the data\n",
    "    os.system(f'unzip {repo_dir}/autoencoders/{ae_group_name}.zip -d {repo_dir}/autoencoders')\n",
    "\n",
    "# Initialize the autoencoder\n",
    "if ae_type == 'standard' or ae_type == 'p_anneal':\n",
    "    ae = AutoEncoder.from_pretrained(os.path.join(ae_path, 'ae.pt'), device='cuda:0')\n",
    "elif ae_type == 'gated' or ae_type == 'gated_anneal':\n",
    "    ae = GatedAutoEncoder.from_pretrained(os.path.join(ae_path, 'ae.pt'), device='cuda:0')\n",
    "elif ae_type == 'standard_new':\n",
    "    ae = AutoEncoderNew.from_pretrained(os.path.join(ae_path, 'ae.pt'), device='cuda:0')\n",
    "elif ae_type == 'identity':\n",
    "    ae = IdentityDict()\n",
    "else:\n",
    "    raise ValueError('Invalid ae_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load legal move neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each neuron, we need the full hypothesis [feature_idx, valid_square_idx, [config_idxs]]\n",
    "import json\n",
    "with open(os.path.join(ae_path, 'hpc_hrc_same_square_indexes_dict.json'), 'r') as f:\n",
    "    hpc_hrc_same_square_indexes_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_idxs, valid_square_idxs, line_idxs = t.tensor(hpc_hrc_same_square_indexes_dict['intersection_FSqC']).T\n",
    "unique_feat_idxs = t.unique(feat_idxs)\n",
    "unique_valid_square_idxs = t.unique(valid_square_idxs)\n",
    "n_unique_feat_idxs = len(unique_feat_idxs)\n",
    "\n",
    "for feat_idx, square_idx in zip(unique_feat_idxs, unique_valid_square_idxs):\n",
    "    config_idxs_per_feat = line_idxs[feat_idxs == feat_idx]\n",
    "    feat_idx = int(feat_idx)\n",
    "    square_idx = int(square_idx)\n",
    "    if feat_idx > 500:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_generator = othello_hf_dataset_to_generator('taufeeque/othellogpt')\n",
    "\n",
    "def construct_othello_dataset(\n",
    "    custom_functions: list[Callable],\n",
    "    games_batch: list,\n",
    "    precompute_dataset: bool = True,\n",
    ") -> dict:\n",
    "    encoded_othello_inputs = []\n",
    "    decoded_othello_inputs = []\n",
    "    for game in games_batch:\n",
    "        encoded_input = game\n",
    "        decoded_input = to_string(encoded_input)\n",
    "        encoded_othello_inputs.append(encoded_input)\n",
    "        decoded_othello_inputs.append(decoded_input)\n",
    "\n",
    "    data = {}\n",
    "    data[\"encoded_inputs\"] = encoded_othello_inputs\n",
    "    data[\"decoded_inputs\"] = decoded_othello_inputs\n",
    "\n",
    "    if not precompute_dataset:\n",
    "        return data\n",
    "\n",
    "    for custom_function in custom_functions:\n",
    "        print(f\"Precomputing {custom_function.__name__}...\")\n",
    "        func_name = custom_function.__name__\n",
    "        data[func_name] = custom_function(decoded_othello_inputs)\n",
    "\n",
    "    return data\n",
    "\n",
    "games_batch = [next(dataset_generator) for _ in range(100)]\n",
    "train_data_example = construct_othello_dataset(\n",
    "    custom_functions=[games_batch_to_state_stack_length_lines_mine_BLRCC],\n",
    "    games_batch = games_batch,\n",
    "    precompute_dataset = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_any_present(train_data, valid_move_idx, line_idxs):\n",
    "    '''for every position in every game, evaluate whether any of the lines is present'''\n",
    "    r = valid_move_idx // 8\n",
    "    c = valid_move_idx % 8\n",
    "    data = train_data['games_batch_to_state_stack_length_lines_mine_BLRCC'][:, :, r, c]\n",
    "    line_idxs_expanded = line_idxs.view(1, 1, -1).expand(data.shape[0], data.shape[1], -1)\n",
    "    data = t.gather(data, dim=-1, index=line_idxs_expanded)\n",
    "    any_line_present = t.any(data, dim=-1)\n",
    "    return any_line_present\n",
    "\n",
    "def game_state_where_line_present(train_data, valid_move_idx, line_idxs):\n",
    "    any_line_present = check_any_present(train_data, valid_move_idx, line_idxs)\n",
    "    enc_inputs = t.tensor(train_data['encoded_inputs'], device=device)\n",
    "    game_state_where_line_present = []\n",
    "    for game, line_present in zip(enc_inputs, any_line_present):\n",
    "        if line_present.sum() > 0:\n",
    "            first_occurence = t.where(line_present)[0][0]\n",
    "            game_state_where_line_present.append(game[:first_occurence+1])\n",
    "    return game_state_where_line_present\n",
    "\n",
    "# def game_state_my_move_before_line_present(train_data, valid_move_idx, line_idxs):\n",
    "#     game_state_where_line_present = game_state_where_line_present(train_data, valid_move_idx, line_idxs)\n",
    "#     return [game[:-2] for game in game_state_where_line_present]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test\n",
    "game_states_line_present = game_state_where_line_present(train_data_example, square_idx, config_idxs_per_feat)\n",
    "game = game_states_line_present[1]\n",
    "game = t.tensor(game, device=device)\n",
    "player = BoardPlayer(game)\n",
    "\n",
    "square_idx, config_idxs_per_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 1 game, where any line is present "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def steering(model, game_batch, submodule, ae, feat_idx, square_idx, steering_factor, device='cpu'):\n",
    "    \n",
    "\n",
    "#     for game, V_square_idx, V_rotated_square_idx, C_square_idx in zip(game_batch):\n",
    "#         V_square_idx = square_idx\n",
    "#     V_row = V_square_idx // 8\n",
    "#     V_col = V_square_idx % 8\n",
    "#     V_rotated_row = 7 - V_row\n",
    "#     V_rotated_col = 7 - V_col\n",
    "#     V_rotated_square_idx = V_rotated_row * 8 + V_rotated_col\n",
    "#     C_square_idxs = game[-2]\n",
    "#     # Clean forward pass\n",
    "#     with t.no_grad(), model.trace(game_batch, **tracer_kwargs):\n",
    "#         x = submodule.output\n",
    "#         f = ae.encode(x).save() # shape: [batch_size, seq_len, n_features]\n",
    "#         logits_clean = model.unembed.output.save() # batch_size x seq_len x vocab_size\n",
    "\n",
    "#     steering_value = f[:, -1, feat_idx] # Activation value where valid_move is present\n",
    "    \n",
    "#     # Steering forward pass\n",
    "#     with t.no_grad(), model.trace(game_batch, **tracer_kwargs):\n",
    "#         x = submodule.output\n",
    "#         f = ae.encode(x).save() # shape: [batch_size, seq_len, n_features]\n",
    "#         f[:, :, feat_idx] = steering_value * steering_factor\n",
    "#         submodule.output = ae.decode(f)\n",
    "#         logits_steer = model.unembed.output.save() # batch_size x seq_len x vocab_size\n",
    "\n",
    "#     # Logit diffs for t-2\n",
    "#     arange_batch = t.arange(batch_size, device=device)\n",
    "#     logit_diff_clean = logits_clean[arange_batch, -3, to_int(V_square_idxs)] - logits_clean[arange_batch, -3, to_int(C_square_idxs)]\n",
    "#     logit_diff_steer = logits_steer[arange_batch, -3, to_int(V_square_idxs)] - logits_steer[arange_batch, -3, to_int(C_square_idxs)]\n",
    "\n",
    "#     rotated_logit_diff_clean = logits_clean[arange_batch, -3, to_int(V_rotated_square_idxs)] - logits_clean[arange_batch, -3, to_int(C_square_idxs)]\n",
    "#     rotated_logit_diff_steer = logits_steer[arange_batch, -3, to_int(V_rotated_square_idxs)] - logits_steer[arange_batch, -3, to_int(C_square_idxs)]\n",
    "    \n",
    "#     steer_clean_diff = logit_diff_steer - logit_diff_clean\n",
    "#     rotated_steer_clean_diff = rotated_logit_diff_steer - rotated_logit_diff_clean\n",
    "#     return steer_clean_diff, rotated_steer_clean_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steering(model, game_batch, submodule, ae, feat_idx, square_idx, steering_factor, timestep=-2, device='cpu'):\n",
    "    batch_size = len(game_batch)\n",
    "    steer_clean_diffs = t.zeros(batch_size, device=device)\n",
    "    rotated_steer_clean_diffs = t.zeros(batch_size, device=device)\n",
    "    boards_clean = t.zeros(batch_size, 64, device=device)\n",
    "    boards_steer = t.zeros(batch_size, 64, device=device)\n",
    "\n",
    "    for i, game in tqdm(enumerate(game_batch), desc='Steering Batch', total=batch_size):\n",
    "        V_square_idx = square_idx\n",
    "        V_row = V_square_idx // 8\n",
    "        V_col = V_square_idx % 8\n",
    "        V_rotated_row = 7 - V_row\n",
    "        V_rotated_col = 7 - V_col\n",
    "        V_rotated_square_idx = V_rotated_row * 8 + V_rotated_col\n",
    "        C_square_idx = game[-2]\n",
    "\n",
    "        # Clean forward pass\n",
    "        with t.no_grad(), model.trace(game, **tracer_kwargs):\n",
    "            x = submodule.output\n",
    "            f = ae.encode(x).save() # shape: [batch_size, seq_len, n_features]\n",
    "            logits_clean = model.unembed.output.save() # batch_size x seq_len x vocab_size\n",
    "\n",
    "        steering_value = f[:, -1, feat_idx] # Activation value where valid_move is present\n",
    "        \n",
    "        # Steering forward pass\n",
    "        with t.no_grad(), model.trace(game, **tracer_kwargs):\n",
    "            x = submodule.output\n",
    "            f = ae.encode(x).save() # shape: [batch_size, seq_len, n_features]\n",
    "            f[:, :, feat_idx] = steering_value * steering_factor\n",
    "            submodule.output = ae.decode(f)\n",
    "            logits_steer = model.unembed.output.save() # batch_size x seq_len x vocab_size\n",
    "\n",
    "        # Logit diffs for t-2\n",
    "        logit_diff_clean = logits_clean[:, timestep, to_int(V_square_idx)] - logits_clean[:, timestep, to_int(C_square_idx)]\n",
    "        logit_diff_steer = logits_steer[:, timestep, to_int(V_square_idx)] - logits_steer[:, timestep, to_int(C_square_idx)]\n",
    "\n",
    "        rotated_logit_diff_clean = logits_clean[:, timestep, to_int(V_rotated_square_idx)] - logits_clean[:, timestep, to_int(C_square_idx)]\n",
    "        rotated_logit_diff_steer = logits_steer[:, timestep, to_int(V_rotated_square_idx)] - logits_steer[:, timestep, to_int(C_square_idx)]\n",
    "    \n",
    "        steer_clean_diffs[i] = logit_diff_steer - logit_diff_clean\n",
    "        rotated_steer_clean_diffs[i] = rotated_logit_diff_steer - rotated_logit_diff_clean\n",
    "        boards_clean[i][stoi_indices] = logits_clean[0, timestep, 1:]\n",
    "        boards_steer[i][stoi_indices] = logits_steer[0, timestep, 1:]\n",
    "\n",
    "    return steer_clean_diffs, rotated_steer_clean_diffs, boards_clean, boards_steer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_idx, config_idxs_per_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_batch_example = game_state_where_line_present(train_data_example, square_idx, config_idxs_per_feat)\n",
    "print('Number of games where line is present:', len(game_batch_example))\n",
    "for steering_factor in [0.1, 0.5, 1.0, 2.0, 5.0, 10.0]:\n",
    "    steer_clean_diff, rotated_steer_clean_diff, boards_clean, boards_steer = steering(\n",
    "        model, \n",
    "        game_batch_example, \n",
    "        submodule, \n",
    "        ae, \n",
    "        feat_idx, \n",
    "        square_idx, \n",
    "        steering_factor,\n",
    "        timestep=-1,\n",
    "        device=device\n",
    "        )\n",
    "    steer_clean_diff = steer_clean_diff.mean()\n",
    "    rotated_steer_clean_diff = rotated_steer_clean_diff.mean()\n",
    "    print(f\"Steering factor: {steering_factor}, steer_clean_diff: {steer_clean_diff.item() - rotated_steer_clean_diff.item()}, rotated_steer_clean_diff: {rotated_steer_clean_diff.item()}\")\n",
    "    # plt.imshow(boards_clean[3].view(8, 8).cpu().numpy() - boards_steer[0].view(8, 8).cpu().numpy())\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "single batch of size 100\n",
    "track number of times the condition is present\n",
    "\n",
    "do clean forward pass\n",
    "do mean ablation / zero ablation forward pass.\n",
    "\n",
    "compute difference in IEs. \n",
    "Do Activation patching for HRC and HPC neurons first\n",
    "Test wheter activation patching is also feasible for..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_patching(model, train_data, submodule, ae, feat_idx, square_idx, config_idxs_per_feat, ablation_method='zero', device='cpu'):\n",
    "    assert ablation_method in ['mean', 'zero'], \"Invalid ablation method. Must be one of ['mean', 'zero']\"\n",
    "    game_batch = t.tensor(train_data['encoded_inputs'])\n",
    "\n",
    "    # Get clean logits and mean submodule activations\n",
    "    with t.no_grad(), model.trace(game_batch, **tracer_kwargs):\n",
    "        x = submodule.output\n",
    "        if ablation_method == 'mean':\n",
    "            f = ae.encode(x) # shape: [batch_size, seq_len, n_features]\n",
    "            f_mean_clean = f.mean(dim=(0, 1))\n",
    "        logits_clean = model.unembed.output.save() # batch_size x seq_len x vocab_size\n",
    "\n",
    "    # Get patch logits\n",
    "    with t.no_grad(), model.trace(game_batch, **tracer_kwargs):\n",
    "        x = submodule.output\n",
    "        f = ae.encode(x)\n",
    "        if ablation_method == 'mean':\n",
    "            f[:, :, feat_idx] = f_mean_clean[feat_idx]\n",
    "        else:\n",
    "            f[:, :, feat_idx] = 0\n",
    "        submodule.output = ae.decode(f)\n",
    "        logits_patch = model.unembed.output.save()\n",
    "\n",
    "    logit_diff = logits_patch - logits_clean\n",
    "    logit_diff = logit_diff[:, :, to_int(square_idx)]\n",
    "    \n",
    "    line_mask = check_any_present(train_data, square_idx, config_idxs_per_feat)\n",
    "    logit_diff_line_present = logit_diff[line_mask]\n",
    "    logit_diff_line_absent = logit_diff[~line_mask]\n",
    "    return logit_diff_line_present, logit_diff_line_absent, line_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_idx, square_idx, config_idxs_per_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size=50\n",
    "# n_batches=10\n",
    "\n",
    "# for batch_idx in trange(n_batches):\n",
    "#     games_batch = [next(dataset_generator) for _ in range(batch_size)]\n",
    "#     train_data = construct_othello_dataset(\n",
    "#         custom_functions=[games_batch_to_state_stack_length_lines_mine_BLRCC],\n",
    "#         games_batch = games_batch,\n",
    "#         precompute_dataset = True,\n",
    "#     )\n",
    "\n",
    "#     logit_diff_line_present, logit_diff_line_absent, line_mask = activation_patching(\n",
    "#         model,\n",
    "#         train_data,\n",
    "#         submodule,\n",
    "#         ae,\n",
    "#         feat_idx,\n",
    "#         square_idx,\n",
    "#         config_idxs_per_feat,\n",
    "#         ablation_method='zero',\n",
    "#         device=device,\n",
    "#     )\n",
    "#     print(f'batch {batch_idx}')\n",
    "#     print(f'mean logit diff for line present: {logit_diff_line_present.mean()}')\n",
    "#     print(f'mean logit diff for line absent: {logit_diff_line_absent.mean()}')\n",
    "#     print(f'fraction of line present: {line_mask.float().mean()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
