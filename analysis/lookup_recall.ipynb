{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find lookup tables mapping high precision classifiers to \n",
    "Load reconstruction results for layer 5 Othello\n",
    "\n",
    "This notebook always uses the sae_feature_index per default, instead of the alive index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "# Imports\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch as t\n",
    "from huggingface_hub import hf_hub_download\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import numpy as np\n",
    "import einops\n",
    "\n",
    "from circuits.dictionary_learning.dictionary import AutoEncoder, AutoEncoderNew, GatedAutoEncoder, IdentityDict\n",
    "from circuits.utils import (\n",
    "    othello_hf_dataset_to_generator,\n",
    "    get_model,\n",
    "    get_submodule,\n",
    ")\n",
    "\n",
    "from feature_viz_othello_utils import (\n",
    "    get_acts_IEs_VN,\n",
    "    plot_lenses,\n",
    "    plot_mean_metrics,\n",
    "    plot_top_k_games\n",
    ")\n",
    "\n",
    "import circuits.utils as utils\n",
    "import circuits.analysis as analysis\n",
    "import feature_viz_othello_utils as viz_utils\n",
    "from circuits.othello_engine_utils import to_board_label\n",
    "\n",
    "\n",
    "\n",
    "device = 'cuda:0'\n",
    "repo_dir = '/share/u/can/chess-gpt-circuits'\n",
    "# repo_dir = \"/home/adam/chess-gpt-circuits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 5\n",
    "# node_type = \"sae_feature\"\n",
    "node_type = \"mlp_neuron\"\n",
    "\n",
    "\n",
    "if node_type == \"sae_feature\":\n",
    "    ae_group_name = 'all_layers_othello_p_anneal_0530_with_lines'\n",
    "    ae_type = 'p_anneal'\n",
    "    trainer_id = 0\n",
    "    ae_path = f'{repo_dir}/autoencoders/{ae_group_name}/layer_{layer}/trainer{trainer_id}'\n",
    "elif node_type == \"mlp_neuron\":\n",
    "    ae_group_name = 'othello_mlp_acts_identity_aes' # with_lines\n",
    "    ae_type = 'identity'\n",
    "    ae_path = f'{repo_dir}/autoencoders/{ae_group_name}/layer_{layer}'\n",
    "else:\n",
    "    raise ValueError('Invalid node_type')\n",
    "\n",
    "# download data from huggingface if needed\n",
    "if not os.path.exists(f'{repo_dir}/autoencoders/{ae_group_name}'):\n",
    "    hf_hub_download(repo_id='adamkarvonen/othello_saes', filename=f'{ae_group_name}.zip', local_dir=f'{repo_dir}/autoencoders')\n",
    "    # unzip the data\n",
    "    os.system(f'unzip {repo_dir}/autoencoders/{ae_group_name}.zip -d {repo_dir}/autoencoders')\n",
    "\n",
    "# Initialize the autoencoder\n",
    "if ae_type == 'standard' or ae_type == 'p_anneal':\n",
    "    ae = AutoEncoder.from_pretrained(os.path.join(ae_path, 'ae.pt'), device='cuda:0')\n",
    "elif ae_type == 'gated' or ae_type == 'gated_anneal':\n",
    "    ae = GatedAutoEncoder.from_pretrained(os.path.join(ae_path, 'ae.pt'), device='cuda:0')\n",
    "elif ae_type == 'standard_new':\n",
    "    ae = AutoEncoderNew.from_pretrained(os.path.join(ae_path, 'ae.pt'), device='cuda:0')\n",
    "elif ae_type == 'identity':\n",
    "    ae = IdentityDict()\n",
    "else:\n",
    "    raise ValueError('Invalid ae_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Baidicoot/Othello-GPT-Transformer-Lens\"\n",
    "model = get_model(model_name, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results files\n",
    "\n",
    "# load feature analysis results\n",
    "def to_device(d, device=device):\n",
    "    if isinstance(d, t.Tensor):\n",
    "        return d.to(device)\n",
    "    if isinstance(d, dict):\n",
    "        return {k: to_device(v, device) for k, v in d.items()}\n",
    "\n",
    "\n",
    "with open (os.path.join(ae_path, 'indexing_None_n_inputs_1000_results.pkl'), 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "results = utils.to_device(results, device)\n",
    "print(results.keys())\n",
    "\n",
    "feature_labels, misc_stats = analysis.analyze_results_dict(results, \"\", device, save_results=False, verbose=False, print_results=False, significance_threshold=100)\n",
    "print(feature_labels.keys())\n",
    "\n",
    "with open (os.path.join(ae_path, 'n_inputs_1000_evals.pkl'), 'rb') as f:\n",
    "    eval_results = pickle.load(f)\n",
    "print(eval_results.keys())\n",
    "print(f\"L0: {eval_results['eval_results']['l0']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs_function = 'games_batch_to_valid_moves_BLRRC'\n",
    "# bs_function = 'games_batch_to_state_stack_mine_yours_blank_mask_BLRRC'\n",
    "# bs_function = 'games_batch_to_state_stack_lines_mine_BLRCC'\n",
    "bs_function = 'games_batch_to_state_stack_length_lines_mine_BLRCC'\n",
    "# bs_function = 'games_batch_to_state_stack_opponent_length_lines_mine_BLRCC'\n",
    "\n",
    "alive_to_feat_idx = {v.item(): i for i, v in enumerate(feature_labels['alive_features'])}\n",
    "n_features_alive = len(alive_to_feat_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[bs_function].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[bs_function]['on'].shape, results[bs_function]['all'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(results[bs_function]['on'].max(dim=0).values.max(dim=0).values < results[bs_function]['all']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_and_off = results[bs_function]['on'] + results[bs_function]['off']\n",
    "for thresh in range(1, 10):\n",
    "    for freat in range(n_features_alive):\n",
    "        assert t.all(on_and_off[thresh, freat] == results[bs_function]['all'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall\n",
    "\n",
    "recall = TP / all_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-6\n",
    "recall_TFRRC = results[bs_function]['on'] / (results[bs_function]['all'] + epsilon)\n",
    "precision_TFRRC = results[bs_function]['on'] / (results['on_count'][:, :, None, None, None] + epsilon)\n",
    "\n",
    "# f1_TFRRC = 2 * recall_TFRRC * precision_TFRRC / (recall_TFRRC + precision_TFRRC + epsilon)\n",
    "# recall_TFRRC = precision_TFRRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop values with incorrect initialization in the first evaluation run\n",
    "recall_TFSqLenDir = einops.rearrange(recall_TFRRC, 'T F R1 R2 (Len Dir) -> T F (R1 R2) Len Dir', Len=6, Dir=8)\n",
    "# recall_TFSqLenDir = recall_TFSqLenDir[:, :, :, 1:-1, :]\n",
    "\n",
    "# Lookup table feature, indices with recall above T_recall\n",
    "T_recall = 0.95\n",
    "high_recall_TFSqLenDir = (recall_TFSqLenDir > T_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_recall_TFSqLenDir.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose T_fire with the maximum hrc features\n",
    "# Looks like noise? what's the random baseline?\n",
    "\n",
    "T_fire_hrc_count = high_recall_TFSqLenDir.sum(dim=(1,2,3,4))\n",
    "plt.bar(t.arange(T_fire_hrc_count.shape[0]).cpu().detach().numpy(), T_fire_hrc_count.cpu().detach().numpy())\n",
    "plt.xlabel('T_fire')\n",
    "plt.ylabel('log(Number of HRC features)')\n",
    "plt.title(f'HRC {node_type} for valid_moves')\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "T_fire_max_hrc = T_fire_hrc_count.argmax().item()\n",
    "print(f'the T_fire with the maximum hrc features is {T_fire_max_hrc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate over T_fire\n",
    "high_recall_FSqLenDir = t.any(high_recall_TFSqLenDir, dim=0).int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookup tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookup: feature --> bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_per_feature = high_recall_FSqLenDir.sum(dim=(1,2,3))\n",
    "\n",
    "counts = plt.hist(lines_per_feature.cpu().detach().numpy())\n",
    "plt.xlabel('Number of lines per feature')\n",
    "plt.ylabel('log(Count of features)')\n",
    "plt.title(f'HRC {node_type}')\n",
    "plt.yscale('log')\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indices of high_recall_F where value ==1\n",
    "high_recall_FSq = t.any(high_recall_FSqLenDir, dim=(-2, -1)).int()\n",
    "high_recall_F = t.sum(high_recall_FSq, dim=-1)\n",
    "feat_idx_single_square_any_number_of_lines = t.where(high_recall_F == 1)[0]\n",
    "print(f'Number of features with high recall for a single square: {feat_idx_single_square_any_number_of_lines.shape[0]}')\n",
    "high_recall_filtered_FSqLenDir = high_recall_FSqLenDir[feat_idx_single_square_any_number_of_lines]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DLA vs valid_move HRC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookup bs --> feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_per_square = high_recall_filtered_FSqLenDir.sum(dim=(0,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = plt.hist(features_per_square.cpu().detach().numpy())\n",
    "plt.xlabel('Number of features per square, any line')\n",
    "plt.ylabel('Count of squares')\n",
    "plt.title(f'HRC {node_type} for Line (Sq * Len * Dir)\\n filtered for HRC corresponding to a single square')\n",
    "\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feature_viz_othello_utils\n",
    "importlib.reload(feature_viz_othello_utils) \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "viz_utils.visualize_board_from_tensor(ax, features_per_square, title=f'Number of HRC {node_type}s per valid move', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we already filter for features with high recall for exactly 1 square\n",
    "# for a single square, print all the board configurations that have a high recall feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eights = [[-1, 0], [-1, 1], [0, 1], [1, 1], [1, 0], [1, -1], [0, -1], [-1, -1]]\n",
    "color_map = {-1: 'black', 0: 'grey', 1: 'gold', -9: 'white', -3: 'green'}\n",
    "color_lbl = {'Mine': -1, 'Empty': 0, 'Yours': 1, 'Not classified': -9, 'Valid move': -3}\n",
    "\n",
    "# Function mapping (Sq, Len, Dir) to a (64,) board tensor\n",
    "def to_board_tensor(square_idxs, lengths, directions, device, opponent_only=True):\n",
    "    board_tensor = t.ones((len(square_idxs), 8, 8), device=device) * color_lbl['Not classified']\n",
    "    for i, (square_idx, len_idx, dir_idx) in enumerate(zip(square_idxs, lengths, directions)):\n",
    "        x, y = square_idx // 8, square_idx % 8\n",
    "        dx, dy = eights[dir_idx]\n",
    "\n",
    "        if opponent_only is False:\n",
    "            board_tensor[i, x, y] = color_lbl['Valid move']\n",
    "        else:\n",
    "            board_tensor[i, x, y] = color_lbl['Empty']\n",
    "        for _ in range(1, len_idx + 2):\n",
    "            x += dx\n",
    "            y += dy\n",
    "            if x < 0 or x >= 8 or y < 0 or y >= 8:\n",
    "                print('Out of bounds')\n",
    "                break\n",
    "            board_tensor[i, x, y] = color_lbl['Yours']\n",
    "\n",
    "        if opponent_only is False:\n",
    "            x += dx\n",
    "            y += dy\n",
    "            board_tensor[i, x, y] = color_lbl['Mine']\n",
    "    return board_tensor\n",
    "\n",
    "def plot_board_categorical(fig, axs, boards, node_idxs, node_type):\n",
    "    # Define color ma\n",
    "    colors = list(color_map.values())\n",
    "    cmap = plt.matplotlib.colors.ListedColormap(colors)\n",
    "    label_to_enumerate = {label: i for i, label in enumerate(color_map.keys())}\n",
    "    vmin=0\n",
    "    vmax=len(color_map)-1\n",
    "    norm = plt.matplotlib.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "    \n",
    "    # Plot each board\n",
    "    for ax, board, feat_idx in zip(axs.flat, boards, node_idxs):\n",
    "        board_indices = np.vectorize(lambda x: label_to_enumerate[x])(board)\n",
    "        cax = ax.imshow(board_indices, cmap=cmap, norm=norm)\n",
    "\n",
    "        # Plot labeling\n",
    "        ax.set_xticks(range(8))\n",
    "        ax.set_xticklabels(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'])\n",
    "        # ax.set_title(f'{node_type} #{feat_idx}', fontsize=10)\n",
    "\n",
    "    cbar = fig.colorbar(cax, ax=axs, norm=norm, orientation='vertical', ticks=range(len(color_lbl)))\n",
    "    cbar.ax.set_yticklabels(list(color_lbl.keys()))\n",
    "\n",
    "# Test\n",
    "# fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "# btensor = to_board_tensor([0,1,2], [0,1,2], [4, 4, 4], device, opponent_only=False).cpu().detach().numpy()\n",
    "# plot_board_categorical(fig, axs, btensor, [0,0,0], node_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feat_idx_single_square_any_number_of_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HRC_nonzero = high_recall_filtered_FSqLenDir.nonzero()\n",
    "HRC_features = HRC_nonzero[:, 0].unique()\n",
    "\n",
    "for feat_idx in HRC_features:\n",
    "    feature_idxs, square_idxs, lengths, directions = HRC_nonzero[HRC_nonzero[:, 0] == feat_idx].T\n",
    "    boards = to_board_tensor(square_idxs, lengths, directions, device, opponent_only=False)\n",
    "\n",
    "    plot_cols = 6\n",
    "    plot_rows = (len(boards) + plot_cols-1) // plot_cols\n",
    "    fig, axs = plt.subplots(plot_rows, plot_cols, figsize=(12, plot_rows+1))\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.4)  # Adjust spacing between subplots\n",
    "    mlp_idx = feat_idx_single_square_any_number_of_lines[feat_idx]\n",
    "    fig.suptitle(f'{node_type} #{mlp_idx}')\n",
    "    \n",
    "    plot_board_categorical(fig, axs, boards.cpu().detach().numpy(), feature_idxs.cpu().detach().numpy(), node_type)\n",
    "    # Remove empty subplots\n",
    "    n_empty = plot_cols*plot_rows - len(boards)\n",
    "    for i in range(n_empty):\n",
    "        fig.delaxes(axs.flatten()[-i-1])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    if feat_idx > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_idxs_SqLenDir = t.zeros((0, 3), dtype=t.int)\n",
    "valid_board = t.zeros((8, 8), dtype=t.int)\n",
    "eights = [(0, 1), (1, 0), (1, 1), (1, -1), (0, -1), (-1, 0), (-1, -1), (-1, 1)]\n",
    "for square_idx in range(64):\n",
    "    r = square_idx // 8\n",
    "    c = square_idx % 8\n",
    "    for direction_idx, (dx, dy) in enumerate(eights):\n",
    "        x, y = r + 2*dx, c + 2*dy\n",
    "        length = 0\n",
    "        while 0 <= x < 8 and 0 <= y < 8:\n",
    "            idx_SqLenDir = t.tensor([square_idx, length, direction_idx], dtype=t.int).view(1, 3)\n",
    "            valid_idxs_SqLenDir = t.cat([valid_idxs_SqLenDir, idx_SqLenDir], dim=0)\n",
    "            valid_board[r, c] += 1\n",
    "            # Update for next iteration\n",
    "            x += dx\n",
    "            y += dy\n",
    "            length += 1\n",
    "\n",
    "print(f'Total number of valid lines: {valid_board.sum()}')\n",
    "\n",
    "# Plotting the valid_board\n",
    "plt.imshow(valid_board.cpu().detach().numpy(), cmap='viridis')\n",
    "plt.xticks(range(8))\n",
    "plt.yticks(range(8))\n",
    "plt.gca().set_xticklabels(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'])\n",
    "\n",
    "# Annotate each square with its value\n",
    "for i in range(valid_board.size(0)):\n",
    "    for j in range(valid_board.size(1)):\n",
    "        plt.text(j, i, f'{valid_board[i, j].item()}', ha='center', va='center', color='white')\n",
    "plt.title('Number of line configurations that make a valid move')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_idxs, length_idxs, direction_idxs = valid_idxs_SqLenDir.T\n",
    "\n",
    "T_recall_space = t.cat((t.linspace(0, 0.95, 50), t.linspace(0.95, 1, 50)))\n",
    "frac_valid_lines_classified = t.zeros(T_recall_space.shape)\n",
    "for i, T_recall in enumerate(T_recall_space):\n",
    "    # Apply T_recall\n",
    "    hrc_TFSqLenDir = (recall_TFSqLenDir > T_recall).int().cpu()\n",
    "\n",
    "    # HRC for any T_fir\n",
    "    hrc_FSqLenDir = t.any(hrc_TFSqLenDir, dim=0)\n",
    "\n",
    "    # Only features with high recall for a single square\n",
    "    hrc_FSq = t.any(hrc_FSqLenDir, dim=(-2, -1))\n",
    "    hrc_F = t.sum(hrc_FSq, dim=-1)\n",
    "    hrc_feat_idx_single_square_any_number_of_lines = t.where(hrc_F == 1)[0]\n",
    "    hrc_FSqLenDir = hrc_FSqLenDir[hrc_feat_idx_single_square_any_number_of_lines]\n",
    "    \n",
    "    # Select valid lines\n",
    "    valid_LenDirs = hrc_FSqLenDir[:, square_idxs, length_idxs, direction_idxs]\n",
    "    frac_valid_lines_classified[i] = valid_LenDirs.sum() / (valid_board.sum() - 4*19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(T_recall_space.cpu().detach().numpy(), frac_valid_lines_classified.cpu().detach().numpy(), zorder=10)\n",
    "plt.xlabel('T_recall')\n",
    "plt.ylabel(f'Fraction of valid lines classified with high recall')\n",
    "plt.grid(alpha=0.5, zorder=1)\n",
    "# plt.ylim(-0.05, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply T_recall\n",
    "T_recall = 0.95\n",
    "hrc_TFSqLenDir = (recall_TFSqLenDir > T_recall).int().cpu()\n",
    "\n",
    "# HRC for any T_fire\n",
    "hrc_FSqLenDir = t.any(hrc_TFSqLenDir, dim=0)\n",
    "\n",
    "# Only features with high recall for a single square\n",
    "hrc_FSq = t.any(hrc_FSqLenDir, dim=(-2, -1))\n",
    "hrc_F = t.sum(hrc_FSq, dim=-1)\n",
    "hrc_feat_idx_single_square_any_number_of_lines = t.where(hrc_F == 1)[0]\n",
    "hrc_single_FSqLenDir = hrc_FSqLenDir[hrc_feat_idx_single_square_any_number_of_lines]\n",
    "hrc_single_F = hrc_single_FSqLenDir.any(dim=(-3, -2, -1))\n",
    "print(f'Number of features with high recall for a single square: {hrc_single_F.sum()}')\n",
    "\n",
    "hrc_FSqLenDir[~hrc_feat_idx_single_square_any_number_of_lines] = 0\n",
    "hrc_FSqLenDir.nonzero()[:, :2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_function_VM = 'games_batch_to_valid_moves_BLRRC'\n",
    "precision_VM_TFRRC = results[bs_function_VM]['on'] / (results['on_count'][:, :, None, None, None] + epsilon)\n",
    "precision_VM_TFSq = einops.rearrange(precision_VM_TFRRC, 'T F R1 R2 1 -> T F (R1 R2 1)')\n",
    "precision_VM_TFSq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_precision_space = t.cat((t.linspace(0, 0.95, 50), t.linspace(0.95, 1, 50)))\n",
    "frac_valid_moves_classified = t.zeros(T_precision_space.shape)\n",
    "precision_F_to_Sq = []\n",
    "for i, T_precision in enumerate(T_precision_space):\n",
    "    # Apply T_precision\n",
    "    hpc_TFSq = (precision_VM_TFSq > T_precision).int().cpu()\n",
    "\n",
    "    # HPC for any T_fire\n",
    "    hpc_FSq = t.any(hpc_TFSq, dim=0)\n",
    "\n",
    "    # Only features with high precision for a single square\n",
    "    hpc_F = t.sum(hpc_FSq, dim=-1)\n",
    "    hpc_feat_idx_single_square_any_number_of_lines = t.where(hpc_F == 1)[0]\n",
    "    hpc_single_FSq = hpc_FSq[hpc_feat_idx_single_square_any_number_of_lines]\n",
    "    hpc_Sq = hpc_single_FSq.any(dim=0)\n",
    "    frac_valid_moves_classified[i] = hpc_Sq.sum() / 60\n",
    "    hpc_FSq[~hpc_feat_idx_single_square_any_number_of_lines] = 0\n",
    "    precision_F_to_Sq.append(t.nonzero(hpc_FSq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(T_precision_space.cpu().detach().numpy(), frac_valid_moves_classified.cpu().detach().numpy(), zorder=10)\n",
    "plt.xlabel('T_precision')\n",
    "plt.ylabel(f'Fraction of valid moves classified with high precision')\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.grid(alpha=0.5, zorder=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply T_precision \n",
    "T_precision = 0.95\n",
    "hpc_TFSq = (precision_VM_TFSq > T_precision).int().cpu()\n",
    "\n",
    "# HPC for any T_fire\n",
    "hpc_FSq = t.any(hpc_TFSq, dim=0)\n",
    "\n",
    "# Only features with high precision for a single square\n",
    "hpc_F = t.sum(hpc_FSq, dim=-1)\n",
    "hpc_feat_idx_single_square_any_number_of_lines = t.where(hpc_F == 1)[0]\n",
    "hpc_single_FSq = hpc_FSq[hpc_feat_idx_single_square_any_number_of_lines]\n",
    "hpc_single_F = hpc_FSq.any(dim=1)\n",
    "print(f'Number of features with high precision for a single square: {hpc_single_F.sum()}')\n",
    "\n",
    "hpc_FSq[~hpc_feat_idx_single_square_any_number_of_lines] = 0\n",
    "hpc_F_to_Sq = t.nonzero(hpc_FSq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpc_F_to_Sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersection of HRC and HPC\n",
    "hrc_single_expanded_F, hpc_single_expanded_F = t.zeros(2048, dtype=t.int), t.zeros(2048, dtype=t.int)\n",
    "hrc_single_expanded_F[hrc_feat_idx_single_square_any_number_of_lines] = 1\n",
    "hpc_single_expanded_F[hpc_feat_idx_single_square_any_number_of_lines] = 1\n",
    "hrc_hpc_single_F = hrc_single_expanded_F * hpc_single_expanded_F\n",
    "print(f'Number of features with high recall and high precision for a single square: {hrc_hpc_single_F.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrc_indexes_single_F = t.nonzero(hrc_single_expanded_F)\n",
    "hpc_indexes_single_F = t.nonzero(hpc_single_expanded_F)\n",
    "hrc_hpc_indexes_single_F = t.nonzero(hrc_hpc_single_F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrc_indexes_single_F.shape, hpc_indexes_single_F.shape, hrc_hpc_indexes_single_F.shape\n",
    "indexes_dict = {\n",
    "    'high_precision': hpc_indexes_single_F.squeeze().tolist(),\n",
    "    'high_recall': hrc_indexes_single_F.squeeze().tolist(),\n",
    "    'high_precision_and_recall': hrc_hpc_indexes_single_F.squeeze().tolist()\n",
    "    }\n",
    "\n",
    "# export the indexes with json\n",
    "import json\n",
    "with open(os.path.join(ae_path, 'hpc_hrc_indexes_dict.json'), 'w') as f:\n",
    "    json.dump(indexes_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
