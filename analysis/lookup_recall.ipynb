{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find lookup tables mapping high precision classifiers to \n",
    "Load reconstruction results for layer 5 Othello\n",
    "\n",
    "This notebook always uses the sae_feature_index per default, instead of the alive index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "# Imports\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch as t\n",
    "from huggingface_hub import hf_hub_download\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import numpy as np\n",
    "import einops\n",
    "\n",
    "from circuits.dictionary_learning.dictionary import AutoEncoder, AutoEncoderNew, GatedAutoEncoder, IdentityDict\n",
    "from circuits.utils import (\n",
    "    othello_hf_dataset_to_generator,\n",
    "    get_model,\n",
    "    get_submodule,\n",
    ")\n",
    "\n",
    "from feature_viz_othello_utils import (\n",
    "    get_acts_IEs_VN,\n",
    "    plot_lenses,\n",
    "    plot_mean_metrics,\n",
    "    plot_top_k_games\n",
    ")\n",
    "\n",
    "import circuits.utils as utils\n",
    "import circuits.analysis as analysis\n",
    "import feature_viz_othello_utils as viz_utils\n",
    "from circuits.othello_engine_utils import to_board_label\n",
    "\n",
    "\n",
    "\n",
    "device = 'cuda:0'\n",
    "repo_dir = '/home/can/chess-gpt-circuits'\n",
    "# repo_dir = \"/home/adam/chess-gpt-circuits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 5\n",
    "# node_type = \"sae_feature\"\n",
    "node_type = \"mlp_neuron\"\n",
    "\n",
    "\n",
    "if node_type == \"sae_feature\":\n",
    "    ae_group_name = 'all_layers_othello_p_anneal_0530'\n",
    "    ae_type = 'p_anneal'\n",
    "    trainer_id = 0\n",
    "    ae_path = f'{repo_dir}/autoencoders/{ae_group_name}/layer_{layer}/trainer{trainer_id}'\n",
    "elif node_type == \"mlp_neuron\":\n",
    "    ae_group_name = 'othello_mlp_acts_identity_aes'\n",
    "    ae_type = 'identity'\n",
    "    ae_path = f'{repo_dir}/autoencoders/{ae_group_name}/layer_{layer}'\n",
    "else:\n",
    "    raise ValueError('Invalid node_type')\n",
    "\n",
    "# download data from huggingface if needed\n",
    "if not os.path.exists(f'{repo_dir}/autoencoders/{ae_group_name}'):\n",
    "    hf_hub_download(repo_id='adamkarvonen/othello_saes', filename=f'{ae_group_name}.zip', local_dir=f'{repo_dir}/autoencoders')\n",
    "    # unzip the data\n",
    "    os.system(f'unzip {repo_dir}/autoencoders/{ae_group_name}.zip -d {repo_dir}/autoencoders')\n",
    "\n",
    "# Initialize the autoencoder\n",
    "if ae_type == 'standard' or ae_type == 'p_anneal':\n",
    "    ae = AutoEncoder.from_pretrained(os.path.join(ae_path, 'ae.pt'), device='cuda:0')\n",
    "elif ae_type == 'gated' or ae_type == 'gated_anneal':\n",
    "    ae = GatedAutoEncoder.from_pretrained(os.path.join(ae_path, 'ae.pt'), device='cuda:0')\n",
    "elif ae_type == 'standard_new':\n",
    "    ae = AutoEncoderNew.from_pretrained(os.path.join(ae_path, 'ae.pt'), device='cuda:0')\n",
    "elif ae_type == 'identity':\n",
    "    ae = IdentityDict()\n",
    "else:\n",
    "    raise ValueError('Invalid ae_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Baidicoot/Othello-GPT-Transformer-Lens\"\n",
    "model = get_model(model_name, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results files\n",
    "\n",
    "# load feature analysis results\n",
    "def to_device(d, device=device):\n",
    "    if isinstance(d, t.Tensor):\n",
    "        return d.to(device)\n",
    "    if isinstance(d, dict):\n",
    "        return {k: to_device(v, device) for k, v in d.items()}\n",
    "\n",
    "\n",
    "with open (os.path.join(ae_path, 'indexing_None_n_inputs_1000_results.pkl'), 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "results = utils.to_device(results, device)\n",
    "print(results.keys())\n",
    "\n",
    "feature_labels, misc_stats = analysis.analyze_results_dict(results, \"\", device, save_results=False, verbose=False, print_results=False, significance_threshold=100)\n",
    "print(feature_labels.keys())\n",
    "\n",
    "with open (os.path.join(ae_path, 'n_inputs_1000_evals.pkl'), 'rb') as f:\n",
    "    eval_results = pickle.load(f)\n",
    "print(eval_results.keys())\n",
    "print(f\"L0: {eval_results['eval_results']['l0']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_function = 'games_batch_to_valid_moves_BLRRC'\n",
    "alive_to_feat_idx = {v.item(): i for i, v in enumerate(feature_labels['alive_features'])}\n",
    "n_features_alive = len(alive_to_feat_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[bs_function].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[bs_function]['on'].shape, results[bs_function]['all'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(results[bs_function]['on'].max(dim=0).values.max(dim=0).values < results[bs_function]['all']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_and_off = results[bs_function]['on'] + results[bs_function]['off']\n",
    "for thresh in range(1, 10):\n",
    "    for freat in range(n_features_alive):\n",
    "        assert t.all(on_and_off[thresh, freat] == results[bs_function]['all'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall\n",
    "\n",
    "recall = TP / all_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-6\n",
    "recall_TFRR1 = results[bs_function]['on'] / (results[bs_function]['all'] + epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of valid_moves per feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lookup table feature, indices with recall above T_recall\n",
    "T_recall = 0.9\n",
    "\n",
    "recall_TFSq = recall_TFRR1.squeeze().view(recall_TFRR1.shape[0], recall_TFRR1.shape[1], 64)\n",
    "high_recall_TFSq = (recall_TFSq > T_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose T_fire with the maximum hrc features\n",
    "# Looks like noise? what's the random baseline?\n",
    "\n",
    "T_fire_hrc_count = high_recall_TFSq.sum(dim=(1,2))\n",
    "plt.bar(t.arange(T_fire_hrc_count.shape[0]).cpu().detach().numpy(), T_fire_hrc_count.cpu().detach().numpy())\n",
    "plt.xlabel('T_fire')\n",
    "plt.ylabel('Number of HPC features')\n",
    "plt.title(f'HPC {node_type} for valid_moves')\n",
    "plt.show()\n",
    "\n",
    "T_fire_max_hrc = T_fire_hrc_count.argmax().item()\n",
    "print(f'the T_fire with the maximum hrc features is {T_fire_max_hrc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookup tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate over T_fire\n",
    "high_recall_FSq = t.any(high_recall_TFSq, dim=0).int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookup: feature --> bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_feat_to_bs = [t.nonzero(high_recall_FSq[i]).squeeze(dim=-1).tolist() for i in range(high_recall_FSq.size(0))]\n",
    "\n",
    "counts = plt.hist([len(x) for x in lookup_feat_to_bs])\n",
    "plt.xlabel('Number of valid_moves per feature')\n",
    "plt.ylabel('log(Count opf features)')\n",
    "plt.title(f'HPC {node_type}')\n",
    "plt.yscale('log')\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alive_idx_to_single_bs = [i for i, l in enumerate(lookup_feat_to_bs) if len(l) ==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookup bs --> feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_recall_SqF = high_recall_FSq.permute(1, 0)\n",
    "lookup_bs_to_feat_with_constant_neurons = [t.nonzero(high_recall_SqF[i]).squeeze(dim=-1).tolist() for i in range(high_recall_SqF.size(0))]\n",
    "\n",
    "# Filter for HRC features associated with a single valid_move\n",
    "lookup_bs_to_feat = []\n",
    "for l in lookup_bs_to_feat_with_constant_neurons:\n",
    "    cur_l = []\n",
    "    for j in l:\n",
    "        if j in alive_idx_to_single_bs:\n",
    "            cur_l.append(j)\n",
    "    lookup_bs_to_feat.append(cur_l)\n",
    "lookup_bs_to_feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = plt.hist([len(x) for x in lookup_bs_to_feat])\n",
    "plt.xlabel('Number of features per valid_move')\n",
    "plt.ylabel('Count of valid_moves')\n",
    "plt.title(f'HPC {node_type} for valid_moves')\n",
    "\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feature_viz_othello_utils\n",
    "importlib.reload(feature_viz_othello_utils) \n",
    "\n",
    "number_of_hrc_per_valid_move = t.tensor([len(x) for x in lookup_bs_to_feat])\n",
    "fig, ax = plt.subplots()\n",
    "viz_utils.visualize_board_from_tensor(ax, number_of_hrc_per_valid_move, title=f'Number of HRC {node_type} per valid move', cmap='inferno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOT_CLASSIFIED_VALUE = -9\n",
    "\n",
    "def get_feature_label_classified_squares(feature_labels, bs_function, feature_idx, mark_idx_s=None) -> t.Tensor:\n",
    "    sae_feature_board_state_RRC = t.any(feature_labels[bs_function], dim=0).int()[feature_idx]\n",
    "    sae_feature_board_state_RR = t.argmax(sae_feature_board_state_RRC, dim=-1)\n",
    "    sae_feature_board_state_RR -= 1\n",
    "\n",
    "    zero_positions_RR = t.all(sae_feature_board_state_RRC == 0, dim=-1)\n",
    "    sae_feature_board_state_RR[zero_positions_RR] = NOT_CLASSIFIED_VALUE\n",
    "    if mark_idx_s is not None:\n",
    "        sae_feature_board_state_RR[mark_idx_s//8, mark_idx_s%8] = -3\n",
    "    return sae_feature_board_state_RR.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_board_categorical(fig, axs, boards, node_idx, node_type):\n",
    "    # Define color map\n",
    "    color_map = {-1: 'black', 0: 'grey', 1: 'gold', NOT_CLASSIFIED_VALUE: 'white', -3: 'green'}\n",
    "    color_map_labels = {-1: 'Mine', 0: 'Empty', 1: 'Yours', NOT_CLASSIFIED_VALUE: 'Not classified', -3: 'valid_move'}\n",
    "    colors = list(color_map.values())\n",
    "    cmap = plt.matplotlib.colors.ListedColormap(colors)\n",
    "    label_to_enumerate = {label: i for i, label in enumerate(color_map.keys())}\n",
    "    vmin=0\n",
    "    vmax=len(color_map)-1\n",
    "    norm = plt.matplotlib.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "    \n",
    "    # Plot each board\n",
    "    for ax, board, feat_idx in zip(axs.flat, boards, node_idx):\n",
    "        board_indices = np.vectorize(lambda x: label_to_enumerate[x])(board)\n",
    "        cax = ax.imshow(board_indices, cmap=cmap, norm=norm)\n",
    "\n",
    "        # Plot labeling\n",
    "        ax.set_xticks(range(8))\n",
    "        ax.set_xticklabels(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'])\n",
    "        ax.set_title(f'{node_type} #{feat_idx}', fontsize=10)\n",
    "\n",
    "    cbar = fig.colorbar(cax, ax=axs, norm=norm, orientation='horizontal', ticks=range(len(color_map_labels)))\n",
    "    cbar.ax.set_xticklabels(list(color_map_labels.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_indices = [0,1,2,21,22,23]\n",
    "for bs_index in bs_indices:\n",
    "\n",
    "    valid_move_square_label = to_board_label(bs_index)\n",
    "    nodes = lookup_bs_to_feat[bs_index]\n",
    "    input_bs_function = 'games_batch_to_state_stack_mine_yours_blank_mask_BLRRC'\n",
    "\n",
    "\n",
    "    boards = [get_feature_label_classified_squares(feature_labels, input_bs_function, node_idx, mark_idx_s=bs_index) for node_idx in nodes]\n",
    "\n",
    "    n_rows = len(boards)//4+1\n",
    "    n_cols = 4\n",
    "    n_empty = n_rows*n_cols - len(boards)\n",
    "\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols*2.5, n_rows*3.5))\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.4)  # Adjust spacing between subplots\n",
    "    plot_board_categorical(fig, axs, boards, nodes, node_type=node_type)\n",
    "\n",
    "    # Remove empty subplots\n",
    "    for i in range(n_empty):\n",
    "        fig.delaxes(axs.flatten()[-i-1])\n",
    "\n",
    "    fig.suptitle(f'HPC {node_type} for board_state, given the {node_type} is HRC for {valid_move_square_label}=valid_move', fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DLA vs valid_move HRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for bs_index in range(64):\n",
    "bs_index = 50\n",
    "\n",
    "print(f'valid_move onto {to_board_label(bs_index)} #{bs_index}')\n",
    "nodes = lookup_bs_to_feat[bs_index]\n",
    "for node_idx in nodes:\n",
    "    print(f'neuron {node_idx}')\n",
    "    plot_lenses(model, ae, node_idx, device, node_type, layer=layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.W_out.shape, model.W_U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DLA histogram\n",
    "import torch.nn.functional as F\n",
    "wOut = F.normalize(model.W_out[5], dim=1)\n",
    "wU = F.normalize(model.W_U, dim=0)\n",
    "dla = wOut @ wU\n",
    "high_dla = (dla > 0.25).sum(dim=0)\n",
    "high_dla = high_dla.cpu().detach().numpy()\n",
    "plt.bar(np.arange(len(high_dla)), high_dla, alpha=0.5, label='High DLA (cos sim > 0.25)')\n",
    "\n",
    "n_feats_per_bs = np.array([len(lookup_bs_to_feat[i]) for i in range(len(lookup_bs_to_feat))])\n",
    "plt.bar(np.arange(len(n_feats_per_bs)), n_feats_per_bs, alpha=0.5, label=\"High precision (> 0.95) for next valid_move\")\n",
    "plt.xlabel('Square index')\n",
    "plt.ylabel(f'Number of {node_type}s')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
