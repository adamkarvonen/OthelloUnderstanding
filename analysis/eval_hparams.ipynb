{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SWEEP_PATH = \"../autoencoders/othello_5-21/othello-gated_anneal/\"\n",
    "\n",
    "SAE_TRAINER_TYPE = \"gated_anneal\"\n",
    "\n",
    "HPARAMS_DICT = {\n",
    "    \"p_anneal\" : [\"lr\", \"sparsity_penalty\", \"anneal_start\", \"dict_size\"],\n",
    "    \"p_anneal_new\" : [\"lr\", \"sparsity_penalty\", \"anneal_start\", \"dict_size\"],\n",
    "    \"standard_new\" : [\"lr\", \"l1_penalty\", \"dict_size\"],\n",
    "    \"standard\" : [\"lr\", \"l1_penalty\"],\n",
    "    \"gated\" : [\"lr\", \"l1_penalty\", \"dict_size\"],\n",
    "    \"gated_anneal\" : [\"lr\", \"sparsity_penalty\", \"anneal_start\", \"dict_size\"],\n",
    "}\n",
    "HPARAMS = HPARAMS_DICT[SAE_TRAINER_TYPE]\n",
    "\n",
    "# read in the `results.csv` file from SWEEP_PATH\n",
    "df = pd.read_csv(SWEEP_PATH + \"results.csv\")\n",
    "\n",
    "# filter for SAE type\n",
    "df = df[df[\"autoencoder_path\"].str.contains(SAE_TRAINER_TYPE + \"/\")]\n",
    "\n",
    "# add trainer_id to data frame\n",
    "df[\"trainer_id\"] = df[\"autoencoder_path\"].map(lambda p: p.split(\"/\")[-2])\n",
    "df[[\"trainer_id\", \"l0\", \"frac_recovered\"]].sort_values(\"l0\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer_dirs = df[\"autoencoder_path\"].to_list()\n",
    "trainer_dirs = [SWEEP_PATH + t_id + \"/\" for t_id in df[\"trainer_id\"]]\n",
    "\n",
    "trainer_configs = {}\n",
    "for t_dir in trainer_dirs:\n",
    "    trainer_id = t_dir.split(\"/\")[-2]\n",
    "    with open(t_dir + \"/config.json\", \"r\") as f:\n",
    "        config = json.load(f)\n",
    "        trainer_configs[trainer_id] = {}\n",
    "        for h in HPARAMS:\n",
    "            trainer_configs[trainer_id][h] = config[\"trainer\"][h]\n",
    "\n",
    "for h in HPARAMS:\n",
    "    df[h] = df[\"trainer_id\"].map(lambda t_id : trainer_configs[t_id][h])\n",
    "    \n",
    "df[[\"trainer_id\", \"l0\", \"frac_recovered\"] + HPARAMS].sort_values(\"l0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sae)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
