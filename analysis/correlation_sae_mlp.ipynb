{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch as t\n",
    "import numpy as np\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from circuits.dictionary_learning.buffer import NNsightActivationBuffer\n",
    "from circuits.dictionary_learning.dictionary import AutoEncoder, AutoEncoderNew, GatedAutoEncoder\n",
    "import circuits.othello_utils as othello_utils\n",
    "from circuits.utils import (\n",
    "    othello_hf_dataset_to_generator,\n",
    "    get_model,\n",
    "    get_submodule,\n",
    ")\n",
    "\n",
    "repo_dir = '/share/u/can/chess-gpt-circuits'\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data from huggingface if needed\n",
    "if not os.path.exists(f'{repo_dir}/autoencoders/othello_5-21'):\n",
    "    hf_hub_download(repo_id='adamkarvonen/othello_saes', filename='othello_5-21.zip', local_dir=f'{repo_dir}/autoencoders')\n",
    "    # unzip the data\n",
    "    os.system(f'unzip {repo_dir}/autoencoders/othello_5-21.zip -d autoencoders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load SAE\n",
    "ae_type = 'standard_new'\n",
    "trainer_id = 0\n",
    "\n",
    "ae_path = f'{repo_dir}/autoencoders/group-2024-05-17_othello/group-2024-05-17_othello-{ae_type}/trainer{trainer_id}'\n",
    "if ae_type == 'standard':\n",
    "    ae = AutoEncoder.from_pretrained(os.path.join(ae_path, 'ae.pt'), device='cuda:0')\n",
    "elif ae_type == 'gated':\n",
    "    ae = GatedAutoEncoder.from_pretrained(os.path.join(ae_path, 'ae.pt'), device='cuda:0')\n",
    "elif ae_type == 'standard_new':\n",
    "    ae = AutoEncoderNew.from_pretrained(os.path.join(ae_path, 'ae.pt'), device='cuda:0')\n",
    "else:\n",
    "    raise ValueError('Invalid ae_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and data\n",
    "\n",
    "layer = 5\n",
    "context_length = 59\n",
    "activation_dim = 512  # output dimension of the layer\n",
    "model_name = \"Baidicoot/Othello-GPT-Transformer-Lens\"\n",
    "dataset_name = \"taufeeque/othellogpt\"\n",
    "\n",
    "game_batch_size = 100\n",
    "\n",
    "model = get_model(model_name, device)\n",
    "\n",
    "submodule = get_submodule(model_name, layer, model)\n",
    "model.blocks[layer].hook_resid_post\n",
    "\n",
    "mlp_post_submodules = [model.blocks[l].mlp.hook_post for l in range(model.cfg.n_layers)]\n",
    "\n",
    "\n",
    "data = othello_hf_dataset_to_generator(\n",
    "    dataset_name, context_length=context_length, split=\"train\", streaming=True\n",
    ")\n",
    "data = othello_hf_dataset_to_generator(\n",
    "    dataset_name, context_length=context_length, split=\"train\", streaming=True\n",
    ")\n",
    "game_batch = [next(data) for _ in range(game_batch_size)]\n",
    "game_batch = t.tensor(game_batch, device=device)\n",
    "print(f'game_batch: {len(game_batch)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single SAE feature ~ all MLP neurons\n",
    "Fixing a single SAE feature, which MLP neurons (in earlier and later layers) show high pearson correlation with the SAE feature?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From feature viz notebook: Feature #21 of f'{repo_dir}/autoencoders/group-2024-05-17_othello/group-2024-05-17_othello-{standard_new}/trainer{0}' looks like it is representing a piece on H1 or G1\n",
    "\n",
    "<img src=\"./feat21.png\" alt=\"Image description\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_idx = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caching activations with nnsight\n",
    "mlp_acts = {}\n",
    "\n",
    "with t.no_grad(), model.trace(game_batch, scan=False, validate=False):\n",
    "    x = submodule.output\n",
    "    feature_acts = ae.encode(x).save()\n",
    "    for l in range(model.cfg.n_layers):\n",
    "        mlp_acts[l] = mlp_post_submodules[l].output.save()\n",
    "\n",
    "feature_acts = einops.rearrange(feature_acts, \"B S F -> F (B S)\")\n",
    "feature_acts = feature_acts[feat_idx]\n",
    "\n",
    "for l in mlp_acts:\n",
    "    mlp_acts[l] = einops.rearrange(mlp_acts[l], \"B S F -> F (B S)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson correlation calculation function\n",
    "def pearson_corr(x, y):\n",
    "    mean_x = x.mean(dim=-1, keepdim=True)\n",
    "    mean_y = y.mean(dim=-1, keepdim=True)\n",
    "    xm = x - mean_x\n",
    "    ym = y - mean_y\n",
    "    r_num = t.sum(xm * ym, dim=-1)\n",
    "    r_den = t.sqrt(t.sum(xm * xm, dim=-1) * t.sum(ym * ym, dim=-1))\n",
    "    r = r_num / r_den\n",
    "    return r\n",
    "\n",
    "# Calculate Pearson correlation\n",
    "pearson_correlations = {}\n",
    "\n",
    "for l in mlp_acts:\n",
    "    mlp_acts_layer = mlp_acts[l]\n",
    "    correlations = t.zeros(mlp_acts_layer.shape[0])\n",
    "    for i in range(mlp_acts_layer.shape[0]):\n",
    "        mlp_feature = mlp_acts_layer[i]\n",
    "        corr = pearson_corr(feature_acts, mlp_feature)\n",
    "        correlations[i] = corr\n",
    "    pearson_correlations[l] = correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "layers = list(pearson_correlations.keys())\n",
    "data = [pearson_correlations[l].abs() for l in layers]\n",
    "\n",
    "# Create stacked histogram\n",
    "plt.hist(data, bins=100, histtype='bar', stacked=True, label=layers)\n",
    "\n",
    "# Add legend and log scale for y-axis\n",
    "plt.legend(title='Layer')\n",
    "plt.yscale('log')\n",
    "\n",
    "# Display plot\n",
    "plt.xlabel('Absolute Pearson Correlation')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Stacked Histogram of Pearson Correlations by Layer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save indices and layer for pearson_correlations above a certain threshold\n",
    "corr_threshold = 0.5\n",
    "indices = {}\n",
    "for l in pearson_correlations:\n",
    "    indices[l] = t.where(pearson_correlations[l].abs() > corr_threshold)[0]\n",
    "\n",
    "indices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
