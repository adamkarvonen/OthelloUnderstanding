{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import einops\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import sklearn\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import concurrent.futures\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from typing import Callable, Optional\n",
    "import os\n",
    "import importlib\n",
    "import pickle\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "import circuits.utils as utils\n",
    "import circuits.othello_utils as othello_utils\n",
    "from circuits.eval_sae_as_classifier import construct_othello_dataset\n",
    "\n",
    "# Setup\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "torch.set_grad_enabled(False)\n",
    "tracer_kwargs = {'validate' : False, 'scan' : False}\n",
    "tracer_kwargs = {'validate' : True, 'scan' : True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and data loading\n",
    "def load_model_and_data(model_name: str, dataset_size: int, custom_functions: list[Callable]):\n",
    "    model = utils.get_model(model_name, device)\n",
    "    data = construct_othello_dataset(\n",
    "        custom_functions=custom_functions,\n",
    "        n_inputs=dataset_size,\n",
    "        split=\"train\",\n",
    "        device=device,\n",
    "    )\n",
    "    return model, data\n",
    "\n",
    "\n",
    "# Cache Neuron Activations\n",
    "def cache_neuron_activations(\n",
    "    model, data: dict, layers: list, batch_size: int, n_batches: int\n",
    ") -> dict:\n",
    "    \"\"\"Deprecated in favor of using identity autoencoders\"\"\"\n",
    "    neuron_acts = defaultdict(list)\n",
    "\n",
    "    for batch_idx in range(n_batches):\n",
    "        batch_start = batch_idx * batch_size\n",
    "        batch_end = (batch_idx + 1) * batch_size\n",
    "        data_batch = data[\"encoded_inputs\"][batch_start:batch_end]\n",
    "        data_batch = torch.tensor(data_batch, device=device)\n",
    "\n",
    "        with torch.no_grad(), model.trace(data_batch, scan=False, validate=False):\n",
    "            for layer in layers:\n",
    "                neuron_activations_BLD = model.blocks[layer].mlp.hook_post.output.save()\n",
    "                neuron_acts[layer].append(neuron_activations_BLD)\n",
    "\n",
    "    for layer in neuron_acts:\n",
    "        neuron_acts[layer] = torch.stack(neuron_acts[layer])\n",
    "        neuron_acts[layer] = einops.rearrange(neuron_acts[layer], \"n b l c -> (n b) l c\")\n",
    "\n",
    "    return neuron_acts\n",
    "\n",
    "\n",
    "def get_submodule_dict(model, model_name: str, layers: list, input_location: str) -> dict:\n",
    "    submodule_dict = {}\n",
    "\n",
    "    for layer in layers:\n",
    "        if input_location == \"sae_feature\":\n",
    "            submodule = utils.get_resid_post_submodule(model_name, layer, model)\n",
    "        elif input_location == \"sae_mlp_feature\":\n",
    "            submodule = utils.get_mlp_activations_submodule(model_name, layer, model)\n",
    "        elif input_location == \"mlp_neuron\":\n",
    "            submodule = utils.get_mlp_activations_submodule(model_name, layer, model)\n",
    "        elif input_location == \"attention_out\":\n",
    "            submodule = model.blocks[layer].hook_attn_out\n",
    "        elif input_location == \"mlp_out\" or input_location == \"sae_mlp_out_feature\":\n",
    "            submodule = model.blocks[layer].hook_mlp_out\n",
    "        elif input_location == \"transcoder\":\n",
    "            submodule = model.blocks[layer].mlp\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid input location: {input_location}\")\n",
    "        submodule_dict[layer] = submodule\n",
    "\n",
    "    return submodule_dict\n",
    "\n",
    "def cache_sae_activations(\n",
    "    model,\n",
    "    model_name: str,\n",
    "    data: dict,\n",
    "    layers: list,\n",
    "    batch_size: int,\n",
    "    n_batches: int,\n",
    "    repo_dir: str,\n",
    "    input_location: str,\n",
    ") -> dict:\n",
    "    sae_acts = defaultdict(list)\n",
    "\n",
    "    ae_dict = utils.get_aes(node_type=input_location, repo_dir=repo_dir)\n",
    "    submodule_dict = get_submodule_dict(model, model_name, layers, input_location)\n",
    "\n",
    "    for batch_idx in range(n_batches):\n",
    "        batch_start = batch_idx * batch_size\n",
    "        batch_end = (batch_idx + 1) * batch_size\n",
    "        data_batch = data[\"encoded_inputs\"][batch_start:batch_end]\n",
    "        data_batch = torch.tensor(data_batch, device=device)\n",
    "\n",
    "        with torch.no_grad(), model.trace(data_batch, **tracer_kwargs):\n",
    "            for layer in layers:\n",
    "                ae = ae_dict[layer]\n",
    "                submodule = submodule_dict[layer]\n",
    "                if input_location != \"transcoder\":\n",
    "                    x = submodule.output\n",
    "                else:\n",
    "                    x = submodule.input[0]\n",
    "                    if type(submodule.input.shape) == tuple: x = x[0]\n",
    "                f = ae.encode(x)\n",
    "                sae_acts[layer].append(f.save())\n",
    "\n",
    "    for layer in sae_acts:\n",
    "        sae_acts[layer] = torch.stack(sae_acts[layer])\n",
    "        sae_acts[layer] = einops.rearrange(sae_acts[layer], \"n b l c -> (n b) l c\")\n",
    "\n",
    "    return sae_acts\n",
    "\n",
    "\n",
    "def get_max_activations(neuron_acts: dict, layer: int) -> torch.Tensor:\n",
    "    D = neuron_acts[layer].shape[-1]\n",
    "    max_activations_D = torch.full((D,), float(\"-inf\"), device=device)\n",
    "\n",
    "    neuron_acts_BLD = neuron_acts[layer]\n",
    "    neuron_acts_BD = einops.rearrange(neuron_acts_BLD, \"b l d -> (b l) d\")\n",
    "\n",
    "    max_activations_D = torch.max(max_activations_D, neuron_acts_BD.max(dim=0).values)\n",
    "    return max_activations_D\n",
    "\n",
    "\n",
    "def calculate_binary_activations(neuron_acts: dict, threshold: float = 0.1):\n",
    "    binary_acts = {}\n",
    "\n",
    "    for layer in neuron_acts:\n",
    "        max_activations_D = get_max_activations(neuron_acts, layer)\n",
    "\n",
    "        binary_acts[layer] = (neuron_acts[layer] > (threshold * max_activations_D)).int()\n",
    "    return binary_acts\n",
    "\n",
    "\n",
    "# Prepare data for modeling\n",
    "def prepare_data(games_BLC: torch.Tensor, mlp_acts_BLD: torch.Tensor):\n",
    "    X = einops.rearrange(games_BLC, \"b l c -> (b l) c\").cpu().numpy()\n",
    "    y = einops.rearrange(mlp_acts_BLD, \"b l d -> (b l) d\").cpu().numpy()\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Train and evaluate models\n",
    "def train_and_evaluate(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return model, mse, r2\n",
    "\n",
    "\n",
    "def train_and_evaluate_xgb(X_train, X_test, y_train, y_test, is_binary=False):\n",
    "    if is_binary:\n",
    "        model = MultiOutputClassifier(\n",
    "            XGBClassifier(\n",
    "                n_estimators=25,  # limit number of trees\n",
    "                max_depth=6,  # limit depth\n",
    "                learning_rate=0.1,\n",
    "                random_state=42,\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        model = MultiOutputRegressor(\n",
    "            XGBRegressor(n_estimators=25, max_depth=6, learning_rate=0.1, random_state=42)\n",
    "        )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    if is_binary:\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "        return model, accuracy, f1\n",
    "    else:\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        return model, mse, r2\n",
    "\n",
    "\n",
    "def calculate_neuron_metrics(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Calculate MSE for all neurons at once\n",
    "    mse_list = np.mean((y - y_pred) ** 2, axis=0)\n",
    "\n",
    "    # Calculate R2 for all neurons at once\n",
    "    ss_res = np.sum((y - y_pred) ** 2, axis=0)\n",
    "    ss_tot = np.sum((y - np.mean(y, axis=0)) ** 2, axis=0)\n",
    "\n",
    "    # Add divide-by-zero protection\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        r2_list = 1 - (ss_res / ss_tot)\n",
    "\n",
    "    # Handle cases where ss_tot is zero\n",
    "    r2_list = np.where(ss_tot == 0, 0, r2_list)\n",
    "\n",
    "    # Clip R2 values to be between 0 and 1\n",
    "    r2_list = np.clip(r2_list, 0, 1)\n",
    "\n",
    "    return mse_list, r2_list\n",
    "\n",
    "\n",
    "def calculate_binary_metrics(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Compute true positives, false positives, true negatives, false negatives\n",
    "    tp = np.sum((y_pred == 1) & (y == 1), axis=0)\n",
    "    fp = np.sum((y_pred == 1) & (y == 0), axis=0)\n",
    "    tn = np.sum((y_pred == 0) & (y == 0), axis=0)\n",
    "    fn = np.sum((y_pred == 0) & (y == 1), axis=0)\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    precision = np.divide(tp, tp + fp, out=np.zeros_like(tp, dtype=float), where=(tp + fp) != 0)\n",
    "    recall = np.divide(tp, tp + fn, out=np.zeros_like(tp, dtype=float), where=(tp + fn) != 0)\n",
    "\n",
    "    # Compute F1 score\n",
    "    f1 = np.divide(\n",
    "        2 * precision * recall,\n",
    "        precision + recall,\n",
    "        out=np.zeros_like(precision, dtype=float),\n",
    "        where=(precision + recall) != 0,\n",
    "    )\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "\n",
    "# Print decision tree rules\n",
    "def print_decision_tree_rules(model, feature_names, neuron_index, max_depth=None):\n",
    "    tree = model.estimators_[neuron_index]\n",
    "    if feature_names is None:\n",
    "        feature_names = [f\"feature_{i}\" for i in range(tree.n_features_in_)]\n",
    "    tree_rules = export_text(tree, feature_names=feature_names, max_depth=max_depth)\n",
    "    print(f\"Decision Tree Rules for Neuron {neuron_index}:\")\n",
    "    print(tree_rules)\n",
    "\n",
    "\n",
    "def rc_to_square_notation(row, col):\n",
    "    letters = \"ABCDEFGH\"\n",
    "    letter = letters[row]\n",
    "    number = 8 - col\n",
    "    # letter = letters[col]\n",
    "    return f\"{letter}{number}\"\n",
    "\n",
    "\n",
    "def idx_to_square_notation(idx):\n",
    "    row = idx // 8\n",
    "    col = idx % 8\n",
    "    square = rc_to_square_notation(row, col)\n",
    "    return square\n",
    "\n",
    "\n",
    "def compute_kl_divergence(logits_clean_BLV, logits_patch_BLV):\n",
    "    # Apply softmax to get probability distributions\n",
    "    log_probs_clean_BLV = torch.nn.functional.log_softmax(logits_clean_BLV, dim=-1)\n",
    "    log_probs_patch_BLV = torch.nn.functional.log_softmax(logits_patch_BLV, dim=-1)\n",
    "\n",
    "    # Compute KL divergence\n",
    "    kl_div_BLV = torch.nn.functional.kl_div(\n",
    "        log_probs_patch_BLV, log_probs_clean_BLV.exp(), reduction=\"none\", log_target=False\n",
    "    )\n",
    "\n",
    "    # Sum over the vocabulary dimension\n",
    "    kl_div_BL = kl_div_BLV.sum(dim=-1)\n",
    "\n",
    "    return kl_div_BL\n",
    "\n",
    "\n",
    "def add_output_folders():\n",
    "    os.makedirs(\"decision_trees\", exist_ok=True)\n",
    "    os.makedirs(\"images\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_layer(\n",
    "    layer: int,\n",
    "    games_BLC: torch.Tensor,\n",
    "    neuron_acts: dict,\n",
    "    binary_acts: dict,\n",
    "    linear_reg: bool = False,\n",
    "    regular_dt: bool = True,\n",
    "    binary_dt: bool = True,\n",
    "    max_depth: int = 8,\n",
    "    random_seed: int = 42,\n",
    ") -> dict:\n",
    "\n",
    "    print(f\"\\nLayer {layer}\")\n",
    "\n",
    "    if regular_dt:\n",
    "        X_train, X_test, y_train, y_test = prepare_data(games_BLC, neuron_acts[layer])\n",
    "\n",
    "        # Decision Tree\n",
    "        dt_model, dt_mse, dt_r2 = train_and_evaluate(\n",
    "            MultiOutputRegressor(\n",
    "                DecisionTreeRegressor(\n",
    "                    random_state=random_seed, max_depth=max_depth, #min_samples_leaf=5, min_samples_split=5\n",
    "                )\n",
    "            ),\n",
    "            X_train,\n",
    "            X_test,\n",
    "            y_train,\n",
    "            y_test,\n",
    "        )\n",
    "\n",
    "        dt_mse, dt_r2 = calculate_neuron_metrics(dt_model, X_test, y_test)\n",
    "\n",
    "    if binary_dt:\n",
    "        # Binary Decision Tree\n",
    "        X_binary_train, X_binary_test, y_binary_train, y_binary_test = prepare_data(\n",
    "            games_BLC, binary_acts[layer]\n",
    "        )\n",
    "        dt_binary_model = MultiOutputClassifier(\n",
    "            DecisionTreeClassifier(\n",
    "                random_state=random_seed, max_depth=max_depth, #min_samples_leaf=5, min_samples_split=5\n",
    "            )\n",
    "        )\n",
    "        dt_binary_model.fit(X_binary_train, y_binary_train)\n",
    "\n",
    "        accuracy, precision, recall, f1 = calculate_binary_metrics(dt_binary_model, X_binary_test, y_binary_test)\n",
    "\n",
    "    layer_results = {\n",
    "        \"layer\": layer,\n",
    "        \"regular_dt\": {\"model\": dt_model, \"mse\": dt_mse, \"r2\": dt_r2},\n",
    "        \"binary_dt\": {\n",
    "            \"model\": dt_binary_model,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    if linear_reg:\n",
    "        lasso_model, lasso_mse, lasso_r2 = train_and_evaluate(\n",
    "            Lasso(alpha=0.005), X_train, X_test, y_train, y_test\n",
    "        )\n",
    "        layer_results[\"lasso\"] = {\"model\": lasso_model, \"mse\": lasso_mse, \"r2\": lasso_r2}\n",
    "\n",
    "    print(f\"Finished Layer {layer}\")\n",
    "\n",
    "    return layer_results\n",
    "\n",
    "def process_layer_xgb(\n",
    "    layer: int,\n",
    "    games_BLC: torch.Tensor,\n",
    "    neuron_acts: dict,\n",
    "    binary_acts: dict,\n",
    "    linear_reg: bool = False,\n",
    ") -> dict:\n",
    "    \n",
    "\n",
    "    print(f\"\\nLayer {layer}\")\n",
    "    X_train, X_test, y_train, y_test = prepare_data(games_BLC, neuron_acts[layer])\n",
    "\n",
    "    # Decision Tree\n",
    "    xgb_model, xgb_mse, xgb_r2 = train_and_evaluate_xgb(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Binary Decision Tree\n",
    "    X_binary_train, X_binary_test, y_binary_train, y_binary_test = prepare_data(\n",
    "        games_BLC, binary_acts[layer]\n",
    "    )\n",
    "    xgb_binary_model, xgb_accuracy, xgb_f1 = train_and_evaluate_xgb(\n",
    "        X_binary_train, X_binary_test, y_binary_train, y_binary_test, is_binary=True\n",
    "    )\n",
    "\n",
    "    layer_results = {\n",
    "        \"layer\": layer,\n",
    "        \"regular_dt\": {\"model\": xgb_model, \"mse\": xgb_mse, \"r2\": xgb_r2},\n",
    "        \"binary_dt\": {\n",
    "            \"model\": xgb_binary_model,\n",
    "            \"accuracy\": xgb_accuracy,\n",
    "            \"f1\": xgb_f1,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return layer_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interventions(\n",
    "    model,\n",
    "    model_name: str,\n",
    "    train_data: dict,\n",
    "    selected_features: dict[int, torch.Tensor],\n",
    "    ae_dict: dict,\n",
    "    submodule_dict: dict,\n",
    "    layers: list[int],\n",
    "    input_location: str,\n",
    "    ablation_method: str=\"zero\",\n",
    "    decision_trees: Optional[dict]=None,\n",
    "    custom_function: Optional[Callable]=None,\n",
    "    ablate_not_selected: bool = False,\n",
    "    add_error: bool = False,\n",
    "):\n",
    "    allowed_methods = [\"mean\", \"zero\", \"max\", \"dt\"]\n",
    "    assert ablation_method in allowed_methods, f\"Invalid ablation method. Must be one of {allowed_methods}\"\n",
    "    game_batch_BL = torch.tensor(train_data[\"encoded_inputs\"])\n",
    "\n",
    "    simulated_activations = {}\n",
    "    mean_activations = {}\n",
    "\n",
    "    if ablation_method == \"dt\":\n",
    "        board_state_BLC = train_data[custom_function.__name__]\n",
    "        B, L, C = board_state_BLC.shape\n",
    "        X = einops.rearrange(board_state_BLC, \"b l c -> (b l) c\").cpu().numpy()\n",
    "\n",
    "        for layer in layers:\n",
    "            decision_tree = decision_trees[layer][custom_function.__name__][\"decision_tree\"][\"model\"]\n",
    "            simulated_activations_BF = decision_tree.predict(X)\n",
    "            simulated_activations_BF = torch.tensor(simulated_activations_BF, device=device, dtype=torch.float32)\n",
    "            simulated_activations_BLF = einops.rearrange(simulated_activations_BF, \"(b l) f -> b l f\", b=B, l=L)\n",
    "            simulated_activations[layer] = simulated_activations_BLF\n",
    "\n",
    "    # Get clean logits and mean submodule activations\n",
    "    with torch.no_grad(), model.trace(game_batch_BL, **tracer_kwargs):\n",
    "        for layer in layers:\n",
    "            submodule = submodule_dict[layer]\n",
    "            ae = ae_dict[layer]\n",
    "            if input_location != \"transcoder\":\n",
    "                original_input_BLD = submodule.output\n",
    "            else:\n",
    "                original_input_BLD = submodule.input[0]\n",
    "                if type(submodule.input.shape) == tuple: original_input_BLD = original_input_BLD[0]\n",
    "\n",
    "            encoded_BLF = ae.encode(original_input_BLD)\n",
    "\n",
    "            if ablation_method == \"mean\":\n",
    "                mean_activations[layer] = encoded_BLF.mean(dim=(0, 1)).save()\n",
    "            elif ablation_method == \"max\":\n",
    "                max_activations = encoded_BLF.max(dim=0).values\n",
    "                mean_activations[layer] = max_activations.max(dim=0).values.save()\n",
    "        \n",
    "        logits_clean_BLV = model.unembed.output.save()\n",
    "\n",
    "    # Get patch logits\n",
    "    with torch.no_grad(), model.trace(game_batch_BL, **tracer_kwargs):\n",
    "        for layer in layers:\n",
    "\n",
    "            submodule = submodule_dict[layer]\n",
    "            ae = ae_dict[layer]\n",
    "            original_output_BLD = submodule.output\n",
    "\n",
    "            if input_location != \"transcoder\":\n",
    "                encoded_BLF = ae.encode(original_output_BLD)\n",
    "            else:\n",
    "                original_input_BLD = submodule.input[0]\n",
    "                if type(submodule.input.shape) == tuple: original_input_BLD = original_input_BLD[0]\n",
    "                encoded_BLF = ae.encode(original_input_BLD)\n",
    "\n",
    "            feat_idxs = selected_features[layer]\n",
    "\n",
    "            decoded_BLD = ae.decode(encoded_BLF)\n",
    "            error_BLD = original_output_BLD - decoded_BLD\n",
    "\n",
    "            if ablation_method == \"mean\":\n",
    "                encoded_BLF[:, :, feat_idxs] = mean_activations[layer][feat_idxs]\n",
    "            elif ablation_method == \"max\":\n",
    "                encoded_BLF[:, :, feat_idxs] = mean_activations[layer][feat_idxs]\n",
    "            elif ablation_method == \"dt\":\n",
    "                encoded_BLF[:, :, feat_idxs] = simulated_activations[layer][:, :, feat_idxs]\n",
    "                if ablate_not_selected:\n",
    "                    not_feature_idxs_F = ~feat_idxs\n",
    "                    encoded_BLF[:, :, not_feature_idxs_F] = 0\n",
    "            else:\n",
    "                encoded_BLF[:, :, feat_idxs] = 0\n",
    "            \n",
    "            modified_decoded_BLD = ae.decode(encoded_BLF)\n",
    "\n",
    "            submodule.output = modified_decoded_BLD \n",
    "            if add_error:\n",
    "                submodule.output += error_BLD\n",
    "\n",
    "        logits_patch_BLV = model.unembed.output.save()\n",
    "\n",
    "    return logits_clean_BLV, logits_patch_BLV\n",
    "\n",
    "def compute_predictors(\n",
    "    custom_functions: list[Callable],\n",
    "    num_cores: int,\n",
    "    layers: list[int],\n",
    "    data: dict,\n",
    "    neuron_acts: dict,\n",
    "    binary_acts: dict,\n",
    "    input_location: str,\n",
    "    dataset_size: int,\n",
    "    force_recompute: bool = False,\n",
    "    save_results: bool = True,\n",
    "    max_depth: int = 8,\n",
    ") -> dict:\n",
    "    \n",
    "    output_filename = f\"decision_trees/decision_trees_{input_location}_{dataset_size}.pkl\"\n",
    "\n",
    "    if not force_recompute and os.path.exists(output_filename):\n",
    "        print(f\"Loading decision trees from {output_filename}\")\n",
    "        with open(output_filename, \"rb\") as f:\n",
    "            decision_trees = pickle.load(f)\n",
    "        return decision_trees\n",
    "\n",
    "    # Use all available cores, but max out at num_cores\n",
    "    num_cores = min(num_cores, multiprocessing.cpu_count())\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for layer in layers:\n",
    "        results[layer] = {}\n",
    "\n",
    "    for custom_function in custom_functions:\n",
    "\n",
    "        print(f\"\\n{custom_function.__name__}\")\n",
    "        games_BLC = data[custom_function.__name__]\n",
    "        games_BLC = utils.to_device(games_BLC, \"cpu\")\n",
    "\n",
    "        layer_results = Parallel(n_jobs=num_cores)(\n",
    "            delayed(process_layer)(layer, games_BLC, neuron_acts, binary_acts, max_depth=max_depth)\n",
    "            for layer in layers\n",
    "        )\n",
    "\n",
    "        for layer_result in layer_results:\n",
    "            if layer_result is not None:\n",
    "                layer = layer_result[\"layer\"]\n",
    "                results[layer][custom_function.__name__] = {\n",
    "                    \"decision_tree\": layer_result[\"regular_dt\"],\n",
    "                    \"binary_decision_tree\": layer_result[\"binary_dt\"],\n",
    "                }\n",
    "\n",
    "        # with ProcessPoolExecutor(max_workers=num_cores) as executor:\n",
    "        #     future_to_layer = {executor.submit(process_layer, layer, games_BLC, neuron_acts, binary_acts): layer for layer in layers}\n",
    "        #     for future in concurrent.futures.as_completed(future_to_layer):\n",
    "        #         layer_result = future.result()\n",
    "        #         layer = layer_result['layer']\n",
    "        #         results[layer][custom_function.__name__] = {\n",
    "        #             'decision_tree': layer_result['regular_dt'],\n",
    "        #             'binary_decision_tree': layer_result['binary_dt']\n",
    "        #         }\n",
    "\n",
    "    if save_results:\n",
    "        with open(output_filename, \"wb\") as f:\n",
    "            pickle.dump(results, f)\n",
    "    return results\n",
    "\n",
    "def perform_interventions(\n",
    "    decision_trees: dict,\n",
    "    input_location: str,\n",
    "    ablation_method: str,\n",
    "    ablate_not_selected: bool,\n",
    "    add_error: bool,\n",
    "    custom_function: Callable,\n",
    "    repo_dir: str,\n",
    "    model,\n",
    "    model_name: str,\n",
    "    layers: list,\n",
    "    data: dict,\n",
    "    threshold: float,\n",
    "):\n",
    "\n",
    "    ablations = {}\n",
    "\n",
    "    ae_dict = utils.get_aes(node_type=input_location, repo_dir=repo_dir)\n",
    "    submodule_dict = get_submodule_dict(model, model_name, layers, input_location)\n",
    "\n",
    "    if input_location == \"mlp_neuron\":\n",
    "        d_model = 2048\n",
    "    elif input_location == \"sae_feature\" or input_location == \"sae_mlp_out_feature\" or input_location == \"transcoder\":\n",
    "        d_model = 4096\n",
    "    else:\n",
    "        d_model = 512\n",
    "\n",
    "    effect_per_layer = []\n",
    "    for i in layers:\n",
    "\n",
    "        intervention_layers = [i]\n",
    "        selected_features = {}\n",
    "\n",
    "        if ablation_method == \"zero\" or ablation_method == \"mean\" or ablation_method == \"max\":\n",
    "            for layer in intervention_layers:\n",
    "                selected_features[layer] = torch.ones(d_model, dtype=torch.bool)\n",
    "        elif ablation_method == \"dt\":\n",
    "            for layer in intervention_layers:\n",
    "\n",
    "                all_f1s = decision_trees[layer][custom_function.__name__][\"decision_tree\"][\"r2\"]\n",
    "                good_f1s = all_f1s > threshold\n",
    "                selected_features[layer] = good_f1s\n",
    "                print(good_f1s.shape, good_f1s.dtype, good_f1s.sum())\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid ablation method: {ablation_method}\")\n",
    "\n",
    "        logits_clean_BLV, logits_patch_BLV = interventions(\n",
    "            model=model,\n",
    "            model_name=model_name,\n",
    "            train_data=data,\n",
    "            selected_features=selected_features,\n",
    "            decision_trees=decision_trees,\n",
    "            ae_dict=ae_dict,\n",
    "            submodule_dict=submodule_dict,\n",
    "            custom_function=custom_function,\n",
    "            layers=intervention_layers,\n",
    "            ablation_method=ablation_method,\n",
    "            ablate_not_selected=ablate_not_selected,\n",
    "            add_error=add_error,\n",
    "            input_location=input_location,\n",
    "        )\n",
    "\n",
    "        kl_div_BL = compute_kl_divergence(logits_clean_BLV, logits_patch_BLV)\n",
    "        print(kl_div_BL.mean())\n",
    "        effect_per_layer.append(kl_div_BL.mean().cpu())\n",
    "        # print(compute_kl_divergence(logits_clean_BLV, logits_patch_BLV))\n",
    "\n",
    "    ablations[\"ablations\"] = effect_per_layer\n",
    "    ablations[\"hyperparameters\"] = {\n",
    "        \"input_location\": input_location,\n",
    "        \"ablation_method\": ablation_method,\n",
    "        \"ablate_not_selected\": ablate_not_selected,\n",
    "        \"add_error\": add_error,\n",
    "        \"threshold\": threshold,\n",
    "    }\n",
    "\n",
    "    return ablations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "importlib.reload(othello_utils)\n",
    "\n",
    "import itertools\n",
    "\n",
    "repo_dir = \"/home/adam/OthelloUnderstanding\"\n",
    "model_name = \"Baidicoot/Othello-GPT-Transformer-Lens\"\n",
    "batch_size = 10\n",
    "n_batches = 10\n",
    "dataset_size = batch_size * n_batches\n",
    "layers = list(range(8))\n",
    "threshold = 0.7\n",
    "max_depth = 8\n",
    "\n",
    "\n",
    "add_output_folders()\n",
    "\n",
    "custom_functions = [\n",
    "    othello_utils.games_batch_to_input_tokens_flipped_bs_valid_moves_classifier_input_BLC,\n",
    "    # othello_utils.games_batch_to_input_tokens_classifier_input_BLC,\n",
    "    # othello_utils.games_batch_to_board_state_and_input_tokens_classifier_input_BLC,\n",
    "    # othello_utils.games_batch_to_input_tokens_flipped_classifier_input_BLC,\n",
    "    # othello_utils.games_batch_to_board_state_classifier_input_BLC,\n",
    "    # othello_utils.games_batch_to_input_tokens_parity_classifier_input_BLC,\n",
    "]\n",
    "\n",
    "true_false_combinations = list(itertools.product([True, False], repeat=2))\n",
    "\n",
    "combinations = [\n",
    "    (\"mlp_neuron\", \"zero\", False, False),\n",
    "    (\"sae_mlp_out_feature\", \"zero\", False, False),\n",
    "    (\"transcoder\", \"zero\", False, False),\n",
    "    (\"mlp_neuron\", \"dt\", False, True),\n",
    "    (\"mlp_neuron\", \"dt\", True, True),\n",
    "]\n",
    "\n",
    "for combo in true_false_combinations:\n",
    "    transcoder_combo = (\"transcoder\", \"dt\", combo[0], combo[1])\n",
    "    sae_mlp_out_combo = (\"sae_mlp_out_feature\", \"dt\", combo[0], combo[1])\n",
    "\n",
    "    if transcoder_combo not in combinations:\n",
    "        combinations.append(transcoder_combo)\n",
    "    if sae_mlp_out_combo not in combinations:\n",
    "        combinations.append(sae_mlp_out_combo)\n",
    "\n",
    "model, train_data = load_model_and_data(model_name, dataset_size, custom_functions)\n",
    "test_data = construct_othello_dataset(\n",
    "    custom_functions=custom_functions,\n",
    "    n_inputs=dataset_size,\n",
    "    split=\"train\",\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "for combination in combinations:\n",
    "\n",
    "    input_location, ablation_method, ablate_not_selected, add_error = combination\n",
    "\n",
    "    neuron_acts = cache_sae_activations(\n",
    "        model, model_name, train_data, layers, batch_size, n_batches, repo_dir, input_location\n",
    "    )\n",
    "\n",
    "    binary_acts = calculate_binary_activations(neuron_acts)\n",
    "\n",
    "    neuron_acts = utils.to_device(neuron_acts, \"cpu\")\n",
    "    binary_acts = utils.to_device(binary_acts, \"cpu\")\n",
    "\n",
    "    ae_dict = utils.get_aes(node_type=input_location, repo_dir=repo_dir)\n",
    "    submodule_dict = get_submodule_dict(model, model_name, layers, input_location)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    decision_trees = compute_predictors(\n",
    "        custom_functions=custom_functions,\n",
    "        num_cores=8,\n",
    "        layers=layers,\n",
    "        data=train_data,\n",
    "        neuron_acts=neuron_acts,\n",
    "        binary_acts=binary_acts,\n",
    "        input_location=input_location,\n",
    "        dataset_size=dataset_size,\n",
    "        force_recompute=False,\n",
    "        save_results=True,\n",
    "        max_depth=max_depth,\n",
    "    )\n",
    "\n",
    "    for layer in decision_trees:\n",
    "        results[layer] = {}\n",
    "        for custom_function in custom_functions:\n",
    "            results[layer][custom_function.__name__] = {\n",
    "                \"decision_tree\": {\n",
    "                    \"mse\": decision_trees[layer][custom_function.__name__][\"decision_tree\"][\"mse\"],\n",
    "                    \"r2\": decision_trees[layer][custom_function.__name__][\"decision_tree\"][\"r2\"],\n",
    "                },\n",
    "                \"binary_decision_tree\": {\n",
    "                    \"f1\": decision_trees[layer][custom_function.__name__][\"binary_decision_tree\"][\n",
    "                        \"f1\"\n",
    "                    ],\n",
    "                    \"accuracy\": decision_trees[layer][custom_function.__name__][\n",
    "                        \"binary_decision_tree\"\n",
    "                    ][\"accuracy\"],\n",
    "                },\n",
    "            }\n",
    "\n",
    "    ablation_custom_function = custom_functions[0]\n",
    "\n",
    "    ablations = perform_interventions(\n",
    "        decision_trees=decision_trees,\n",
    "        input_location=input_location,\n",
    "        ablation_method=ablation_method,\n",
    "        ablate_not_selected=ablate_not_selected,\n",
    "        add_error=add_error,\n",
    "        custom_function=ablation_custom_function,\n",
    "        repo_dir=repo_dir,\n",
    "        model=model,\n",
    "        model_name=model_name,\n",
    "        layers=layers,\n",
    "        data=test_data,\n",
    "        threshold=threshold,\n",
    "    )\n",
    "\n",
    "    with open(f\"decision_trees/results_{input_location}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(results, f)\n",
    "\n",
    "    with open(\n",
    "        f\"decision_trees/ablation_results_{input_location}_{ablation_method}_ablate_not_selected_{ablate_not_selected}_add_error_{add_error}.pkl\",\n",
    "        \"wb\",\n",
    "    ) as f:\n",
    "        pickle.dump(ablations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "ablations = {}\n",
    "for filename in os.listdir(\"decision_trees\"):\n",
    "    if filename.startswith(\"results_\"):\n",
    "        with open(f\"decision_trees/{filename}\", \"rb\") as f:\n",
    "            result = pickle.load(f)\n",
    "            result = utils.to_device(result, \"cpu\")\n",
    "\n",
    "        key = filename.split(\".pkl\")[0].split(\"results_\")[1]\n",
    "        results[key] = result\n",
    "\n",
    "    if filename.startswith(\"ablation_results_\"):\n",
    "        with open(f\"decision_trees/{filename}\", \"rb\") as f:\n",
    "            ablation = pickle.load(f)\n",
    "            ablation = utils.to_device(ablation, \"cpu\")\n",
    "\n",
    "        key = filename.split(\".pkl\")[0].split(\"ablation_results_\")[1]\n",
    "        ablations[key] = ablation\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in layers:\n",
    "#     max_activations_D = get_max_activations(neuron_acts, layer)\n",
    "#     plt.hist(max_activations_D.cpu().numpy(), bins=50)\n",
    "#     plt.xlim(0, 15)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(ablations)\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for label in ablations.keys():\n",
    "    # if \"zero_ablate_not_selected_False\" not in label and \"ablate_not_selected_True\" not in label:\n",
    "    #     continue\n",
    "\n",
    "    if \"ablate_not_selected_False\" in label and \"zero\" not in label:\n",
    "        continue\n",
    "\n",
    "    print(label, ablations[label])\n",
    "\n",
    "    # if \"zero\" not in label:\n",
    "    #     continue\n",
    "    effect_per_layer = ablations[label][\"ablations\"]\n",
    "    for i in range(len(effect_per_layer)):\n",
    "        effect_per_layer[i] = effect_per_layer[i]\n",
    "    plt.plot(range(8), effect_per_layer, label=label)\n",
    "\n",
    "plt.xlabel('Layer')\n",
    "plt.ylabel('Effect (KL Divergence)')\n",
    "plt.title('Effect per Layer for Activating All Neurons with Decision Trees at Different Locations')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.yscale('log')\n",
    "\n",
    "# plt.show()\n",
    "plt.savefig(\"images/kl_divergence.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to view metrics for a specific layer\n",
    "def view_layer_metrics(\n",
    "    layer: int,\n",
    "    threshold: float,\n",
    "    data: dict,\n",
    "    custom_function_name: str,\n",
    "    neuron_acts: dict,\n",
    "    results: dict,\n",
    "    linear_reg: bool = False,\n",
    "    verbose: bool = True,\n",
    "):\n",
    "    if layer not in results:\n",
    "        print(f\"Layer {layer} not found in results.\")\n",
    "        return\n",
    "\n",
    "    # print(f\"  MSE: {results[layer][custom_function_name]['decision_tree']['mse']}\")\n",
    "    # print(f\"  R2: {results[layer][custom_function_name]['decision_tree']['r2']}\")\n",
    "\n",
    "    dt_mse = results[layer][custom_function_name][\"decision_tree\"][\"mse\"]\n",
    "    dt_r2 = results[layer][custom_function_name][\"decision_tree\"][\"r2\"]\n",
    "\n",
    "    # print(\"\\nNeuron-specific metrics:\")\n",
    "    # print(f\"Decision Tree - Mean MSE: {np.mean(dt_mse)}, Mean R2: {np.mean(dt_r2)}\")\n",
    "\n",
    "    dt_r2_tensor = torch.tensor(dt_r2)\n",
    "\n",
    "    good_dt_r2 = (dt_r2_tensor > threshold).sum().item()\n",
    "\n",
    "    f1 = results[layer][custom_function_name][\"binary_decision_tree\"][\"f1\"]\n",
    "    # print(f\"  Accuracy: {np.mean(accuracy)}\")\n",
    "    # print(f\"  Precision: {np.mean(precision)}\")\n",
    "    # print(f\"  Recall: {np.mean(recall)}\")\n",
    "    # print(f\"  F1: {np.mean(f1)}\")\n",
    "\n",
    "    good_f1 = (torch.tensor(f1) > threshold).sum().item()\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\n\\nMetrics for Layer {layer}:\")\n",
    "        print(\"Decision Tree:\")\n",
    "\n",
    "        print(f\"Number of neurons with R2 > {threshold} (Decision Tree): {good_dt_r2}\")\n",
    "\n",
    "        print(\"\\nBinary Decision Tree Metrics:\")\n",
    "        print(f\"Number of neurons with F1 > {threshold} {good_f1}\")\n",
    "\n",
    "    return good_f1\n",
    "\n",
    "\n",
    "accuracy_by_layer = {}\n",
    "thresholds = [0.7, 0.8, 0.9]\n",
    "\n",
    "\n",
    "for i, location in enumerate(results):\n",
    "    for custom_function in custom_functions:\n",
    "        print(f\"\\n\\n{custom_function.__name__}\\n\")\n",
    "        accuracy_by_layer[location] = {custom_function.__name__: {}}\n",
    "        for threshold in thresholds:\n",
    "            print(f\"\\nThreshold: {threshold}\")\n",
    "            accuracy_by_layer[location][custom_function.__name__][threshold] = []\n",
    "            for layer in layers:\n",
    "                f1_count = view_layer_metrics(\n",
    "                    layer,\n",
    "                    threshold,\n",
    "                    train_data,\n",
    "                    custom_function.__name__,\n",
    "                    neuron_acts,\n",
    "                    results[location],\n",
    "                    verbose=False,\n",
    "                )\n",
    "                accuracy_by_layer[location][custom_function.__name__][threshold].append(f1_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "function_labels = {\n",
    "    othello_utils.games_batch_to_input_tokens_classifier_input_BLC: \"Input Tokens\",\n",
    "    othello_utils.games_batch_to_input_tokens_parity_classifier_input_BLC: \"Input Tokens and Parity\",\n",
    "    othello_utils.games_batch_to_input_tokens_flipped_classifier_input_BLC: \"Input Tokens and Flipped\",\n",
    "    othello_utils.games_batch_to_board_state_and_input_tokens_classifier_input_BLC: \"Board State and Input Tokens\",\n",
    "    othello_utils.games_batch_to_board_state_classifier_input_BLC: \"Board State\",\n",
    "    othello_utils.games_batch_to_input_tokens_flipped_bs_classifier_input_BLC: \"Input Tokens and Flipped with Board\",\n",
    "}\n",
    "\n",
    "custom_function = custom_functions[0]\n",
    "function_name = custom_function.__name__\n",
    "threshold = 0.7\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "for location in accuracy_by_layer:\n",
    "    f1_counts = accuracy_by_layer[location][function_name][threshold]\n",
    "\n",
    "    plt.plot(layers, f1_counts, label=f\"location: {location}\", linewidth=2, markersize=8)\n",
    "\n",
    "    # Optionally, add value labels on each point\n",
    "    for j, count in enumerate(f1_counts):\n",
    "        plt.annotate(\n",
    "            str(count),\n",
    "            (layers[j], count),\n",
    "            textcoords=\"offset points\",\n",
    "            xytext=(0, 5),\n",
    "            ha=\"center\",\n",
    "            fontsize=8,\n",
    "        )\n",
    "\n",
    "plt.title(\n",
    "    f\"Number of Neurons with F1 > Threshold for \\n{function_labels[custom_function]} by Layer \\n{dataset_size} datapoints Input location: {input_location} depth: {max_depth}\",\n",
    "    fontsize=14,\n",
    ")\n",
    "plt.xlabel(\"Layer Number\", fontsize=12)\n",
    "plt.ylabel(\"F1 Count\", fontsize=12)\n",
    "plt.legend(loc=\"best\", fontsize=10)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "output_filename = f\"images/{input_location}_{function_name}_inputs_{dataset_size}_depth_{max_depth}_f1_count_by_layer_all_thresholds.png\"\n",
    "plt.savefig(output_filename, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"All graphs have been created and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors = ['b', 'g', 'r']  # Colors for different thresholds\n",
    "markers = ['o', 's', '^']  # Markers for different thresholds\n",
    "\n",
    "for custom_function in custom_functions:\n",
    "    function_name = custom_function.__name__\n",
    "    \n",
    "    plt.figure(figsize=(12, 7))\n",
    "    \n",
    "    for i, threshold in enumerate(thresholds):\n",
    "        f1_counts = accuracy_by_layer[function_name][threshold]\n",
    "        \n",
    "        plt.plot(layers, f1_counts, color=colors[i], marker=markers[i], \n",
    "                 label=f'Threshold: {threshold}', linewidth=2, markersize=8)\n",
    "        \n",
    "        # Optionally, add value labels on each point\n",
    "        for j, count in enumerate(f1_counts):\n",
    "            plt.annotate(str(count), (layers[j], count), \n",
    "                         textcoords=\"offset points\", xytext=(0,5), ha='center', \n",
    "                         fontsize=8, color=colors[i])\n",
    "    \n",
    "    plt.title(f'Number of Neurons with F1 > Threshold for \\n{function_labels[custom_function]} by Layer \\n{dataset_size} datapoints Input location: {input_location} depth: {max_depth}', fontsize=14)\n",
    "    plt.xlabel('Layer Number', fontsize=12)\n",
    "    plt.ylabel('F1 Count', fontsize=12)\n",
    "    plt.legend(loc='best', fontsize=10)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    output_filename = f\"images/{input_location}_{function_name}_inputs_{dataset_size}_depth_{max_depth}_f1_count_by_layer_all_thresholds.png\"\n",
    "    plt.savefig(output_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(\"All graphs have been created and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 1\n",
    "neuron_idx = 421\n",
    "custom_function_name = custom_functions[0].__name__\n",
    "\n",
    "decision_tree_filename = f\"decision_trees/decision_trees_{input_location}_{dataset_size}.pkl\"\n",
    "\n",
    "with open(decision_tree_filename, \"rb\") as f:\n",
    "    decision_tree = pickle.load(f)\n",
    "\n",
    "layer_dt = decision_tree[layer][custom_function_name]['decision_tree']['model']\n",
    "layer_dt = decision_tree[layer][custom_function_name]['binary_decision_tree']['model']\n",
    "\n",
    "games_BLC = train_data[custom_function_name]\n",
    "\n",
    "feature_names = []\n",
    "\n",
    "X_binary_train, X_binary_test, y_binary_train, y_binary_test = prepare_data(\n",
    "    games_BLC, binary_acts[layer]\n",
    ")\n",
    "accuracy, precision, recall, f1 = calculate_binary_metrics(\n",
    "    decision_tree[layer][custom_function_name][\"binary_decision_tree\"][\"model\"], X_binary_test, y_binary_test\n",
    ")\n",
    "\n",
    "print(f\"Neuron 421 F1: {f1[neuron_idx]}\")\n",
    "\n",
    "for i in range(games_BLC.shape[2]):\n",
    "    if i < 64:\n",
    "        square = idx_to_square_notation(i)\n",
    "        feature_names.append(f\"Input_{square}\")\n",
    "    elif i < 128:\n",
    "        j = i - 64\n",
    "        square = idx_to_square_notation(j)\n",
    "        feature_names.append(f\"Occupied_{square}\")\n",
    "    else:\n",
    "        feature_names.append(f\"Output_{i}\")\n",
    "\n",
    "print_decision_tree_rules(layer_dt, feature_names=feature_names, neuron_index=neuron_idx, max_depth=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "othello",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
