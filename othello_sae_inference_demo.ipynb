{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect SAE activations Othello GPT \n",
    "\n",
    "Rico Angell trained a bunch of SAEs on OthelloGPT layer 5 resid post. Use this notebook to retrieve SAE feature activations.\n",
    "\n",
    "Running this notebook requires cloning **THE COLLAB BRANCH** of Sam Marks' dictionary learning repo: https://github.com/saprmarks/dictionary_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "from datasets import load_dataset\n",
    "from transformer_lens import HookedTransformer\n",
    "from nnsight import NNsight\n",
    "\n",
    "import sys\n",
    "sys.path.append('your-path-to-dictionary-learning-repo')\n",
    "from dictionary_learning.buffer import NNsightActivationBuffer\n",
    "from dictionary_learning.dictionary import AutoEncoder, AutoEncoderNew, GatedAutoEncoder\n",
    "\n",
    "repo_dir = 'your-path-to-own-experiments-repo'\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data from huggingface if needed\n",
    "if not os.path.exists(f'{repo_dir}/autoencoders/group-2024-05-17_othello'):\n",
    "    hf_hub_download(repo_id='adamkarvonen/othello_saes', filename='group-2024-05-17_othello.zip', local_dir=f'{repo_dir}/autoencoders')\n",
    "    # unzip the data\n",
    "    os.system(f'unzip {repo_dir}/autoencoders/group-2024-05-17_othello.zip -d autoencoders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load SAE\n",
    "ae_type = 'standard_new'\n",
    "trainer_id = 0\n",
    "\n",
    "ae_path = f'{repo_dir}/autoencoders/group-2024-05-17_othello/group-2024-05-17_othello-{ae_type}/trainer{trainer_id}'\n",
    "if ae_type == 'standard':\n",
    "    ae = AutoEncoder.from_pretrained(os.path.join(ae_path, 'ae.pt'), device='cuda:0')\n",
    "elif ae_type == 'gated':\n",
    "    ae = GatedAutoEncoder.from_pretrained(os.path.join(ae_path, 'ae.pt'), device='cuda:0')\n",
    "elif ae_type == 'standard_new':\n",
    "    ae = AutoEncoderNew.from_pretrained(os.path.join(ae_path, 'ae.pt'), device='cuda:0')\n",
    "else:\n",
    "    raise ValueError('Invalid ae_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def othello_hf_dataset_to_generator(\n",
    "    dataset_name: str, context_length: int = 59, split=\"train\", streaming=True\n",
    "):\n",
    "    dataset = load_dataset(dataset_name, split=split, streaming=streaming)\n",
    "\n",
    "    def gen():\n",
    "        for x in iter(dataset):\n",
    "            yield x[\"tokens\"][:context_length]\n",
    "\n",
    "    return gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model_name = \"Baidicoot/Othello-GPT-Transformer-Lens\"\n",
    "layer = 5\n",
    "\n",
    "tf_model = HookedTransformer.from_pretrained(\"Baidicoot/Othello-GPT-Transformer-Lens\")\n",
    "model = NNsight(tf_model).to(device)\n",
    "submodule =  model.blocks[layer].hook_resid_post\n",
    "\n",
    "# load data\n",
    "context_length = 59\n",
    "activation_dim = 512  # output dimension of the layer\n",
    "dataset_name = \"taufeeque/othellogpt\"\n",
    "data = othello_hf_dataset_to_generator(\n",
    "    dataset_name, context_length=context_length, split=\"train\", streaming=True\n",
    ")\n",
    "buffer = NNsightActivationBuffer(\n",
    "    data,\n",
    "    model,\n",
    "    submodule,\n",
    "    n_ctxs=8e3,\n",
    "    ctx_len=context_length,\n",
    "    refresh_batch_size=128,\n",
    "    io=\"out\",\n",
    "    d_submodule=activation_dim,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts = next(buffer)\n",
    "ae.encode(acts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
