{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize othello board with highlighted background\n",
    "\n",
    "Input to the model: \"int\", doesn't contain middle pieces\n",
    "For plotting and correct conversion to board visualization: \"string\", does mind middle pieces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from IPython.display import HTML\n",
    "\n",
    "import torch as t\n",
    "import matplotlib.pyplot as plt\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from circuits.dictionary_learning.buffer import NNsightActivationBuffer\n",
    "from circuits.dictionary_learning.dictionary import AutoEncoder, AutoEncoderNew, GatedAutoEncoder\n",
    "import circuits.othello_utils as othello_utils\n",
    "from circuits.utils import (\n",
    "    othello_hf_dataset_to_generator,\n",
    "    get_model,\n",
    "    get_submodule,\n",
    ")\n",
    "\n",
    "repo_dir = '/home/can/chess-gpt-circuits'\n",
    "# repo_dir = \"/home/adam/chess-gpt-circuits/\"\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data from huggingface if needed\n",
    "if not os.path.exists(f'{repo_dir}/autoencoders/othello_5-21'):\n",
    "    hf_hub_download(repo_id='adamkarvonen/othello_saes', filename='othello_5-21.zip', local_dir=f'{repo_dir}/autoencoders')\n",
    "    # unzip the data\n",
    "    os.system(f'unzip {repo_dir}/autoencoders/othello_5-21.zip -d autoencoders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load SAE\n",
    "ae_type = 'standard'\n",
    "trainer_id = 4\n",
    "\n",
    "ae_path = f'{repo_dir}/autoencoders/othello_5-21/othello-{ae_type}/trainer{trainer_id}'\n",
    "if ae_type == 'standard':\n",
    "    ae = AutoEncoder.from_pretrained(os.path.join(ae_path, 'ae.pt'), device='cuda:0')\n",
    "elif ae_type == 'gated':\n",
    "    ae = GatedAutoEncoder.from_pretrained(os.path.join(ae_path, 'ae.pt'), device='cuda:0')\n",
    "elif ae_type == 'standard_new':\n",
    "    ae = AutoEncoderNew.from_pretrained(os.path.join(ae_path, 'ae.pt'), device='cuda:0')\n",
    "else:\n",
    "    raise ValueError('Invalid ae_type')\n",
    "\n",
    "with open (os.path.join(ae_path, 'indexing_None_n_inputs_1000_feature_labels.pkl'), 'rb') as f:\n",
    "    lookup_table = pickle.load(f)\n",
    "\n",
    "print(lookup_table.keys())\n",
    "\n",
    "with open (os.path.join(ae_path, 'n_inputs_1000_evals.pkl'), 'rb') as f:\n",
    "    eval_results = pickle.load(f)\n",
    "\n",
    "print(eval_results.keys())\n",
    "print(f\"L0: {eval_results['eval_results']['l0']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load information about features\n",
    "\n",
    "def to_device(d, device=device):\n",
    "    if isinstance(d, t.Tensor):\n",
    "        return d.to(device)\n",
    "    if isinstance(d, dict):\n",
    "        return {k: to_device(v, device) for k, v in d.items()}\n",
    "    \n",
    "ae = ae.to(device)\n",
    "with open(os.path.join(ae_path, 'indexing_None_n_inputs_1000_feature_labels.pkl'), 'rb') as f:\n",
    "    feature_labels = pickle.load(f)\n",
    "feature_labels = to_device(feature_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and data\n",
    "\n",
    "layer = 5\n",
    "context_length = 59\n",
    "activation_dim = 512  # output dimension of the layer\n",
    "model_name = \"Baidicoot/Othello-GPT-Transformer-Lens\"\n",
    "dataset_name = \"taufeeque/othellogpt\"\n",
    "\n",
    "model = get_model(model_name, device)\n",
    "submodule = get_submodule(model_name, layer, model)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "data = othello_hf_dataset_to_generator(\n",
    "    dataset_name, context_length=context_length, split=\"train\", streaming=True\n",
    ")\n",
    "buffer = NNsightActivationBuffer(\n",
    "    data,\n",
    "    model,\n",
    "    submodule,\n",
    "    n_ctxs=8e3,\n",
    "    ctx_len=context_length,\n",
    "    refresh_batch_size=128,\n",
    "    io=\"out\",\n",
    "    d_submodule=activation_dim,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_othello_dataset_sample_to_board(sample_i, move_idx=None):\n",
    "    if type(sample_i) == t.Tensor:\n",
    "        sample_i = sample_i.tolist()\n",
    "    context = [othello_utils.itos[s] for s in sample_i]\n",
    "    if move_idx is not None:\n",
    "        context = context[:move_idx+1]\n",
    "    board_state_RR = othello_utils.games_batch_to_state_stack_mine_yours_BLRRC([context])[0][-1]\n",
    "    board_state_RR = t.argmax(board_state_RR, dim=-1) - 1\n",
    "    return board_state_RR\n",
    "\n",
    "game_idx = 0\n",
    "move_idx = 20\n",
    "sample_game = buffer.text_batch()[game_idx] # in \"model input format\"\n",
    "sample_board = convert_othello_dataset_sample_to_board(sample_game, move_idx=move_idx)\n",
    "# sample_board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_othello_board_highlighted(true_board_RR, bg_board_RR=None, title=''):\n",
    "    \"\"\"\n",
    "    Plots a comparison of the true and reconstructed Othello boards using matplotlib.\n",
    "\n",
    "    Args:\n",
    "    true_board (torch.Tensor): A 2D tensor representing the true Othello board.\n",
    "    recon_board (torch.Tensor): A 2D tensor representing the reconstructed Othello board.\n",
    "    \"\"\"\n",
    "\n",
    "    true_color_map = {-1: 'black', 0: 'white', 1: 'cornsilk'}\n",
    "    if bg_board_RR is None:\n",
    "        bg_board_RR = t.zeros_like(true_board_RR)\n",
    "        cmap = plt.matplotlib.colors.ListedColormap(['white'])\n",
    "        print_color_bar = False\n",
    "        vmin = 0\n",
    "        vmax = 0\n",
    "    else:\n",
    "        bg_max_abs = t.abs(bg_board_RR).max().item()\n",
    "        if bg_board_RR.min() < 0:\n",
    "            cmap = \"RdBu\"\n",
    "            vmin = -bg_max_abs\n",
    "            vmax = bg_max_abs\n",
    "        else:\n",
    "            cmap = \"Blues\"\n",
    "            vmin = 0\n",
    "            vmax = bg_board_RR.max().item()\n",
    "        print_color_bar = True\n",
    "\n",
    "    # Create a figure and axis for the plot\n",
    "    fig, ax = plt.subplots(figsize=(4,4))\n",
    "    plt.imshow(bg_board_RR, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    # add circles on each square with black borders\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            plt.gca().add_patch(plt.Rectangle((j-0.5, i-0.5), 1, 1, fill=False, edgecolor='black', lw=0.5))\n",
    "            if true_board_RR[i, j].item() == 0:\n",
    "                continue\n",
    "            circle = plt.Circle((j, i), 0.3, color=true_color_map[true_board_RR[i, j].item()], fill=True)\n",
    "            circle_edges = plt.Circle((j, i), 0.3, color='black', fill=False)\n",
    "            plt.gca().add_artist(circle)\n",
    "            plt.gca().add_artist(circle_edges)\n",
    "    plt.xticks(range(8), ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'])\n",
    "    plt.title(title)\n",
    "    if print_color_bar:\n",
    "        # align colorbar to zero\n",
    "        norm = plt.Normalize(vmin=vmin, vmax=vmax)\n",
    "        plt.colorbar(plt.cm.ScalarMappable(cmap=cmap, norm=norm), ax=ax)\n",
    "\n",
    "    # plt.savefig('othello_board_highlighted.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Test visualization\n",
    "# random_bg = t.arange(-10,54).reshape(8,8)\n",
    "# plot_othello_board_highlighted(sample_board, random_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_game_seq(context_i, bg_values, true_board_RR, max_act, prefix=''):\n",
    "    context_s = [othello_utils.itos[s] for s in context_i]\n",
    "    bg_board_RR = t.zeros((8, 8))\n",
    "    for act, token in zip(bg_values, context_s):\n",
    "        bg_board_RR[token // 8, token % 8] = act\n",
    "    plot_othello_board_highlighted(true_board_RR, bg_board_RR=bg_board_RR, max_bg=max_act, title=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for visualizing highlighted token sequences\n",
    "def shade(value, max_value):\n",
    "    if abs(value) > max_value:\n",
    "        raise ValueError(\"Absolute value must be less than or equal to max_value.\")\n",
    "    \n",
    "    if max_value == 0:\n",
    "        return \"#ffffff\"\n",
    "    \n",
    "    normalized_value = value / max_value\n",
    "    \n",
    "    if normalized_value < 0:\n",
    "        # Red shade for negative values\n",
    "        red = 255\n",
    "        green = int(255 * (1 + normalized_value))\n",
    "        blue = int(255 * (1 + normalized_value))\n",
    "    else:\n",
    "        # Blue shade for positive values\n",
    "        red = int(255 * (1 - normalized_value))\n",
    "        green = int(255 * (1 - normalized_value))\n",
    "        blue = 255\n",
    "    \n",
    "    # White color for zero value\n",
    "    if value == 0:\n",
    "        red = green = blue = 255\n",
    "    \n",
    "    # Convert RGB values to hex color code\n",
    "    hex_color = \"#{:02x}{:02x}{:02x}\".format(red, green, blue)\n",
    "    \n",
    "    return hex_color\n",
    "\n",
    "def visualize_game_seq(context_i, activations, max_value, prefix=''):\n",
    "    context_s = [othello_utils.itos[s] for s in context_i]\n",
    "    labeled_seq = list(map(othello_utils.to_board_label, context_s))\n",
    "    html_elements = []\n",
    "    for token, act in zip(labeled_seq, activations):\n",
    "        hex_color = shade(act, max_value)\n",
    "        s = token\n",
    "        s = s.replace(' ', '&nbsp;')\n",
    "        html_element = f'<span style=\"background-color: {hex_color}; color: black\">{s}</span>'\n",
    "        html_elements.append(html_element)\n",
    "    \n",
    "    combined_html = ' '.join(html_elements)\n",
    "    combined_html = prefix + combined_html\n",
    "    return HTML(combined_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(model, ae, buffer, feat_idx, k=10):\n",
    "    labeled_seq = buffer.token_batch()\n",
    "    with model.trace(labeled_seq, scan=False, validate=False): # use_cache=False,  output_attentions=False\n",
    "        embeds = model.hook_embed.output.save()\n",
    "        embeds.retain_grad()\n",
    "        x = submodule.output\n",
    "        f = ae.encode(x).save()\n",
    "    mean_embed = embeds.value.mean(dim=(0,1))\n",
    "    f = f.value[...,feat_idx]\n",
    "\n",
    "    # get indices of top k exemplars\n",
    "\n",
    "    def unravel_index(indices, shape):\n",
    "        out = []\n",
    "        for dim in reversed(shape):\n",
    "            out.append(indices % dim)\n",
    "            indices = indices // dim\n",
    "        return tuple(reversed(out))\n",
    "\n",
    "    flattened_f = f.flatten()\n",
    "    top_values, top_indices_flattened = t.topk(flattened_f, k)\n",
    "    top_indices = unravel_index(top_indices_flattened, f.shape)\n",
    "    top_values.sum().backward()\n",
    "\n",
    "    # compile top contexts and activations\n",
    "    contexts, activations, attributions = [], [], []\n",
    "    for i in range(k):\n",
    "        context_idx, token_idx = top_indices[0][i].item(), top_indices[1][i].item()\n",
    "        contexts.append(labeled_seq[context_idx, :token_idx+1].tolist())\n",
    "        activations.append(f[context_idx, :token_idx+1].tolist())\n",
    "        attributions.append(\n",
    "            (embeds.value.grad * (embeds.value - mean_embed)).sum(dim=-1)[context_idx, :token_idx+1].tolist()\n",
    "        )\n",
    "    max_value = max([abs(x) for act in activations for x in act] + [abs(x) for att in attributions for x in att])\n",
    "\n",
    "    for cnt, (context_i, activation, attribution) in enumerate(zip(contexts, activations, attributions)):\n",
    "        print(\"=\"*80)\n",
    "        print(f'Top {cnt+1} example:')\n",
    "        board_state_RR = convert_othello_dataset_sample_to_board(context_i)\n",
    "        display(visualize_game_seq(context_i, activation, max_value, prefix='feature activations: '))\n",
    "        plot_game_seq(context_i, activation, board_state_RR, prefix='activations on board: ')\n",
    "        display(visualize_game_seq(context_i, attribution, max_value, prefix='embedding attributions:'))\n",
    "        plot_game_seq(context_i, attribution, board_state_RR, prefix='mean attribution patching effects on embed tokens: ')\n",
    "\n",
    "    return contexts[0], activations[0], attributions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.W_E.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logit lens and token_embed visualization\n",
    "\n",
    "def cossim_logit_feature_decoder(model, ae, feat_idx):\n",
    "    feat_decoder_vec = ae.decoder.weight[:, feat_idx]\n",
    "    cossim = t.cosine_similarity(feat_decoder_vec, model.W_U[:, 1:].T, dim=1) # NOTE 0 is a special token?\n",
    "    return cossim\n",
    "\n",
    "def cossim_tokenembed_feature_decoder(model, ae, feat_idx):\n",
    "    feat_decoder_vec = ae.decoder.weight[:, feat_idx]\n",
    "    cossim = t.cosine_similarity(feat_decoder_vec, model.W_E[1:, :], dim=1)\n",
    "    return cossim\n",
    "\n",
    "def visualize_lens(ax, model, ae, feat_idx, cossim_func, title=''):\n",
    "    cossim = cossim_func(model, ae, feat_idx)\n",
    "    ll_board = t.zeros(64, device=device)\n",
    "    print(cossim.shape)\n",
    "    ll_board[othello_utils.stoi_indices] = cossim\n",
    "    ll_board = ll_board.view(8, 8)\n",
    "\n",
    "    cmap = \"RdBu\"\n",
    "    vmin = -cossim.abs().max().item()\n",
    "    vmax = cossim.abs().max().item()\n",
    "    norm = plt.Normalize(vmin=vmin, vmax=vmax)\n",
    "    ax.imshow(ll_board.cpu().detach().numpy(), cmap=cmap, norm=norm)\n",
    "    plt.colorbar(plt.cm.ScalarMappable(cmap=cmap, norm=norm), ax=ax)\n",
    "    ax.set_xticks(range(8))\n",
    "    ax.set_xticklabels(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'])\n",
    "    ax.set_title(f'{title} #feat {feat_idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_game_seq(ax, context_i, bg_values, true_board_RR, prefix=''):\n",
    "    context_s = [othello_utils.itos[s] for s in context_i]\n",
    "    bg_board_RR = t.zeros((8, 8))\n",
    "    for act, token in zip(bg_values, context_s):\n",
    "        bg_board_RR[token // 8, token % 8] = act\n",
    "    plot_othello_board_highlighted(ax, true_board_RR, bg_board_RR=bg_board_RR, title=prefix)\n",
    "\n",
    "def plot_othello_board_highlighted(ax, true_board_RR, bg_board_RR=None, title=''):\n",
    "    true_color_map = {-1: 'black', 0: 'white', 1: 'cornsilk'}\n",
    "    if bg_board_RR is None:\n",
    "        bg_board_RR = t.zeros_like(true_board_RR)\n",
    "        cmap = plt.matplotlib.colors.ListedColormap(['white'])\n",
    "        print_color_bar = False\n",
    "        vmin = 0\n",
    "        vmax = 0\n",
    "    else:\n",
    "        bg_max_abs = t.abs(bg_board_RR).max().item()\n",
    "        if bg_board_RR.min() < 0:\n",
    "            cmap = \"RdBu\"\n",
    "            vmin = -bg_max_abs\n",
    "            vmax = bg_max_abs\n",
    "        else:\n",
    "            cmap = \"Blues\"\n",
    "            vmin = 0\n",
    "            vmax = bg_board_RR.max().item()\n",
    "        print_color_bar = True\n",
    "\n",
    "    ax.imshow(bg_board_RR, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            ax.add_patch(plt.Rectangle((j-0.5, i-0.5), 1, 1, fill=False, edgecolor='black', lw=0.5))\n",
    "            if true_board_RR[i, j].item() == 0:\n",
    "                continue\n",
    "            circle = plt.Circle((j, i), 0.3, color=true_color_map[true_board_RR[i, j].item()], fill=True)\n",
    "            circle_edges = plt.Circle((j, i), 0.3, color='black', fill=False)\n",
    "            ax.add_artist(circle)\n",
    "            ax.add_artist(circle_edges)\n",
    "    ax.set_xticks(range(8))\n",
    "    ax.set_xticklabels(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'])\n",
    "    ax.set_title(title)\n",
    "    if print_color_bar:\n",
    "        norm = plt.Normalize(vmin=vmin, vmax=vmax)\n",
    "        plt.colorbar(plt.cm.ScalarMappable(cmap=cmap, norm=norm), ax=ax)\n",
    "\n",
    "def unravel_index(indices, shape):\n",
    "        out = []\n",
    "        for dim in reversed(shape):\n",
    "            out.append(indices % dim)\n",
    "            indices = indices // dim\n",
    "        return tuple(reversed(out))\n",
    "\n",
    "def visualize_combined(model, ae, buffer, feat_idx, k=10):\n",
    "    labeled_seq = buffer.token_batch()\n",
    "    with model.trace(labeled_seq, scan=False, validate=False): \n",
    "        embeds = model.hook_embed.output.save()\n",
    "        embeds.retain_grad()\n",
    "        x = submodule.output\n",
    "        f = ae.encode(x).save()\n",
    "    mean_embed = embeds.value.mean(dim=(0,1))\n",
    "    f = f.value[...,feat_idx]\n",
    "\n",
    "    flattened_f = f.flatten()\n",
    "    top_values, top_indices_flattened = t.topk(flattened_f, k)\n",
    "    top_indices = unravel_index(top_indices_flattened, f.shape)\n",
    "    top_values.sum().backward()\n",
    "\n",
    "    contexts, activations, attributions = [], [], []\n",
    "    for i in range(k):\n",
    "        context_idx, token_idx = top_indices[0][i].item(), top_indices[1][i].item()\n",
    "        contexts.append(labeled_seq[context_idx, :token_idx+1].tolist())\n",
    "        activations.append(f[context_idx, :token_idx+1].tolist())\n",
    "        attributions.append(\n",
    "            (embeds.value.grad * (embeds.value - mean_embed)).sum(dim=-1)[context_idx, :token_idx+1].tolist()\n",
    "        )\n",
    "    # Normalize with max of all act values (act usually much bigger, so not sure this makes sense)\n",
    "    # max_value = max([abs(x) for act in activations for x in act] + [abs(x) for att in attributions for x in att])\n",
    "\n",
    "    for cnt, (context_i, activation, attribution) in enumerate(zip(contexts, activations, attributions)):\n",
    "        print(\"=\"*80)\n",
    "        print(f'Top {cnt+1} example:')\n",
    "        board_state_RR = convert_othello_dataset_sample_to_board(context_i)\n",
    "\n",
    "        display(visualize_game_seq(context_i, activation, t.tensor(activation).abs().max(), prefix='feature activations: <br>'))\n",
    "        display(visualize_game_seq(context_i, attribution, t.tensor(attribution).abs().max(), prefix='embedding attributions: <br>'))\n",
    "\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "        \n",
    "        plot_game_seq(axs[0], context_i, activation, board_state_RR, prefix='Activations on board')\n",
    "        plot_game_seq(axs[1], context_i, attribution, board_state_RR, prefix='Attribution patching on embedding\\n(mean_ablation)')\n",
    "        visualize_lens(axs[2], model, ae, feat_idx, cossim_tokenembed_feature_decoder, title='Cosine similarity token_embed lens')\n",
    "        visualize_lens(axs[3], model, ae, feat_idx, cossim_logit_feature_decoder, title='Cosine similarity logit lens')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "    return contexts[0], activations[0], attributions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here's the interactive part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key for mapping from the last entry of the board state tensor to pieces:\n",
    "* 0 => black king\n",
    "* 1 => black queen\n",
    "* 2 => black rook\n",
    "* 3 => black bishop\n",
    "* 4 => black knight\n",
    "* 5 => black pawn\n",
    "* 6 => empty\n",
    "* 7 => white pawn\n",
    "* 8 => white knight\n",
    "* 9 => white bishop\n",
    "* 10 => white rook\n",
    "* 11 => white queen\n",
    "* 12 => white king"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "NOT_CLASSIFIED_VALUE = -9\n",
    "\n",
    "def plot_othello_board(board):\n",
    "    \"\"\"\n",
    "    Plots an Othello board using matplotlib with a specific color lookup for different values.\n",
    "\n",
    "    Args:\n",
    "    board (torch.Tensor): A 2D tensor representing the Othello board,\n",
    "                          where 0, -1, 1, and -2 are mapped to specific colors.\n",
    "    \"\"\"\n",
    "    # Create a color map with specific colors\n",
    "    # Creating a dictionary for the color mapping\n",
    "    color_map = {-1: 'black', 0: 'grey', 1: 'white', NOT_CLASSIFIED_VALUE: 'yellow', -3: 'red'}\n",
    "    \n",
    "    # Replace board values with corresponding colors using a numpy vectorized operation\n",
    "    label_colors = np.vectorize(color_map.get)(board.numpy())\n",
    "\n",
    "    # Create a figure and axis for the plot\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Create a color map based on the unique labels in the board\n",
    "    unique_labels = np.unique(board)\n",
    "    colors = [color_map[label] for label in unique_labels]\n",
    "    cmap = plt.matplotlib.colors.ListedColormap(colors)\n",
    "\n",
    "    # Map board values to indices in the unique labels\n",
    "    board_indices = np.vectorize(lambda x: np.where(unique_labels == x)[0][0])(board.numpy())\n",
    "\n",
    "    # Plot the board using imshow\n",
    "    cax = ax.imshow(board_indices, cmap=cmap)\n",
    "\n",
    "    # Create a color bar with the correct labels\n",
    "    cbar = fig.colorbar(cax, ticks=range(len(unique_labels)))\n",
    "    cbar.ax.set_yticklabels([color_map[label] for label in unique_labels])\n",
    "\n",
    "    # Set the axis to be off since we don't need it for a game board representation\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Add a title to the plot\n",
    "    plt.title('Othello Board. Grey = Empty, Yellow = Not present in one hot vector')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "def get_feature_label_classified_squares(feature_labels, board_state_function, threshold_idx, feature_idx) -> t.Tensor:\n",
    "    sae_feature_board_state_RRC = feature_labels[board_state_function][threshold_idx][feature_idx]\n",
    "    sae_feature_board_state_RR = t.argmax(sae_feature_board_state_RRC, dim=-1)\n",
    "    sae_feature_board_state_RR -= 1\n",
    "\n",
    "    zero_positions_RR = t.all(sae_feature_board_state_RRC == 0, dim=-1)\n",
    "    sae_feature_board_state_RR[zero_positions_RR] = NOT_CLASSIFIED_VALUE\n",
    "    return sae_feature_board_state_RR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_state_function = 'games_batch_to_state_stack_mine_yours_BLRRC'\n",
    "board_state_function = 'games_batch_to_state_stack_mine_yours_blank_mask_BLRRC'\n",
    "board_state_function = 'games_batch_to_valid_moves_BLRRC'\n",
    "\n",
    "threshold_idx = 1 # There's 11 thresholds in the lookup table. If 0, the lookup table is constructed from every activation\n",
    "# If 1, it's constructed from all activations above 10% of that feature's max activation. If 2, 20% etc.\n",
    "# 1 is a reasonable default\n",
    "\n",
    "demo_idx = None\n",
    "\n",
    "for alive_feature_index in range(70):\n",
    "    num_classified_squares = feature_labels[board_state_function][threshold_idx][alive_feature_index].sum()\n",
    "    if num_classified_squares > 0:\n",
    "        print(f'Feature {alive_feature_index} has {num_classified_squares} classified squares')\n",
    "\n",
    "        demo_idx = alive_feature_index\n",
    "\n",
    "if demo_idx is None:\n",
    "    raise ValueError('No features have any classified squares')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_labels.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just rerun this cell to skip through features\n",
    "\n",
    "idx = demo_idx\n",
    "idx = 36\n",
    "\n",
    "threshold_idx = 1\n",
    "\n",
    "print(f'idx: {idx}')\n",
    "feat_idx = feature_labels['alive_features'][idx]\n",
    "# ll_fig, ll_board = visualize_logit_lens(model, ae, feat_idx)\n",
    "# ll_fig.show()\n",
    "\n",
    "sae_feature_board_state_RR = get_feature_label_classified_squares(feature_labels, board_state_function, threshold_idx, idx)\n",
    "plot_othello_board(sae_feature_board_state_RR.to('cpu'))\n",
    "\n",
    "print(\"Board states that the feature classifies according to Adam's measurements:\")\n",
    "print((feature_labels[board_state_function][threshold_idx][idx] == 1).nonzero())\n",
    "print(\"Number of such board states:\")\n",
    "print((feature_labels[board_state_function][threshold_idx][idx] == 1).sum())\n",
    "\n",
    "contexts, activations, attributions = visualize_combined(model, ae, buffer, feat_idx, k=50)\n",
    "\n",
    "idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_vec = ae.decoder.weight[:, 0]\n",
    "dec_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.W_E[1:, :].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cossim = t.cosine_similarity(dec_vec, model.W_E[1:, :], dim=1)\n",
    "dot_prod = dec_vec @ model.W_E[1:, :].T\n",
    "manual_cossim = dot_prod / t.norm(dec_vec) / t.norm(model.W_E[1:, :], dim=1)\n",
    "assert (cossim - manual_cossim).abs().sum() < 1e-6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cossim = t.cosine_similarity(dec_vec, model.W_U[:, 1:].T, dim=1) # NOTE 0 is a special token?\n",
    "dot_prod = dec_vec @ model.W_U[:, 1:]\n",
    "manual_cossim = dot_prod / t.norm(dec_vec) / t.norm(model.W_U[:, 1:], dim=0)\n",
    "assert (cossim - manual_cossim).abs().sum() < 1e-6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
